{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "309b73ea-81f0-4d89-8edb-64b774b58321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ef35a39-96f8-4773-95ed-0f47bd46dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'output DataScience Course for DataCamp.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c1a7fc9-5c81-4dd9-86df-500bf989a126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Questions Unnamed: 1 Unnamed: 2\n",
      "0     50xp In this chapter, you're going to look at ...        NaN        NaN\n",
      "1     Import pandas as pd. Read 'dob_job_application...        NaN        NaN\n",
      "2     50xp In the previous exercise, you identified ...        NaN        NaN\n",
      "3     Print the info of df. Print the info of the su...        NaN        NaN\n",
      "4     100xp As you've seen, .describe() can only be ...        NaN        NaN\n",
      "...                                                 ...        ...        ...\n",
      "1520  In the video, you learned how to use NMF featu...        NaN        NaN\n",
      "1521  In this exercise and the next, you'll use what...        NaN        NaN\n",
      "1522  100XP Import: NMF from sklearn.decomposition. ...        NaN        NaN\n",
      "1523  Suppose you were a big fan of Bruce Springstee...        NaN        NaN\n",
      "1524  100XP Import pandas as pd. Create a DataFrame ...        NaN        NaN\n",
      "\n",
      "[1525 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed89dd76-f6d7-4da0-8082-d2952b40e30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Questions', 'Unnamed: 1', 'Unnamed: 2'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1baed0-b704-469e-993a-ac904b28d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 1', 'Unnamed: 2'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd641e08-8285-4d8e-a606-ce4d6cea28d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50xp In this chapter, you're going to look at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Import pandas as pd. Read 'dob_job_application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50xp In the previous exercise, you identified ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Print the info of df. Print the info of the su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100xp As you've seen, .describe() can only be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>In the video, you learned how to use NMF featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>In this exercise and the next, you'll use what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>100XP Import: NMF from sklearn.decomposition. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>Suppose you were a big fan of Bruce Springstee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1525 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Questions\n",
       "0     50xp In this chapter, you're going to look at ...\n",
       "1     Import pandas as pd. Read 'dob_job_application...\n",
       "2     50xp In the previous exercise, you identified ...\n",
       "3     Print the info of df. Print the info of the su...\n",
       "4     100xp As you've seen, .describe() can only be ...\n",
       "...                                                 ...\n",
       "1520  In the video, you learned how to use NMF featu...\n",
       "1521  In this exercise and the next, you'll use what...\n",
       "1522  100XP Import: NMF from sklearn.decomposition. ...\n",
       "1523  Suppose you were a big fan of Bruce Springstee...\n",
       "1524  100XP Import pandas as pd. Create a DataFrame ...\n",
       "\n",
       "[1525 rows x 1 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50ceec8e-d49e-4f17-a3d0-dff35c1375af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Import pandas as pd. Read 'dob_job_application_filings_subset.csv' into a DataFrame called df. Print the head and tail of df. Print the shape of df and its columns. Note: .shape and .columns are attributes, not methods, so you don't need to follow these with parentheses (). Hit 'Submit Answer' to view the results! Notice the suspicious number of 0 values. Perhaps these represent missing data.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Questions'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52676521-470e-451a-9131-2ce1599bc335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df['Questions'].str.startswith(('50xp', '100xp', '100XP', '50XP', '0XP', '0xp')).to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34842169-34eb-42a2-bd32-c6a6e04030cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb86bba4-f5bc-45b3-b401-0d192e351870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50xp In this chapter, you're going to look at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50xp In the previous exercise, you identified ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100xp As you've seen, .describe() can only be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100xp Up until now, you've been looking at des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100xp Histograms are great ways of visualizing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100xp Boxplots are great when you have a numer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100xp Melting data is the process of turning c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100xp When melting DataFrames, it would be bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100xp Pivoting data is the opposite of melting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100xp After pivoting airquality_melt in the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100xp The dataset you saw in the video, consis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100xp Another common way multiple variables ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100xp The dataset you'll be working with here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100xp Think of column-wise concatenation of da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100xp You're now going to practice using the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100xp Now that you have a list of filenames to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>100xp Merging data allows you to combine dispa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100xp In a many-to-one (or one-to-many) merge,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100xp The final merging scenario occurs when b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100xp In this exercise, you'll see how ensurin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100xp If you expect the data type of a column ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100xp In the video, Dan introduced you to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100xp Extracting numbers from strings is a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100xp In this exercise, you'll continue practi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>100xp You'll now practice writing functions to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>100xp You'll now be introduced to a powerful P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>100xp Duplicate data causes a variety of probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>100xp Here, you'll return to the airquality da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0xp Here, you'll practice writing assert state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>100xp In this exercise, you'll write code to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0xp As Dan explained to you in the video, an \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>100xp You'll now define a function called pred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>100xp In this exercise, you'll write code to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>100xp Now you'll get to change weights in a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>100xp You've seen how different weights will h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>100xp You're now going to practice calculating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>100xp Hurray! You've just calculated the slope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>100xp You're now going to make multiple update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>100xp Now you'll get to work with your first m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>100xp You're now going to compile the model yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>100xp You're at the most fun part. You'll now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>100xp You'll now create a classification model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>100xp The trained network from your previous c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>100xp It's time to get your hands dirty with o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>100xp Now it's your turn to monitor model accu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100xp Now that you know how to monitor your mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0xp Now you know everything you need to begin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100xp You've seen how to experiment with wider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0xp You've reached the final exercise of the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>100xp In this exercise, you'll be working with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>100xp For large files, we may not want to prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>100xp In this exercise, you're now going to lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>100xp What if there are rows, such as a header...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>100xp The file seaslug.txt has a text header, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>100xp You have just used np.genfromtxt() to im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>100xp In the last exercise, you were able to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>100xp The pandas package is also great at deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>100xp There are a number of datatypes that can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>100xp Whether you like it or not, any working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>100xp In the previous exercises, you saw that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>100xp Here, you'll parse your spreadsheets and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>100xp Here, you'll gain expertise in importing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>100xp The file 'LIGO_data.hdf5' is already in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>100xp In this exercise, you'll extract some of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>100xp Here, you'll discover what is in the MAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>100xp Here, you're going to fire up your very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>100xp In this exercise, you'll once again crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0xp Now, it's time for liftoff! In this exerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>100xp Congratulations on executing your first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>100xp You can now execute a basic SQL query to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>100xp You can also order your SQL query result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>100xp Here, you'll become more familiar with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>100xp Here, you'll perform your first INNER JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>100xp Congrats on performing your first INNER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>100xp In this exercise, you'll be working with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>100xp For large files, we may not want to prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>100xp In this exercise, you're now going to lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>100xp What if there are rows, such as a header...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>100xp The file seaslug.txt has a text header, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>100xp You have just used np.genfromtxt() to im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>100xp In the last exercise, you were able to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>100xp The pandas package is also great at deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>100xp There are a number of datatypes that can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>100xp Whether you like it or not, any working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>100xp In the previous exercises, you saw that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>100xp Here, you'll parse your spreadsheets and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>100xp Here, you'll gain expertise in importing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>100xp The file 'LIGO_data.hdf5' is already in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>100xp In this exercise, you'll extract some of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>100xp Here, you'll discover what is in the MAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>100xp Here, you're going to fire up your very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>100xp In this exercise, you'll once again crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0xp Now, it's time for liftoff! In this exerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>100xp Congratulations on executing your first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>100xp You can now execute a basic SQL query to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>100xp You can also order your SQL query result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>100xp Here, you'll become more familiar with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>100xp Here, you'll perform your first INNER JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>100xp Congrats on performing your first INNER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>100xp You are about to import your first file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>100xp You have just imported a file from the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>100xp Congrats! You've just loaded a flat file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>100xp Now that you know the basics behind HTTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>100xp You have just packaged and sent a GET re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>100xp Now that you've got your head and hands ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>100xp In this interactive exercise, you'll lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>100xp As promised, in the following exercises,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0xp Now that you know what a JSON is, you'll l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>100xp Now it's your turn to pull some movie da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>100xp Wow, congrats! You've just queried your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>100xp You're doing so well and having so much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>100xp The package tweepy is great at handling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>100xp Now that you have set up your authentica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>100xp Now that you've got your Twitter data si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>100xp Now you have the Twitter data in a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>100xp Now that you have your DataFrame of twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>100xp Now that you have the number of tweets t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>100XP Import the figure function from bokeh.pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>100XP Create the figure p with the figure() fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>100XP Using the Latin America data (fertility_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>100XP Import the figure function from bokeh.pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>100XP Plot date along the x-axis and price alo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>100XP Create a list of the longitude positions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>100XP Import numpy as np. Create an array x us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>100XP Import pandas as pd. Use the read_csv() ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>100XP Import the ColumnDataSource class from b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>100XP Create a figure p with an x-axis label o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>100XP Import HoverTool from bokeh.models. Add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>100XP Import CategoricalColorMapper from bokeh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>100XP Import row from the bokeh.layouts module...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>100XP Import column from the bokeh.layouts mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>100XP Import row and column from bokeh.layouts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>100XP Import gridplot from the bokeh.layouts m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>100XP Import Panel from bokeh.models.widgets. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>100XP Import Tabs from bokeh.models.widgets. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>100XP Link the x_range of p2 to p1. Link the y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>100XP Create a ColumnDataSource object called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>100XP Add a red circle glyph to the figure p u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>100XP Use p.legend.location to adjust the lege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>100XP Import the HoverTool class from bokeh.mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>100XP Import curdoc from bokeh.io and figure f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>100XP Import curdoc from bokeh.io, widgetbox f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>100XP Create the first slider, slider1, using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>100XP Create a ColumnDataSource called source....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>100XP Define a callback function callback with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>100XP Define a callback function called update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>100XP Create select1, the first dropdown selec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0XP Create a button called button using the fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>100XP Import CheckboxGroup, RadioGroup, Toggle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>100XP Import output_file and show from bokeh.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>100XP Make a ColumnDataSource object called so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>100XP Make a list of the unique values from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>100XP Import the widgetbox and row functions f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>100XP Define the update_plot callback function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>100XP Import HoverTool from bokeh.models. Crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>100XP Inside the update_plot() callback functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>100xp With matplotlib, you can create a bunch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>100xp Now that you've built your first line pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>100xp When you have a time scale along the hor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>100xp In the previous exercise, you saw that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>100xp life_exp, the list containing data on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>100xp In the previous exercise, you didn't spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>100xp It's time to customize your own plot. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>100xp The customizations you've coded up to no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>100xp Right now, the scatter plot is just a cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>100xp The code you've written up to now is ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>100xp If you have another look at the script, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>100xp To see why dictionaries are useful, have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>100xp The countries and capitals lists are aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>100xp If the keys of a dictionary are chosen w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0xp If you know how to access a dictionary, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>100xp Somebody thought it would be funny to me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>100xp Remember lists? They could contain anyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>100xp Pandas is an open source library, provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>100xp The Python code that solves the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>100xp Putting data in a dictionary and then bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>100xp Your read_csv() call to import the CSV d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>100xp In the video, you saw that you can index...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>100xp Square brackets can do more than just se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>100xp With loc and iloc you can do practically...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>100xp loc and iloc also allow you to select bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>100xp It's also possible to select only column...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>100xp To check if two Python values, or variab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>100xp In the video, Filip also talked about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>100xp Out of the box, you can also use compari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>100xp A boolean is either 1 or 0, True or Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>100xp It's time to take a closer look around i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>100xp On the right, the if construct for room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>100xp It's also possible to have a look around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>100xp Remember that cars dataset, containing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>100xp The code in the previous example worked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>100xp Let's stick to the cars data some more. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>100xp Remember about np.logical_and(), np.logi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>100xp Below you can find the example from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>100xp The while loop that corrects the offset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>100xp Have another look at the for loop that F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>100xp Using a for loop to iterate over a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>100xp For non-programmer folks, room 0: 11.25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>100xp Remember the house variable from the Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>100xp In Python 3, you need the items() method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>100xp If you're dealing with a 1D Numpy array,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>100xp Iterating over a Pandas DataFrame is typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>100xp The row data that's generated by iterrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0xp In the video, Filip showed you how to add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>100xp Using iterrows() to iterate over every o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>100xp Below you can find the example from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>100xp The while loop that corrects the offset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>100xp Have another look at the for loop that F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>100xp Using a for loop to iterate over a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>100xp For non-programmer folks, room 0: 11.25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>100xp Remember the house variable from the Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>100xp In Python 3, you need the items() method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>100xp If you're dealing with a 1D Numpy array,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>100xp Iterating over a Pandas DataFrame is typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>100xp The row data that's generated by iterrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0xp In the video, Filip showed you how to add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>100xp Using iterrows() to iterate over every o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>100xp Randomness has many uses in science, art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>100xp In the previous exercise, you used rand(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>100xp In the Empire State Building bet, your n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>100xp Before, you have already written Python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0xp Things are shaping up nicely! You already ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>100xp Let's visualize this random walk! Rememb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>100xp A single random walk is one thing, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>100xp all_walks is a list of lists: every sub-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>100xp With this neatly written code of yours, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>100xp All these fancy visualizations have put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>100xp Subsetting Python lists is a piece of ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>50xp You saw before that a Python list can con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>100xp Replacing list elements is pretty easy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>100xp If you can change elements in a list, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>100xp Out of the box, Python offers a bunch of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>50xp Maybe you already know the name of a Pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>100xp In the previous exercise, the square bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>100xp Strings come with a bunch of methods. Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>100xp Strings are not the only Python types th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>100xp Most list methods will change the list t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>100xp As a data scientist, some notions of geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>100xp General imports, like import math, make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>50xp There are several ways to import packages...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>100xp We're going to dive into the world of ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>100xp You are a huge baseball fan. You decide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>100xp The MLB also offers to let you analyze t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>100xp To subset both regular Python lists and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>100xp You've seen it with your own eyes: Pytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>100xp Before working on the actual MLB data, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>100xp You have another look at the MLB data an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>100xp If your 2D Numpy array has a regular str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>100xp Remember how you calculated the Body Mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>100xp You now know how to use Numpy functions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0xp Because the mean and median are so far apa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>100xp In the last few exercises you've learned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0XP Import create_engine from the sqlalchemy m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>100XP Import the Table object from sqlalchemy....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>100XP Reflect the census table as you did in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>100XP Build a SQL statement to query all the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>100XP Import select from the sqlalchemy module...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>100XP Extract the first row of results and ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>50XP Import create_engine from sqlalchemy. Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>100XP Select all records from the census table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>100XP Select all records from the census table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>100XP Import and_ from the sqlalchemy module. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>100XP Select all records of the state column f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>100XP Import desc from the sqlalchemy module. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>100XP Select all records of the state and age ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>100XP Build a select statement to count the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>100XP Import func from sqlalchemy. Build an ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>100XP Import matplotlib.pyplot as plt. Create ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>100XP Import the create_engine function from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>100XP Define a select statement called stmt to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>100XP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>100XP Build a statement to join the census and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>100XP Build a statement to select ALL the colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>100XP Build a statement to select: The state c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>100XP Save an alias of the employees table as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>100XP Use a while loop that checks if there ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>100XP Import Table, Column, String, Integer, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>100XP Table, Column, String, Integer, Float, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>100XP Import insert and select from the sqlalc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>100XP Build a list of dictionaries called valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>100XP Create a statement for bulk insert into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>100XP Build a statement to select all columns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>100XP Build an update statement to update the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>100XP Build a statement to select the name col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>100XP Import delete and select from sqlalchemy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>100XP Build a delete statement to remove data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>100XP Drop the state_fact table by applying th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>100XP Import create_engine and MetaData from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>100XP Import Table, Column, String, and Intege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>100XP Create an empty list called values_list....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>100XP Import insert from sqlalchemy. Build an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>100XP Import select from sqlalchemy. Build a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>100XP Import case, cast and Float from sqlalch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>100XP Build a statement to: Select state. Calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>100XP Import matplotlib.pyplot as its usual al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>100XP Create a set of plot axes with lower cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>100XP Use plt.subplot() to create a figure wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>100XP Create a figure with 2Ã—22Ã—2 subplot layo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>100XP Use plt.xlim() to set the x-axis range t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>100XP Use plt.axis() to select the time period...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>100XP Modify the plot command provided that dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>100XP Compute the maximum enrollment of women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>100XP Import matplotlib.pyplot as its usual al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>100XP Import the numpy and matplotlib.pyplot m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>100XP Using the meshgrid X, Y as axes: Generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>100XP Modify the call to plt.contourf() so the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>100XP Generate a two-dimensional histogram to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>100XP Generate a two-dimensional histogram wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>100XP Load the file '480px-Astronaut-EVA.jpg' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>100XP Print the shape of the existing image ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>100XP Display img in the top left subplot with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>100XP Use the methods .min() and .max() to sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>100XP Import matplotlib.pyplot and seaborn usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>100XP Import matplotlib.pyplot and seaborn usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>100XP Modify the call to plt.scatter() to plot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>100XP Plot a linear regression between 'weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>100XP Plot linear regressions of 'hp' (on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>100XP In the first row of subplots, make a str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>100XP In the first row of subplots, make a swa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>100XP In the first row of subplots, make a vio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>100XP Use sns.jointplot() to visualize the joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>100XP Create a hexbin plot of the joint distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>100XP Print the first five rows of the DataFra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>100XP Plot the pairwise joint distributions se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>100XP Print the covariance matrix cov_matrix t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>100XP Plot the aapl time series in blue with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>100XP Plot the series aapl in 'blue' in the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>100XP Extract a slice named view from the seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>100XP Extract a slice of series aapl from Nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>100XP In the top left subplot, plot the 30-day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>100XP Produce a single plot with four curves o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>100XP Load data from the file '640px-Unequaliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>100XP First, use plt.hist() to plot the histog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>100XP Use the NumPy array method .reshape() to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>100XP Display image in the top subplot of a 2Ã—...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>100XP Make a 2-D histogram in the top left sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>100XP Import the create_engine function from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>100XP Define a select statement called stmt to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>100XP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>100XP Build a statement to join the census and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>100XP Build a statement to select ALL the colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>100XP Build a statement to select: The state c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>100XP Save an alias of the employees table as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>100XP Use a while loop that checks if there ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>100XP Import Table, Column, String, Integer, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>100XP Table, Column, String, Integer, Float, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>100XP Import insert and select from the sqlalc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>100XP Build a list of dictionaries called valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>100XP Create a statement for bulk insert into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>100XP Build a statement to select all columns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>100XP Build an update statement to update the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>100XP Build a statement to select the name col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>100XP Import delete and select from sqlalchemy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>100XP Build a delete statement to remove data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>100XP Drop the state_fact table by applying th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>100XP Import create_engine and MetaData from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>100XP Import Table, Column, String, and Intege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>100XP Create an empty list called values_list....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>100XP Import insert from sqlalchemy. Build an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>100XP Import select from sqlalchemy. Build a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>100XP Import case, cast and Float from sqlalch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>100XP Build a statement to: Select state. Calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>100XP Print summary statistics of the numeric ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>100XP Define the lambda function categorize_la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>100XP Create the DataFrame num_unique_labels b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>100XP Using the compute_log_loss() function, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>100XP Create a new DataFrame named numeric_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>100XP Import LogisticRegression from sklearn.l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>100XP Read HoldoutData.csv into a DataFrame ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>100XP Create the prediction_df DataFrame by sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>100XP Use the .drop() method on data_frame wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>100XP Import Pipeline from sklearn.pipeline. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>100XP Compute the selector get_text_data by us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>100XP In the process_and_join_features: Add th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>100XP Complete the call to multilabel_train_te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>100XP Complete the 'numeric_features' transfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>100XP Import the RandomForestClassifier from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>100XP Import the RandomForestClassifier from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>100XP Create text_vector by preprocessing X_tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>100XP Add the interaction terms step using Spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>100XP Import HashingVectorizer from sklearn.fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>100XP Import HashingVectorizer from sklearn.fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>100xp As you saw in the video, loading data fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>100xp In this exercise, you'll combine the thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0xp It is often useful to rearrange the sequen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>100xp Sorting methods are not the only way to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>100xp Another common technique is to reindex a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>100xp In this exercise, you'll work with weath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>100xp Your job in this exercise is to compute ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>100XP Create an empty list called units. This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>100XP Create a 'year' column in the DataFrames...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>100XP Create a new DataFrame called weather by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>100XP Iterate over medal_types in the for loop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>100XP Within the for loop: Read file_name into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>100XP Create a new DataFrame medals_sorted wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>100XP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>100XP Create a list called month_list consisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>100XP Construct a list of DataFrames called me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>100XP Make a new DataFrame china_annual by res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>100XP Using pd.merge(), merge the DataFrames r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>100XP Merge the DataFrames revenue and manager...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>100XP Create a column called 'state' in the Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>100XP Execute a right merge using pd.merge() w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>100XP Merge sales_and_managers with revenue_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>100XP Perform an ordered merge on austin and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>100XP Merge auto and oil using pd.merge_asof()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>100XP Read file_path into a DataFrame called e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>100XP Read file_path into a DataFrame called i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>100XP Within the for loop: Create the file pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>0XP Construct a pivot table from the DataFrame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>100XP Set the index of the DataFrame editions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>100XP Create mean_fractions by chaining the me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>0XP Create the DataFrame hosts by doing a left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>100XP Create a DataFrame reshaped by reshaping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>100XP Merge reshaped and hosts using an inner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>100XP Create a Series called change by extract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>100xp Now you'll get a chance to write some re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>100xp Here, you'll be using the first scene of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0xp In this exercise, you'll utilize re.search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>50xp Given the following string, which is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>100xp Twitter is a frequently used source for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0xp In this exercise, you'll practice advanced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>100xp Try using your new skills to find and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>100xp In this exercise, you'll build your firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>100xp Now, it's your turn to apply the techniq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>100xp It's time to apply the methods you learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>100xp Now, you'll use your new gensim corpus a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>100xp You're now going to have some fun with n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>100xp In this exercise, you'll use some extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>100xp Using the same text you used in the firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>100xp In this exercise and the next, you'll us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0xp Here, you'll complete the work you began i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>100xp You'll continue your exploration of poly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>100xp In the final exercise of this NER chapte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>100xp It's time to begin building your text cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>100xp Similar to the sparse CountVectorizer cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>100xp To get a better idea of how the vectors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>100xp Now it's your turn to train the \"fake ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>100xp Now that you have evaluated the model us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>100xp Your job in this exercise is to test a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>100xp Now that you have built a \"fake news\" cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>100XP Import matplotlib.pyplot as plt and netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>100XP Use a list comprehension to get a list o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>100XP Set the 'weight' attribute of the edge b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>100XP Define a function called find_selfloop_n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>100XP Import nxviz as nv. Plot the graph T as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>100XP Import CircosPlot from nxviz. Plot the T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>100XP Import ArcPlot from nxviz. Create an un-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>100XP Write a function called nodes_with_m_nbr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>100XP Use a list comprehension along with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>100XP Compute the degree centrality of the Twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>100XP Create a function called path_exists() t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>100XP Using the .add() method, add the current...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>100XP Check to see if the queue has been empti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>100XP Compute the betweenness centrality bet_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>100XP Write a function find_nodes_with_highest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>100XP Write a function find_node_with_highest_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>100XP Import combinations from itertools. Writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>100XP Write a function nodes_in_triangle() tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>100XP Write a function node_in_open_triangle()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>100XP Write a function maximal_cliques() that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>100XP Write a function get_nodes_and_nbrs(G, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>100XP Using a list comprehension, extract node...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>100XP Plot the degree distribution of the GitH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>100XP Plot the betweenness centrality distribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>100XP Make a MatrixPlot visualization of the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>100XP Make an ArcPlot of the GitHub collaborat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>100XP Make a CircosPlot of the network, again,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>100XP Count the number of maximal cliques pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>100XP Find the author(s) that are part of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>100XP Go out 1 degree of separation from the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>100XP Compile a list of GitHub users that shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>100xp Pandas depends upon and interoperates wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>100xp In this exercise, you're going to make a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>100xp You can use the DataFrame attribute df.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>100xp You can implicitly use 'broadcasting', a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>100xp In previous exercises, we have preloaded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>100xp Not all data files are clean and tidy. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>100xp Data visualization is often a very effec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>100xp Comparing data from several columns can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>100xp In the previous chapter, you saw that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>100xp Pandas scatter plots are generated using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>100xp While pandas can plot multiple columns o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>100xp Pandas relies on the .hist() method to n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>100xp In this exercise, you will investigate s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>100xp In many data sets, there can be large di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>100xp In this exercise, you'll investigate the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>100xp Let's use the mean and standard deviatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>50xp How many automobiles were manufactured in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>100xp Let's use population filtering to determ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>100xp Population filtering can be used alongsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>100xp Pandas time series support \"partial stri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>100xp Reindexing is useful in preparation for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>100xp Pandas provides methods for resampling t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>100xp With pandas, you can resample in differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>100xp In this exercise, some hourly weather da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>100xp As of pandas version 0.18.0, the interfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>100xp We've seen that pandas supports method c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>100xp One common application of interpolation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>0xp Time zone handling with pandas typically a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>100xp Pandas handles datetimes not only in you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>100xp Now that you have set the DatetimeIndex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>100xp Now that you have identified the method ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>100xp After the initial step of reading in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>0xp In order to use the full power of pandas t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>100xp The numeric columns contain missing valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>100xp Now that you have the data read and clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>0xp You're now ready to compare the 2011 weath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>100xp On average, how much hotter is it when t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>100xp Is there a correlation between temperatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>100xp In a previous exercise, you analyzed the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>100xp Dew point is a measure of relative humid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>100xp We already know that 2011 was hotter tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>100xp Let's work more on your mastery of scope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0xp You've learned in the last video about nes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>100xp Great job, you've just nested a function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>100xp Let's once again work further on your ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>100xp In the previous chapter, you've learned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>100xp You've now defined a function that uses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>100xp Flexible arguments enable you to pass a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>100xp Let's push further on what you've learne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>100xp Recall the Bringing it all together exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>100xp Wow, you've just generalized your Twitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>100xp Some function definitions are simple eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>100xp So far, you've used lambda functions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>100xp In the previous exercise, you used lambd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>100xp You're getting very good at using lambda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>100xp A good practice in writing your own func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>100xp Another way to raise an error is by usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>100xp This is awesome! You have now learned ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>100xp Sometimes, we make mistakes when calling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>100xp In the previous exercise, you built on y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>100xp Great, you're familiar with what iterabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>100xp One of the things you learned about in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>100xp You've been using the iter() function to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>100xp You're really getting the hang of using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>100xp Another interesting function that you've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>100xp You know how to use zip() as well as how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>100xp Sometimes, the data we have to process r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>100xp Great job chunking out that file in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>100xp You now have all the knowledge necessary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>100xp Great! At this point, you have a good gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0xp You've been using list comprehensions to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>100xp In the previous exercise, you used an if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>100xp Comprehensions aren't relegated merely t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>100xp You are familiar with what generators an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>100xp Great! At this point, you already know h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>100xp In previous exercises, you've dealt main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0xp You will now make use of what you've learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>100xp Great, you've successfully extracted the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>0xp For this exercise, you'll use what you've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>100xp Suppose you needed to repeat the same pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>100xp This time, you're going to use the lists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>100xp You've zipped lists together, created a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>100xp Sometimes, data sources can be so large ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>100xp In the previous exercise, you processed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>100xp Great! You've just created a generator f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>100xp Another way to read data too large to st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>100xp In the previous exercise, you used read_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>100xp You're getting used to reading and proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>100xp In the previous exercises, you've only p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>100xp This is the last leg. You've learned a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>100XP Seed the random number generator with 42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>100XP Compute an ECDF from the actual time bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>100XP Plot fertility (y-axis) versus illiterac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>100XP Compute the slope and intercept of the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>100XP Specify the values of the slope for whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>100XP Compute the parameters for the slope and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>100XP Write a for loop to do the following for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>100XP Write a for loop to acquire 50 bootstrap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>100XP Define a function with call signature dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>100XP Draw 10000 bootstrap replicates of the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>100XP Draw 10000 bootstrap replicates of the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>100XP Generate 10000 bootstrap replicates of Ï„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>100XP Define a function with call signature dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>100XP Use your draw_bs_pairs_linreg() function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>100XP Generate an array of xx-values consistin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>100XP Concatenate the two input arrays into on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>100XP Write a for loop to 50 generate permutat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>100XP Define a function with this signature: d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>100XP Use sns.swarmplot() to make a bee swarm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>100XP Define a function with call signature di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>100XP Translate the impact forces of Frog B su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>100XP Compute the observed difference in impac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>100XP Compute the mean of all forces (from for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>100XP Construct Boolean arrays, dems and reps ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>100XP Compute the observed difference in mean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>100XP Compute the observed Pearson correlation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>100XP Use your ecdf() function to generate x,y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>100XP Compute the mean alive sperm count of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>100XP Label the axes. Don't forget that you sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>100XP Import numpy as np. This gives access to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>100XP Use ecdf() to compute the ECDF of versic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>100XP Define a function with the signature ecd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>100XP Compute ECDFs for each of the three spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>100XP Compute the mean petal length of Iris ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>100XP Plot the percentiles as red diamonds on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>100XP The set-up is exactly the same as for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>100XP Create an array called differences that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>100XP Compute the variance of the data in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>100XP Use plt.plot() with the appropriate keyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>100XP Use np.cov() to compute the covariance m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>100XP Define a function with signature pearson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>100XP Seed the random number generator using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>100XP Define a function with signature perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>100XP Seed the random number generator to 42. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>100XP Compute the x and y values for the ECDF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>100XP Draw samples out of the Binomial distrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>100XP Using np.arange(), compute the bin edges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>100XP Using the np.random.poisson() function, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>100XP Draw 10000 samples from a Poisson distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>100XP Use your ecdf() function to generate x a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>100XP Compute mean and standard deviation of B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>100XP Take 1,000,000 samples from the normal d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>100XP Define a function with call signature su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>100XP Use your successive_poisson() function t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>100xp In this chapter, you'll be working with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>50xp The Numerical EDA you did in the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>0xp Having explored the Congressional voting r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>0xp Having fit a k-NN classifier, you can now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>100xp Up until now, you have been performing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>100xp Now that you have learned about the impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>100xp Remember the model complexity curve that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>100xp In this chapter, you will work with Gapm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>100xp Now, you will fit a linear regression an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>100xp As you learned in Chapter 1, train and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>100xp Cross-validation is a vital step in eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>100xp Cross validation is essential but do not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>0xp In the video, you saw how Lasso selected o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>100xp Lasso is great for feature selection, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>100xp In Chapter 1, you evaluated the performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>100xp Time to build your first logistic regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>100xp Great job in the previous exercise - you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>100xp Say you have a binary classifier that in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>100xp Hugo demonstrated how to use to tune the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>100xp GridSearchCV can be computationally expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>100xp You will now practice evaluating a model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>100xp Remember lasso and ridge regression from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0xp The Gapminder dataset that you worked with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>100xp As Andy discussed in the video, scikit-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>100xp Having created the dummy variables from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>100xp The voting dataset from Chapter 1 contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>100xp As you've come to appreciate, there are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>100xp Having setup the steps of the pipeline i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>100xp In the video, Hugo demonstrated how sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>100xp With regard to whether or not scaling is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>100xp It is time now to piece together everyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>100xp For this final exercise, you will return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>100XP Import: matplotlib.pyplot as plt. pearso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>100XP Import PCA from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>100XP Make a scatter plot of the grain measure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>100XP Create an instance of StandardScaler cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>100XP Import PCA from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>100XP Import TfidfVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>100XP Import: TruncatedSVD from sklearn.decomp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>100XP Import pandas as pd. Fit the pipeline to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>100XP Import NMF from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>100XP Import matplotlib.pyplot as plt. Select ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>100XP Import NMF from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>100XP Import PCA from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>100XP Import: NMF from sklearn.decomposition. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Questions\n",
       "0     50xp In this chapter, you're going to look at ...\n",
       "2     50xp In the previous exercise, you identified ...\n",
       "4     100xp As you've seen, .describe() can only be ...\n",
       "6     100xp Up until now, you've been looking at des...\n",
       "8     100xp Histograms are great ways of visualizing...\n",
       "10    100xp Boxplots are great when you have a numer...\n",
       "12    100xp Melting data is the process of turning c...\n",
       "14    100xp When melting DataFrames, it would be bet...\n",
       "16    100xp Pivoting data is the opposite of melting...\n",
       "18    100xp After pivoting airquality_melt in the pr...\n",
       "21    100xp The dataset you saw in the video, consis...\n",
       "23    100xp Another common way multiple variables ar...\n",
       "25    100xp The dataset you'll be working with here ...\n",
       "27    100xp Think of column-wise concatenation of da...\n",
       "29    100xp You're now going to practice using the g...\n",
       "31    100xp Now that you have a list of filenames to...\n",
       "33    100xp Merging data allows you to combine dispa...\n",
       "35    100xp In a many-to-one (or one-to-many) merge,...\n",
       "37    100xp The final merging scenario occurs when b...\n",
       "39    100xp In this exercise, you'll see how ensurin...\n",
       "41    100xp If you expect the data type of a column ...\n",
       "43    100xp In the video, Dan introduced you to the ...\n",
       "45    100xp Extracting numbers from strings is a com...\n",
       "47    100xp In this exercise, you'll continue practi...\n",
       "49    100xp You'll now practice writing functions to...\n",
       "51    100xp You'll now be introduced to a powerful P...\n",
       "56    100xp Duplicate data causes a variety of probl...\n",
       "58    100xp Here, you'll return to the airquality da...\n",
       "60    0xp Here, you'll practice writing assert state...\n",
       "62    100xp In this exercise, you'll write code to d...\n",
       "65    0xp As Dan explained to you in the video, an \"...\n",
       "67    100xp You'll now define a function called pred...\n",
       "69    100xp In this exercise, you'll write code to d...\n",
       "71    100xp Now you'll get to change weights in a re...\n",
       "73    100xp You've seen how different weights will h...\n",
       "75    100xp You're now going to practice calculating...\n",
       "77    100xp Hurray! You've just calculated the slope...\n",
       "79    100xp You're now going to make multiple update...\n",
       "81    100xp Now you'll get to work with your first m...\n",
       "83    100xp You're now going to compile the model yo...\n",
       "85    100xp You're at the most fun part. You'll now ...\n",
       "87    100xp You'll now create a classification model...\n",
       "89    100xp The trained network from your previous c...\n",
       "91    100xp It's time to get your hands dirty with o...\n",
       "93    100xp Now it's your turn to monitor model accu...\n",
       "95    100xp Now that you know how to monitor your mo...\n",
       "97    0xp Now you know everything you need to begin ...\n",
       "99    100xp You've seen how to experiment with wider...\n",
       "101   0xp You've reached the final exercise of the c...\n",
       "103   100xp In this exercise, you'll be working with...\n",
       "105   100xp For large files, we may not want to prin...\n",
       "109   100xp In this exercise, you're now going to lo...\n",
       "111   100xp What if there are rows, such as a header...\n",
       "113   100xp The file seaslug.txt has a text header, ...\n",
       "117   100xp You have just used np.genfromtxt() to im...\n",
       "119   100xp In the last exercise, you were able to i...\n",
       "123   100xp The pandas package is also great at deal...\n",
       "125   100xp There are a number of datatypes that can...\n",
       "127   100xp Whether you like it or not, any working ...\n",
       "129   100xp In the previous exercises, you saw that ...\n",
       "131   100xp Here, you'll parse your spreadsheets and...\n",
       "133   100xp In this exercise, you'll figure out how ...\n",
       "136   100xp Here, you'll gain expertise in importing...\n",
       "138   100xp The file 'LIGO_data.hdf5' is already in ...\n",
       "140   100xp In this exercise, you'll extract some of...\n",
       "142   100xp In this exercise, you'll figure out how ...\n",
       "144   100xp Here, you'll discover what is in the MAT...\n",
       "147   100xp Here, you're going to fire up your very ...\n",
       "150   100xp In this exercise, you'll once again crea...\n",
       "152   0xp Now, it's time for liftoff! In this exerci...\n",
       "154   100xp Congratulations on executing your first ...\n",
       "161   100xp You can now execute a basic SQL query to...\n",
       "165   100xp You can also order your SQL query result...\n",
       "169   100xp Here, you'll become more familiar with t...\n",
       "171   100xp Here, you'll perform your first INNER JO...\n",
       "174   100xp Congrats on performing your first INNER ...\n",
       "177   100xp In this exercise, you'll be working with...\n",
       "179   100xp For large files, we may not want to prin...\n",
       "183   100xp In this exercise, you're now going to lo...\n",
       "185   100xp What if there are rows, such as a header...\n",
       "187   100xp The file seaslug.txt has a text header, ...\n",
       "191   100xp You have just used np.genfromtxt() to im...\n",
       "193   100xp In the last exercise, you were able to i...\n",
       "197   100xp The pandas package is also great at deal...\n",
       "199   100xp There are a number of datatypes that can...\n",
       "201   100xp Whether you like it or not, any working ...\n",
       "203   100xp In the previous exercises, you saw that ...\n",
       "205   100xp Here, you'll parse your spreadsheets and...\n",
       "207   100xp In this exercise, you'll figure out how ...\n",
       "210   100xp Here, you'll gain expertise in importing...\n",
       "212   100xp The file 'LIGO_data.hdf5' is already in ...\n",
       "214   100xp In this exercise, you'll extract some of...\n",
       "216   100xp In this exercise, you'll figure out how ...\n",
       "218   100xp Here, you'll discover what is in the MAT...\n",
       "221   100xp Here, you're going to fire up your very ...\n",
       "224   100xp In this exercise, you'll once again crea...\n",
       "226   0xp Now, it's time for liftoff! In this exerci...\n",
       "228   100xp Congratulations on executing your first ...\n",
       "235   100xp You can now execute a basic SQL query to...\n",
       "239   100xp You can also order your SQL query result...\n",
       "243   100xp Here, you'll become more familiar with t...\n",
       "245   100xp Here, you'll perform your first INNER JO...\n",
       "248   100xp Congrats on performing your first INNER ...\n",
       "251   100xp You are about to import your first file ...\n",
       "254   100xp You have just imported a file from the w...\n",
       "256   100xp Congrats! You've just loaded a flat file...\n",
       "259   100xp Now that you know the basics behind HTTP...\n",
       "261   100xp You have just packaged and sent a GET re...\n",
       "263   100xp Now that you've got your head and hands ...\n",
       "265   100xp In this interactive exercise, you'll lea...\n",
       "267   100xp As promised, in the following exercises,...\n",
       "269   100xp In this exercise, you'll figure out how ...\n",
       "271   0xp Now that you know what a JSON is, you'll l...\n",
       "273   100xp Now it's your turn to pull some movie da...\n",
       "275   100xp Wow, congrats! You've just queried your ...\n",
       "277   100xp You're doing so well and having so much ...\n",
       "279   100xp The package tweepy is great at handling ...\n",
       "281   100xp Now that you have set up your authentica...\n",
       "283   100xp Now that you've got your Twitter data si...\n",
       "285   100xp Now you have the Twitter data in a list ...\n",
       "287   100xp Now that you have your DataFrame of twee...\n",
       "291   100xp Now that you have the number of tweets t...\n",
       "294   100XP Import the figure function from bokeh.pl...\n",
       "296   100XP Create the figure p with the figure() fu...\n",
       "298   100XP Using the Latin America data (fertility_...\n",
       "300   100XP Import the figure function from bokeh.pl...\n",
       "302   100XP Plot date along the x-axis and price alo...\n",
       "304   100XP Create a list of the longitude positions...\n",
       "306   100XP Import numpy as np. Create an array x us...\n",
       "308   100XP Import pandas as pd. Use the read_csv() ...\n",
       "310   100XP Import the ColumnDataSource class from b...\n",
       "312   100XP Create a figure p with an x-axis label o...\n",
       "314   100XP Import HoverTool from bokeh.models. Add ...\n",
       "316   100XP Import CategoricalColorMapper from bokeh...\n",
       "318   100XP Import row from the bokeh.layouts module...\n",
       "320   100XP Import column from the bokeh.layouts mod...\n",
       "322   100XP Import row and column from bokeh.layouts...\n",
       "324   100XP Import gridplot from the bokeh.layouts m...\n",
       "326   100XP Import Panel from bokeh.models.widgets. ...\n",
       "328   100XP Import Tabs from bokeh.models.widgets. C...\n",
       "330   100XP Link the x_range of p2 to p1. Link the y...\n",
       "332   100XP Create a ColumnDataSource object called ...\n",
       "334   100XP Add a red circle glyph to the figure p u...\n",
       "336   100XP Use p.legend.location to adjust the lege...\n",
       "338   100XP Import the HoverTool class from bokeh.mo...\n",
       "340   100XP Import curdoc from bokeh.io and figure f...\n",
       "342   100XP Import curdoc from bokeh.io, widgetbox f...\n",
       "344   100XP Create the first slider, slider1, using ...\n",
       "346   100XP Create a ColumnDataSource called source....\n",
       "348   100XP Define a callback function callback with...\n",
       "350   100XP Define a callback function called update...\n",
       "352   100XP Create select1, the first dropdown selec...\n",
       "354   0XP Create a button called button using the fu...\n",
       "356   100XP Import CheckboxGroup, RadioGroup, Toggle...\n",
       "358   100XP Import output_file and show from bokeh.i...\n",
       "360   100XP Make a ColumnDataSource object called so...\n",
       "362   100XP Make a list of the unique values from th...\n",
       "364   100XP Import the widgetbox and row functions f...\n",
       "366   100XP Define the update_plot callback function...\n",
       "368   100XP Import HoverTool from bokeh.models. Crea...\n",
       "370   100XP Inside the update_plot() callback functi...\n",
       "371   100xp With matplotlib, you can create a bunch ...\n",
       "374   100xp Now that you've built your first line pl...\n",
       "376   100xp When you have a time scale along the hor...\n",
       "379   100xp In the previous exercise, you saw that t...\n",
       "381   100xp life_exp, the list containing data on th...\n",
       "383   100xp In the previous exercise, you didn't spe...\n",
       "386   100xp It's time to customize your own plot. Th...\n",
       "388   100xp The customizations you've coded up to no...\n",
       "391   100xp Right now, the scatter plot is just a cl...\n",
       "393   100xp The code you've written up to now is ava...\n",
       "396   100xp If you have another look at the script, ...\n",
       "398   100xp To see why dictionaries are useful, have...\n",
       "400   100xp The countries and capitals lists are aga...\n",
       "402   100xp If the keys of a dictionary are chosen w...\n",
       "405   0xp If you know how to access a dictionary, yo...\n",
       "407   100xp Somebody thought it would be funny to me...\n",
       "409   100xp Remember lists? They could contain anyth...\n",
       "411   100xp Pandas is an open source library, provid...\n",
       "413   100xp The Python code that solves the previous...\n",
       "415   100xp Putting data in a dictionary and then bu...\n",
       "416   100xp Your read_csv() call to import the CSV d...\n",
       "418   100xp In the video, you saw that you can index...\n",
       "421   100xp Square brackets can do more than just se...\n",
       "424   100xp With loc and iloc you can do practically...\n",
       "429   100xp loc and iloc also allow you to select bo...\n",
       "433   100xp It's also possible to select only column...\n",
       "436   100xp To check if two Python values, or variab...\n",
       "439   100xp In the video, Filip also talked about th...\n",
       "442   100xp Out of the box, you can also use compari...\n",
       "444   100xp A boolean is either 1 or 0, True or Fals...\n",
       "448   100xp It's time to take a closer look around i...\n",
       "450   100xp On the right, the if construct for room ...\n",
       "452   100xp It's also possible to have a look around...\n",
       "454   100xp Remember that cars dataset, containing t...\n",
       "456   100xp The code in the previous example worked ...\n",
       "458   100xp Let's stick to the cars data some more. ...\n",
       "460   100xp Remember about np.logical_and(), np.logi...\n",
       "462   100xp Below you can find the example from the ...\n",
       "464   100xp The while loop that corrects the offset ...\n",
       "465   100xp Have another look at the for loop that F...\n",
       "468   100xp Using a for loop to iterate over a list ...\n",
       "470   100xp For non-programmer folks, room 0: 11.25 ...\n",
       "472   100xp Remember the house variable from the Int...\n",
       "474   100xp In Python 3, you need the items() method...\n",
       "478   100xp If you're dealing with a 1D Numpy array,...\n",
       "482   100xp Iterating over a Pandas DataFrame is typ...\n",
       "485   100xp The row data that's generated by iterrow...\n",
       "487   0xp In the video, Filip showed you how to add ...\n",
       "490   100xp Using iterrows() to iterate over every o...\n",
       "494   100xp Below you can find the example from the ...\n",
       "497   100xp The while loop that corrects the offset ...\n",
       "499   100xp Have another look at the for loop that F...\n",
       "502   100xp Using a for loop to iterate over a list ...\n",
       "504   100xp For non-programmer folks, room 0: 11.25 ...\n",
       "506   100xp Remember the house variable from the Int...\n",
       "508   100xp In Python 3, you need the items() method...\n",
       "512   100xp If you're dealing with a 1D Numpy array,...\n",
       "516   100xp Iterating over a Pandas DataFrame is typ...\n",
       "519   100xp The row data that's generated by iterrow...\n",
       "521   0xp In the video, Filip showed you how to add ...\n",
       "524   100xp Using iterrows() to iterate over every o...\n",
       "528   100xp Randomness has many uses in science, art...\n",
       "530   100xp In the previous exercise, you used rand(...\n",
       "533   100xp In the Empire State Building bet, your n...\n",
       "535   100xp Before, you have already written Python ...\n",
       "537   0xp Things are shaping up nicely! You already ...\n",
       "539   100xp Let's visualize this random walk! Rememb...\n",
       "542   100xp A single random walk is one thing, but t...\n",
       "544   100xp all_walks is a list of lists: every sub-...\n",
       "548   100xp With this neatly written code of yours, ...\n",
       "550   100xp All these fancy visualizations have put ...\n",
       "574   100xp Subsetting Python lists is a piece of ca...\n",
       "583   50xp You saw before that a Python list can con...\n",
       "586   100xp Replacing list elements is pretty easy. ...\n",
       "589   100xp If you can change elements in a list, yo...\n",
       "597   100xp Out of the box, Python offers a bunch of...\n",
       "599   50xp Maybe you already know the name of a Pyth...\n",
       "602   100xp In the previous exercise, the square bra...\n",
       "604   100xp Strings come with a bunch of methods. Fo...\n",
       "605   100xp Strings are not the only Python types th...\n",
       "607   100xp Most list methods will change the list t...\n",
       "608   100xp As a data scientist, some notions of geo...\n",
       "609   100xp General imports, like import math, make ...\n",
       "611   50xp There are several ways to import packages...\n",
       "613   100xp We're going to dive into the world of ba...\n",
       "614   100xp You are a huge baseball fan. You decide ...\n",
       "615   100xp The MLB also offers to let you analyze t...\n",
       "616   100xp To subset both regular Python lists and ...\n",
       "619   100xp You've seen it with your own eyes: Pytho...\n",
       "622   100xp Before working on the actual MLB data, l...\n",
       "623   100xp You have another look at the MLB data an...\n",
       "624   100xp If your 2D Numpy array has a regular str...\n",
       "628   100xp Remember how you calculated the Body Mas...\n",
       "630   100xp You now know how to use Numpy functions ...\n",
       "632   0xp Because the mean and median are so far apa...\n",
       "633   100xp In the last few exercises you've learned...\n",
       "635   0XP Import create_engine from the sqlalchemy m...\n",
       "637   100XP Import the Table object from sqlalchemy....\n",
       "639   100XP Reflect the census table as you did in t...\n",
       "641   100XP Build a SQL statement to query all the c...\n",
       "643   100XP Import select from the sqlalchemy module...\n",
       "645   100XP Extract the first row of results and ass...\n",
       "647   50XP Import create_engine from sqlalchemy. Cre...\n",
       "649   100XP Select all records from the census table...\n",
       "651   100XP Select all records from the census table...\n",
       "653   100XP Import and_ from the sqlalchemy module. ...\n",
       "655   100XP Select all records of the state column f...\n",
       "657   100XP Import desc from the sqlalchemy module. ...\n",
       "659   100XP Select all records of the state and age ...\n",
       "664   100XP Build a select statement to count the di...\n",
       "668   100XP Import func from sqlalchemy. Build an ex...\n",
       "670   100XP Import pandas as pd. Create a DataFrame ...\n",
       "672   100XP Import matplotlib.pyplot as plt. Create ...\n",
       "674   100XP Import the create_engine function from t...\n",
       "676   100XP Define a select statement called stmt to...\n",
       "678                                               100XP\n",
       "682   100XP Build a statement to join the census and...\n",
       "684   100XP Build a statement to select ALL the colu...\n",
       "686   100XP Build a statement to select: The state c...\n",
       "690   100XP Save an alias of the employees table as ...\n",
       "692   100XP Use a while loop that checks if there ar...\n",
       "694   100XP Import Table, Column, String, Integer, F...\n",
       "696   100XP Table, Column, String, Integer, Float, B...\n",
       "698   100XP Import insert and select from the sqlalc...\n",
       "700   100XP Build a list of dictionaries called valu...\n",
       "702   100XP Create a statement for bulk insert into ...\n",
       "705   100XP Build a statement to select all columns ...\n",
       "707   100XP Build an update statement to update the ...\n",
       "709   100XP Build a statement to select the name col...\n",
       "712   100XP Import delete and select from sqlalchemy...\n",
       "715   100XP Build a delete statement to remove data ...\n",
       "717   100XP Drop the state_fact table by applying th...\n",
       "719   100XP Import create_engine and MetaData from s...\n",
       "721   100XP Import Table, Column, String, and Intege...\n",
       "723   100XP Create an empty list called values_list....\n",
       "725   100XP Import insert from sqlalchemy. Build an ...\n",
       "727   100XP Import select from sqlalchemy. Build a s...\n",
       "729   100XP Import case, cast and Float from sqlalch...\n",
       "731   100XP Build a statement to: Select state. Calc...\n",
       "733   100XP Import matplotlib.pyplot as its usual al...\n",
       "735   100XP Create a set of plot axes with lower cor...\n",
       "737   100XP Use plt.subplot() to create a figure wit...\n",
       "739   100XP Create a figure with 2Ã—22Ã—2 subplot layo...\n",
       "741   100XP Use plt.xlim() to set the x-axis range t...\n",
       "743   100XP Use plt.axis() to select the time period...\n",
       "745   100XP Modify the plot command provided that dr...\n",
       "747   100XP Compute the maximum enrollment of women ...\n",
       "749   100XP Import matplotlib.pyplot as its usual al...\n",
       "752   100XP Import the numpy and matplotlib.pyplot m...\n",
       "754   100XP Using the meshgrid X, Y as axes: Generat...\n",
       "756   100XP Modify the call to plt.contourf() so the...\n",
       "758   100XP Generate a two-dimensional histogram to ...\n",
       "760   100XP Generate a two-dimensional histogram wit...\n",
       "762   100XP Load the file '480px-Astronaut-EVA.jpg' ...\n",
       "764   100XP Print the shape of the existing image ar...\n",
       "766   100XP Display img in the top left subplot with...\n",
       "768   100XP Use the methods .min() and .max() to sav...\n",
       "770   100XP Import matplotlib.pyplot and seaborn usi...\n",
       "772   100XP Import matplotlib.pyplot and seaborn usi...\n",
       "774   100XP Modify the call to plt.scatter() to plot...\n",
       "776   100XP Plot a linear regression between 'weight...\n",
       "778   100XP Plot linear regressions of 'hp' (on the ...\n",
       "780   100XP In the first row of subplots, make a str...\n",
       "782   100XP In the first row of subplots, make a swa...\n",
       "784   100XP In the first row of subplots, make a vio...\n",
       "786   100XP Use sns.jointplot() to visualize the joi...\n",
       "788   100XP Create a hexbin plot of the joint distri...\n",
       "790   100XP Print the first five rows of the DataFra...\n",
       "792   100XP Plot the pairwise joint distributions se...\n",
       "794   100XP Print the covariance matrix cov_matrix t...\n",
       "797   100XP Plot the aapl time series in blue with a...\n",
       "799   100XP Plot the series aapl in 'blue' in the to...\n",
       "801   100XP Extract a slice named view from the seri...\n",
       "803   100XP Extract a slice of series aapl from Nove...\n",
       "805   100XP In the top left subplot, plot the 30-day...\n",
       "807   100XP Produce a single plot with four curves o...\n",
       "809   100XP Load data from the file '640px-Unequaliz...\n",
       "811   100XP First, use plt.hist() to plot the histog...\n",
       "813   100XP Use the NumPy array method .reshape() to...\n",
       "815   100XP Display image in the top subplot of a 2Ã—...\n",
       "817   100XP Make a 2-D histogram in the top left sub...\n",
       "820   100XP Import the create_engine function from t...\n",
       "822   100XP Define a select statement called stmt to...\n",
       "824                                               100XP\n",
       "828   100XP Build a statement to join the census and...\n",
       "830   100XP Build a statement to select ALL the colu...\n",
       "832   100XP Build a statement to select: The state c...\n",
       "836   100XP Save an alias of the employees table as ...\n",
       "838   100XP Use a while loop that checks if there ar...\n",
       "840   100XP Import Table, Column, String, Integer, F...\n",
       "842   100XP Table, Column, String, Integer, Float, B...\n",
       "844   100XP Import insert and select from the sqlalc...\n",
       "846   100XP Build a list of dictionaries called valu...\n",
       "848   100XP Create a statement for bulk insert into ...\n",
       "851   100XP Build a statement to select all columns ...\n",
       "853   100XP Build an update statement to update the ...\n",
       "855   100XP Build a statement to select the name col...\n",
       "858   100XP Import delete and select from sqlalchemy...\n",
       "861   100XP Build a delete statement to remove data ...\n",
       "863   100XP Drop the state_fact table by applying th...\n",
       "865   100XP Import create_engine and MetaData from s...\n",
       "867   100XP Import Table, Column, String, and Intege...\n",
       "869   100XP Create an empty list called values_list....\n",
       "871   100XP Import insert from sqlalchemy. Build an ...\n",
       "873   100XP Import select from sqlalchemy. Build a s...\n",
       "875   100XP Import case, cast and Float from sqlalch...\n",
       "877   100XP Build a statement to: Select state. Calc...\n",
       "885   100XP Print summary statistics of the numeric ...\n",
       "888   100XP Define the lambda function categorize_la...\n",
       "890   100XP Create the DataFrame num_unique_labels b...\n",
       "893   100XP Using the compute_log_loss() function, c...\n",
       "895   100XP Create a new DataFrame named numeric_dat...\n",
       "897   100XP Import LogisticRegression from sklearn.l...\n",
       "899   100XP Read HoldoutData.csv into a DataFrame ca...\n",
       "901   100XP Create the prediction_df DataFrame by sp...\n",
       "903   100XP Import CountVectorizer from sklearn.feat...\n",
       "905   100XP Use the .drop() method on data_frame wit...\n",
       "907   100XP Import CountVectorizer from sklearn.feat...\n",
       "909   100XP Import Pipeline from sklearn.pipeline. C...\n",
       "911   100XP Import CountVectorizer from sklearn.feat...\n",
       "913   100XP Compute the selector get_text_data by us...\n",
       "915   100XP In the process_and_join_features: Add th...\n",
       "917   100XP Complete the call to multilabel_train_te...\n",
       "919   100XP Complete the 'numeric_features' transfor...\n",
       "921   100XP Import the RandomForestClassifier from s...\n",
       "923   100XP Import the RandomForestClassifier from s...\n",
       "928   100XP Create text_vector by preprocessing X_tr...\n",
       "930   100XP Import CountVectorizer from sklearn.feat...\n",
       "934   100XP Add the interaction terms step using Spa...\n",
       "938   100XP Import HashingVectorizer from sklearn.fe...\n",
       "940   100XP Import HashingVectorizer from sklearn.fe...\n",
       "941   100xp As you saw in the video, loading data fr...\n",
       "943   100xp In this exercise, you'll combine the thr...\n",
       "945   0xp It is often useful to rearrange the sequen...\n",
       "947   100xp Sorting methods are not the only way to ...\n",
       "949   100xp Another common technique is to reindex a...\n",
       "952   100xp In this exercise, you'll work with weath...\n",
       "954   100xp Your job in this exercise is to compute ...\n",
       "961   100XP Create an empty list called units. This ...\n",
       "963   100XP Create a 'year' column in the DataFrames...\n",
       "965   100XP Create a new DataFrame called weather by...\n",
       "967   100XP Iterate over medal_types in the for loop...\n",
       "969   100XP Within the for loop: Read file_name into...\n",
       "971   100XP Create a new DataFrame medals_sorted wit...\n",
       "973                                               100XP\n",
       "976   100XP Create a list called month_list consisti...\n",
       "978   100XP Construct a list of DataFrames called me...\n",
       "980   100XP Make a new DataFrame china_annual by res...\n",
       "982   100XP Using pd.merge(), merge the DataFrames r...\n",
       "986   100XP Merge the DataFrames revenue and manager...\n",
       "988   100XP Create a column called 'state' in the Da...\n",
       "993   100XP Execute a right merge using pd.merge() w...\n",
       "995   100XP Merge sales_and_managers with revenue_an...\n",
       "997   100XP Perform an ordered merge on austin and h...\n",
       "999   100XP Merge auto and oil using pd.merge_asof()...\n",
       "1001  100XP Read file_path into a DataFrame called e...\n",
       "1003  100XP Read file_path into a DataFrame called i...\n",
       "1005  100XP Within the for loop: Create the file pat...\n",
       "1007  0XP Construct a pivot table from the DataFrame...\n",
       "1009  100XP Set the index of the DataFrame editions ...\n",
       "1011  100XP Create mean_fractions by chaining the me...\n",
       "1013  0XP Create the DataFrame hosts by doing a left...\n",
       "1015  100XP Create a DataFrame reshaped by reshaping...\n",
       "1017  100XP Merge reshaped and hosts using an inner ...\n",
       "1019  100XP Create a Series called change by extract...\n",
       "1021  100xp Now you'll get a chance to write some re...\n",
       "1022  100xp Here, you'll be using the first scene of...\n",
       "1023  0xp In this exercise, you'll utilize re.search...\n",
       "1024  50xp Given the following string, which is the ...\n",
       "1025  100xp Twitter is a frequently used source for ...\n",
       "1026  0xp In this exercise, you'll practice advanced...\n",
       "1027  100xp Try using your new skills to find and ch...\n",
       "1028  100xp In this exercise, you'll build your firs...\n",
       "1030  100xp Now, it's your turn to apply the techniq...\n",
       "1032  100xp It's time to apply the methods you learn...\n",
       "1034  100xp Now, you'll use your new gensim corpus a...\n",
       "1038  100xp You're now going to have some fun with n...\n",
       "1040  100xp In this exercise, you'll use some extrac...\n",
       "1042  100xp Using the same text you used in the firs...\n",
       "1044  100xp In this exercise and the next, you'll us...\n",
       "1046  0xp Here, you'll complete the work you began i...\n",
       "1048  100xp You'll continue your exploration of poly...\n",
       "1050  100xp In the final exercise of this NER chapte...\n",
       "1052  100xp It's time to begin building your text cl...\n",
       "1054  100xp Similar to the sparse CountVectorizer cr...\n",
       "1056  100xp To get a better idea of how the vectors ...\n",
       "1062  100xp Now it's your turn to train the \"fake ne...\n",
       "1064  100xp Now that you have evaluated the model us...\n",
       "1066  100xp Your job in this exercise is to test a f...\n",
       "1068  100xp Now that you have built a \"fake news\" cl...\n",
       "1073  100XP Import matplotlib.pyplot as plt and netw...\n",
       "1075  100XP Use a list comprehension to get a list o...\n",
       "1078  100XP Set the 'weight' attribute of the edge b...\n",
       "1080  100XP Define a function called find_selfloop_n...\n",
       "1082  100XP Import nxviz as nv. Plot the graph T as ...\n",
       "1084  100XP Import CircosPlot from nxviz. Plot the T...\n",
       "1086  100XP Import ArcPlot from nxviz. Create an un-...\n",
       "1088  100XP Write a function called nodes_with_m_nbr...\n",
       "1090  100XP Use a list comprehension along with the ...\n",
       "1092  100XP Compute the degree centrality of the Twi...\n",
       "1094  100XP Create a function called path_exists() t...\n",
       "1096  100XP Using the .add() method, add the current...\n",
       "1098  100XP Check to see if the queue has been empti...\n",
       "1100  100XP Compute the betweenness centrality bet_c...\n",
       "1102  100XP Write a function find_nodes_with_highest...\n",
       "1104  100XP Write a function find_node_with_highest_...\n",
       "1106  100XP Import combinations from itertools. Writ...\n",
       "1108  100XP Write a function nodes_in_triangle() tha...\n",
       "1110  100XP Write a function node_in_open_triangle()...\n",
       "1112  100XP Write a function maximal_cliques() that ...\n",
       "1114  100XP Write a function get_nodes_and_nbrs(G, n...\n",
       "1116  100XP Using a list comprehension, extract node...\n",
       "1118  100XP Plot the degree distribution of the GitH...\n",
       "1120  100XP Plot the betweenness centrality distribu...\n",
       "1122  100XP Make a MatrixPlot visualization of the l...\n",
       "1124  100XP Make an ArcPlot of the GitHub collaborat...\n",
       "1126  100XP Make a CircosPlot of the network, again,...\n",
       "1128  100XP Count the number of maximal cliques pres...\n",
       "1130  100XP Find the author(s) that are part of the ...\n",
       "1133  100XP Go out 1 degree of separation from the c...\n",
       "1135  100XP Compile a list of GitHub users that shou...\n",
       "1136  100xp Pandas depends upon and interoperates wi...\n",
       "1138  100xp In this exercise, you're going to make a...\n",
       "1139  100xp You can use the DataFrame attribute df.c...\n",
       "1140  100xp You can implicitly use 'broadcasting', a...\n",
       "1141  100xp In previous exercises, we have preloaded...\n",
       "1142  100xp Not all data files are clean and tidy. P...\n",
       "1143  100xp Data visualization is often a very effec...\n",
       "1144  100xp Comparing data from several columns can ...\n",
       "1145  100xp In the previous chapter, you saw that th...\n",
       "1146  100xp Pandas scatter plots are generated using...\n",
       "1147  100xp While pandas can plot multiple columns o...\n",
       "1148  100xp Pandas relies on the .hist() method to n...\n",
       "1150  100xp In this exercise, you will investigate s...\n",
       "1152  100xp In many data sets, there can be large di...\n",
       "1153  100xp In this exercise, you'll investigate the...\n",
       "1154  100xp Let's use the mean and standard deviatio...\n",
       "1155  50xp How many automobiles were manufactured in...\n",
       "1157  100xp Let's use population filtering to determ...\n",
       "1158  100xp Population filtering can be used alongsi...\n",
       "1159  100xp Pandas time series support \"partial stri...\n",
       "1161  100xp Reindexing is useful in preparation for ...\n",
       "1163  100xp Pandas provides methods for resampling t...\n",
       "1165  100xp With pandas, you can resample in differe...\n",
       "1167  100xp In this exercise, some hourly weather da...\n",
       "1169  100xp As of pandas version 0.18.0, the interfa...\n",
       "1171  100xp We've seen that pandas supports method c...\n",
       "1173  100xp One common application of interpolation ...\n",
       "1175  0xp Time zone handling with pandas typically a...\n",
       "1177  100xp Pandas handles datetimes not only in you...\n",
       "1179  100xp Now that you have set the DatetimeIndex ...\n",
       "1181  100xp Now that you have identified the method ...\n",
       "1183  100xp After the initial step of reading in the...\n",
       "1185  0xp In order to use the full power of pandas t...\n",
       "1187  100xp The numeric columns contain missing valu...\n",
       "1189  100xp Now that you have the data read and clea...\n",
       "1191  0xp You're now ready to compare the 2011 weath...\n",
       "1193  100xp On average, how much hotter is it when t...\n",
       "1195  100xp Is there a correlation between temperatu...\n",
       "1197  100xp In a previous exercise, you analyzed the...\n",
       "1199  100xp Dew point is a measure of relative humid...\n",
       "1201  100xp We already know that 2011 was hotter tha...\n",
       "1203  100xp Let's work more on your mastery of scope...\n",
       "1204  0xp You've learned in the last video about nes...\n",
       "1206  100xp Great job, you've just nested a function...\n",
       "1208  100xp Let's once again work further on your ma...\n",
       "1210  100xp In the previous chapter, you've learned ...\n",
       "1212  100xp You've now defined a function that uses ...\n",
       "1214  100xp Flexible arguments enable you to pass a ...\n",
       "1216  100xp Let's push further on what you've learne...\n",
       "1218  100xp Recall the Bringing it all together exer...\n",
       "1220  100xp Wow, you've just generalized your Twitte...\n",
       "1222  100xp Some function definitions are simple eno...\n",
       "1224  100xp So far, you've used lambda functions to ...\n",
       "1227  100xp In the previous exercise, you used lambd...\n",
       "1228  100xp You're getting very good at using lambda...\n",
       "1231  100xp A good practice in writing your own func...\n",
       "1232  100xp Another way to raise an error is by usin...\n",
       "1233  100xp This is awesome! You have now learned ho...\n",
       "1234  100xp Sometimes, we make mistakes when calling...\n",
       "1235  100xp In the previous exercise, you built on y...\n",
       "1236  100xp Great, you're familiar with what iterabl...\n",
       "1238  100xp One of the things you learned about in t...\n",
       "1241  100xp You've been using the iter() function to...\n",
       "1243  100xp You're really getting the hang of using ...\n",
       "1245  100xp Another interesting function that you've...\n",
       "1247  100xp You know how to use zip() as well as how...\n",
       "1249  100xp Sometimes, the data we have to process r...\n",
       "1251  100xp Great job chunking out that file in the ...\n",
       "1253  100xp You now have all the knowledge necessary...\n",
       "1255  100xp Great! At this point, you have a good gr...\n",
       "1258  0xp You've been using list comprehensions to b...\n",
       "1260  100xp In the previous exercise, you used an if...\n",
       "1262  100xp Comprehensions aren't relegated merely t...\n",
       "1264  100xp You are familiar with what generators an...\n",
       "1266  100xp Great! At this point, you already know h...\n",
       "1268  100xp In previous exercises, you've dealt main...\n",
       "1270  0xp You will now make use of what you've learn...\n",
       "1272  100xp Great, you've successfully extracted the...\n",
       "1274  0xp For this exercise, you'll use what you've ...\n",
       "1276  100xp Suppose you needed to repeat the same pr...\n",
       "1278  100xp This time, you're going to use the lists...\n",
       "1280  100xp You've zipped lists together, created a ...\n",
       "1282  100xp Sometimes, data sources can be so large ...\n",
       "1284  100xp In the previous exercise, you processed ...\n",
       "1286  100xp Great! You've just created a generator f...\n",
       "1288  100xp Another way to read data too large to st...\n",
       "1290  100xp In the previous exercise, you used read_...\n",
       "1292  100xp You're getting used to reading and proce...\n",
       "1294  100xp In the previous exercises, you've only p...\n",
       "1296  100xp This is the last leg. You've learned a l...\n",
       "1300  100XP Seed the random number generator with 42...\n",
       "1302  100XP Compute an ECDF from the actual time bet...\n",
       "1306  100XP Plot fertility (y-axis) versus illiterac...\n",
       "1308  100XP Compute the slope and intercept of the r...\n",
       "1310  100XP Specify the values of the slope for whic...\n",
       "1312  100XP Compute the parameters for the slope and...\n",
       "1314  100XP Write a for loop to do the following for...\n",
       "1316  100XP Write a for loop to acquire 50 bootstrap...\n",
       "1318  100XP Define a function with call signature dr...\n",
       "1320  100XP Draw 10000 bootstrap replicates of the m...\n",
       "1322  100XP Draw 10000 bootstrap replicates of the v...\n",
       "1324  100XP Generate 10000 bootstrap replicates of Ï„...\n",
       "1326  100XP Define a function with call signature dr...\n",
       "1328  100XP Use your draw_bs_pairs_linreg() function...\n",
       "1330  100XP Generate an array of xx-values consistin...\n",
       "1332  100XP Concatenate the two input arrays into on...\n",
       "1334  100XP Write a for loop to 50 generate permutat...\n",
       "1337  100XP Define a function with this signature: d...\n",
       "1339  100XP Use sns.swarmplot() to make a bee swarm ...\n",
       "1341  100XP Define a function with call signature di...\n",
       "1343  100XP Translate the impact forces of Frog B su...\n",
       "1345  100XP Compute the observed difference in impac...\n",
       "1347  100XP Compute the mean of all forces (from for...\n",
       "1349  100XP Construct Boolean arrays, dems and reps ...\n",
       "1351  100XP Compute the observed difference in mean ...\n",
       "1355  100XP Compute the observed Pearson correlation...\n",
       "1357  100XP Use your ecdf() function to generate x,y...\n",
       "1359  100XP Compute the mean alive sperm count of co...\n",
       "1361  100XP Label the axes. Don't forget that you sh...\n",
       "1363  100XP Import numpy as np. This gives access to...\n",
       "1365  100XP Use ecdf() to compute the ECDF of versic...\n",
       "1368  100XP Define a function with the signature ecd...\n",
       "1370  100XP Compute ECDFs for each of the three spec...\n",
       "1372  100XP Compute the mean petal length of Iris ve...\n",
       "1374  100XP Plot the percentiles as red diamonds on ...\n",
       "1376  100XP The set-up is exactly the same as for th...\n",
       "1379  100XP Create an array called differences that ...\n",
       "1381  100XP Compute the variance of the data in the ...\n",
       "1383  100XP Use plt.plot() with the appropriate keyw...\n",
       "1385  100XP Use np.cov() to compute the covariance m...\n",
       "1387  100XP Define a function with signature pearson...\n",
       "1389  100XP Seed the random number generator using t...\n",
       "1391  100XP Define a function with signature perform...\n",
       "1393  100XP Seed the random number generator to 42. ...\n",
       "1395  100XP Compute the x and y values for the ECDF ...\n",
       "1397  100XP Draw samples out of the Binomial distrib...\n",
       "1399  100XP Using np.arange(), compute the bin edges...\n",
       "1401  100XP Using the np.random.poisson() function, ...\n",
       "1403  100XP Draw 10000 samples from a Poisson distri...\n",
       "1406  100XP Use your ecdf() function to generate x a...\n",
       "1408  100XP Compute mean and standard deviation of B...\n",
       "1410  100XP Take 1,000,000 samples from the normal d...\n",
       "1412  100XP Define a function with call signature su...\n",
       "1414  100XP Use your successive_poisson() function t...\n",
       "1415  100xp In this chapter, you'll be working with ...\n",
       "1421  50xp The Numerical EDA you did in the previous...\n",
       "1423  0xp Having explored the Congressional voting r...\n",
       "1425  0xp Having fit a k-NN classifier, you can now ...\n",
       "1426  100xp Up until now, you have been performing b...\n",
       "1428  100xp Now that you have learned about the impo...\n",
       "1430  100xp Remember the model complexity curve that...\n",
       "1432  100xp In this chapter, you will work with Gapm...\n",
       "1434  100xp Now, you will fit a linear regression an...\n",
       "1436  100xp As you learned in Chapter 1, train and t...\n",
       "1438  100xp Cross-validation is a vital step in eval...\n",
       "1440  100xp Cross validation is essential but do not...\n",
       "1443  0xp In the video, you saw how Lasso selected o...\n",
       "1445  100xp Lasso is great for feature selection, bu...\n",
       "1448  100xp In Chapter 1, you evaluated the performa...\n",
       "1450  100xp Time to build your first logistic regres...\n",
       "1452  100xp Great job in the previous exercise - you...\n",
       "1454  100xp Say you have a binary classifier that in...\n",
       "1456  100xp Hugo demonstrated how to use to tune the...\n",
       "1458  100xp GridSearchCV can be computationally expe...\n",
       "1460  100xp You will now practice evaluating a model...\n",
       "1462  100xp Remember lasso and ridge regression from...\n",
       "1464  0xp The Gapminder dataset that you worked with...\n",
       "1466  100xp As Andy discussed in the video, scikit-l...\n",
       "1468  100xp Having created the dummy variables from ...\n",
       "1470  100xp The voting dataset from Chapter 1 contai...\n",
       "1472  100xp As you've come to appreciate, there are ...\n",
       "1474  100xp Having setup the steps of the pipeline i...\n",
       "1476  100xp In the video, Hugo demonstrated how sign...\n",
       "1478  100xp With regard to whether or not scaling is...\n",
       "1480  100xp It is time now to piece together everyth...\n",
       "1482  100xp For this final exercise, you will return...\n",
       "1486  100XP Import: matplotlib.pyplot as plt. pearso...\n",
       "1488  100XP Import PCA from sklearn.decomposition. C...\n",
       "1492  100XP Make a scatter plot of the grain measure...\n",
       "1494  100XP Create an instance of StandardScaler cal...\n",
       "1498  100XP Import PCA from sklearn.decomposition. C...\n",
       "1500  100XP Import TfidfVectorizer from sklearn.feat...\n",
       "1502  100XP Import: TruncatedSVD from sklearn.decomp...\n",
       "1504  100XP Import pandas as pd. Fit the pipeline to...\n",
       "1507  100XP Import NMF from sklearn.decomposition. C...\n",
       "1509  100XP Import pandas as pd. Create a DataFrame ...\n",
       "1512  100XP Import pandas as pd. Create a DataFrame ...\n",
       "1514  100XP Import matplotlib.pyplot as plt. Select ...\n",
       "1517  100XP Import NMF from sklearn.decomposition. C...\n",
       "1519  100XP Import PCA from sklearn.decomposition. C...\n",
       "1522  100XP Import: NMF from sklearn.decomposition. ...\n",
       "1524  100XP Import pandas as pd. Create a DataFrame ..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions = []\n",
    "# loop through DataFrame using iterrows()\n",
    "for index, row in df[df_1].iterrows():\n",
    "    if True:\n",
    "        #print(row['Questions'])\n",
    "        questions.append(row)\n",
    "        #df.drop(row, axis=0)\n",
    "        #df\n",
    "# convert lists to DataFrames\n",
    "questions = pd.DataFrame(questions).dropna()\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23a10a4a-bc2c-42ec-8802-f0cfb4d5fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32277751-ffad-4c45-86e9-c392cd4399f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50xp In this chapter, you're going to look at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50xp In the previous exercise, you identified ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100xp As you've seen, .describe() can only be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100xp Up until now, you've been looking at des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100xp Histograms are great ways of visualizing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100xp Boxplots are great when you have a numer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100xp Melting data is the process of turning c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100xp When melting DataFrames, it would be bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100xp Pivoting data is the opposite of melting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100xp After pivoting airquality_melt in the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100xp The dataset you saw in the video, consis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100xp Another common way multiple variables ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100xp The dataset you'll be working with here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100xp Think of column-wise concatenation of da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100xp You're now going to practice using the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>100xp Now that you have a list of filenames to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>100xp Merging data allows you to combine dispa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>100xp In a many-to-one (or one-to-many) merge,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>100xp The final merging scenario occurs when b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>100xp In this exercise, you'll see how ensurin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>100xp If you expect the data type of a column ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>100xp In the video, Dan introduced you to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>100xp Extracting numbers from strings is a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>100xp In this exercise, you'll continue practi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>100xp You'll now practice writing functions to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>100xp You'll now be introduced to a powerful P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>100xp Duplicate data causes a variety of probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>100xp Here, you'll return to the airquality da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0xp Here, you'll practice writing assert state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>100xp In this exercise, you'll write code to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0xp As Dan explained to you in the video, an \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>100xp You'll now define a function called pred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>100xp In this exercise, you'll write code to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>100xp Now you'll get to change weights in a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>100xp You've seen how different weights will h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>100xp You're now going to practice calculating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>100xp Hurray! You've just calculated the slope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>100xp You're now going to make multiple update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>100xp Now you'll get to work with your first m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>100xp You're now going to compile the model yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>100xp You're at the most fun part. You'll now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>100xp You'll now create a classification model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>100xp The trained network from your previous c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>100xp It's time to get your hands dirty with o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>100xp Now it's your turn to monitor model accu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>100xp Now that you know how to monitor your mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0xp Now you know everything you need to begin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100xp You've seen how to experiment with wider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0xp You've reached the final exercise of the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>100xp In this exercise, you'll be working with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>100xp For large files, we may not want to prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>100xp In this exercise, you're now going to lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>100xp What if there are rows, such as a header...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>100xp The file seaslug.txt has a text header, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>100xp You have just used np.genfromtxt() to im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>100xp In the last exercise, you were able to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>100xp The pandas package is also great at deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>100xp There are a number of datatypes that can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>100xp Whether you like it or not, any working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>100xp In the previous exercises, you saw that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>100xp Here, you'll parse your spreadsheets and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>100xp Here, you'll gain expertise in importing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>100xp The file 'LIGO_data.hdf5' is already in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>100xp In this exercise, you'll extract some of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>100xp Here, you'll discover what is in the MAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>100xp Here, you're going to fire up your very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>100xp In this exercise, you'll once again crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0xp Now, it's time for liftoff! In this exerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>100xp Congratulations on executing your first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>100xp You can now execute a basic SQL query to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>100xp You can also order your SQL query result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>100xp Here, you'll become more familiar with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>100xp Here, you'll perform your first INNER JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>100xp Congrats on performing your first INNER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>100xp In this exercise, you'll be working with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>100xp For large files, we may not want to prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>100xp In this exercise, you're now going to lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>100xp What if there are rows, such as a header...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>100xp The file seaslug.txt has a text header, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>100xp You have just used np.genfromtxt() to im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>100xp In the last exercise, you were able to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>100xp The pandas package is also great at deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>100xp There are a number of datatypes that can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>100xp Whether you like it or not, any working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>100xp In the previous exercises, you saw that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>100xp Here, you'll parse your spreadsheets and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>100xp Here, you'll gain expertise in importing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>100xp The file 'LIGO_data.hdf5' is already in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>100xp In this exercise, you'll extract some of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>100xp Here, you'll discover what is in the MAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>100xp Here, you're going to fire up your very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>100xp In this exercise, you'll once again crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0xp Now, it's time for liftoff! In this exerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>100xp Congratulations on executing your first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>100xp You can now execute a basic SQL query to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>100xp You can also order your SQL query result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>100xp Here, you'll become more familiar with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>100xp Here, you'll perform your first INNER JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>100xp Congrats on performing your first INNER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>100xp You are about to import your first file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>100xp You have just imported a file from the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>100xp Congrats! You've just loaded a flat file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>100xp Now that you know the basics behind HTTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>100xp You have just packaged and sent a GET re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>100xp Now that you've got your head and hands ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>100xp In this interactive exercise, you'll lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>100xp As promised, in the following exercises,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0xp Now that you know what a JSON is, you'll l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>100xp Now it's your turn to pull some movie da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>100xp Wow, congrats! You've just queried your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>100xp You're doing so well and having so much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>100xp The package tweepy is great at handling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>100xp Now that you have set up your authentica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>100xp Now that you've got your Twitter data si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>100xp Now you have the Twitter data in a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>100xp Now that you have your DataFrame of twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>100xp Now that you have the number of tweets t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>100XP Import the figure function from bokeh.pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>100XP Create the figure p with the figure() fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>100XP Using the Latin America data (fertility_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>100XP Import the figure function from bokeh.pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>100XP Plot date along the x-axis and price alo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>100XP Create a list of the longitude positions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>100XP Import numpy as np. Create an array x us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>100XP Import pandas as pd. Use the read_csv() ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>100XP Import the ColumnDataSource class from b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>100XP Create a figure p with an x-axis label o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>100XP Import HoverTool from bokeh.models. Add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>100XP Import CategoricalColorMapper from bokeh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>100XP Import row from the bokeh.layouts module...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>100XP Import column from the bokeh.layouts mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>100XP Import row and column from bokeh.layouts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>100XP Import gridplot from the bokeh.layouts m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>100XP Import Panel from bokeh.models.widgets. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>100XP Import Tabs from bokeh.models.widgets. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>100XP Link the x_range of p2 to p1. Link the y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>100XP Create a ColumnDataSource object called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>100XP Add a red circle glyph to the figure p u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>100XP Use p.legend.location to adjust the lege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>100XP Import the HoverTool class from bokeh.mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>100XP Import curdoc from bokeh.io and figure f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>100XP Import curdoc from bokeh.io, widgetbox f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>100XP Create the first slider, slider1, using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>100XP Create a ColumnDataSource called source....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>100XP Define a callback function callback with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>100XP Define a callback function called update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>100XP Create select1, the first dropdown selec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0XP Create a button called button using the fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>100XP Import CheckboxGroup, RadioGroup, Toggle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>100XP Import output_file and show from bokeh.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>100XP Make a ColumnDataSource object called so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>100XP Make a list of the unique values from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>100XP Import the widgetbox and row functions f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>100XP Define the update_plot callback function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>100XP Import HoverTool from bokeh.models. Crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>100XP Inside the update_plot() callback functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>100xp With matplotlib, you can create a bunch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>100xp Now that you've built your first line pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>100xp When you have a time scale along the hor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>100xp In the previous exercise, you saw that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>100xp life_exp, the list containing data on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>100xp In the previous exercise, you didn't spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>100xp It's time to customize your own plot. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>100xp The customizations you've coded up to no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>100xp Right now, the scatter plot is just a cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>100xp The code you've written up to now is ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>100xp If you have another look at the script, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>100xp To see why dictionaries are useful, have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>100xp The countries and capitals lists are aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>100xp If the keys of a dictionary are chosen w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0xp If you know how to access a dictionary, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>100xp Somebody thought it would be funny to me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>100xp Remember lists? They could contain anyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>100xp Pandas is an open source library, provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>100xp The Python code that solves the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>100xp Putting data in a dictionary and then bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>100xp Your read_csv() call to import the CSV d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>100xp In the video, you saw that you can index...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>100xp Square brackets can do more than just se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>100xp With loc and iloc you can do practically...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>100xp loc and iloc also allow you to select bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>100xp It's also possible to select only column...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>100xp To check if two Python values, or variab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>100xp In the video, Filip also talked about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>100xp Out of the box, you can also use compari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>100xp A boolean is either 1 or 0, True or Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>100xp It's time to take a closer look around i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>100xp On the right, the if construct for room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>100xp It's also possible to have a look around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>100xp Remember that cars dataset, containing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>100xp The code in the previous example worked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>100xp Let's stick to the cars data some more. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>100xp Remember about np.logical_and(), np.logi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>100xp Below you can find the example from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>100xp The while loop that corrects the offset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>100xp Have another look at the for loop that F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>100xp Using a for loop to iterate over a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>100xp For non-programmer folks, room 0: 11.25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>100xp Remember the house variable from the Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>100xp In Python 3, you need the items() method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>100xp If you're dealing with a 1D Numpy array,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>100xp Iterating over a Pandas DataFrame is typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>100xp The row data that's generated by iterrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0xp In the video, Filip showed you how to add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>100xp Using iterrows() to iterate over every o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>100xp Below you can find the example from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>100xp The while loop that corrects the offset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>100xp Have another look at the for loop that F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>100xp Using a for loop to iterate over a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>100xp For non-programmer folks, room 0: 11.25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>100xp Remember the house variable from the Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>100xp In Python 3, you need the items() method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>100xp If you're dealing with a 1D Numpy array,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>100xp Iterating over a Pandas DataFrame is typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>100xp The row data that's generated by iterrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0xp In the video, Filip showed you how to add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>100xp Using iterrows() to iterate over every o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>100xp Randomness has many uses in science, art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>100xp In the previous exercise, you used rand(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>100xp In the Empire State Building bet, your n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>100xp Before, you have already written Python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>0xp Things are shaping up nicely! You already ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>100xp Let's visualize this random walk! Rememb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>100xp A single random walk is one thing, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>100xp all_walks is a list of lists: every sub-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>100xp With this neatly written code of yours, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>100xp All these fancy visualizations have put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>100xp Subsetting Python lists is a piece of ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>50xp You saw before that a Python list can con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>100xp Replacing list elements is pretty easy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>100xp If you can change elements in a list, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>100xp Out of the box, Python offers a bunch of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>50xp Maybe you already know the name of a Pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>100xp In the previous exercise, the square bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>100xp Strings come with a bunch of methods. Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>100xp Strings are not the only Python types th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>100xp Most list methods will change the list t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>100xp As a data scientist, some notions of geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>100xp General imports, like import math, make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>50xp There are several ways to import packages...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>100xp We're going to dive into the world of ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>100xp You are a huge baseball fan. You decide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>100xp The MLB also offers to let you analyze t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>100xp To subset both regular Python lists and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>100xp You've seen it with your own eyes: Pytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>100xp Before working on the actual MLB data, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>100xp You have another look at the MLB data an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>100xp If your 2D Numpy array has a regular str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>100xp Remember how you calculated the Body Mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>100xp You now know how to use Numpy functions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0xp Because the mean and median are so far apa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>100xp In the last few exercises you've learned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0XP Import create_engine from the sqlalchemy m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>100XP Import the Table object from sqlalchemy....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>100XP Reflect the census table as you did in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>100XP Build a SQL statement to query all the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>100XP Import select from the sqlalchemy module...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>100XP Extract the first row of results and ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>50XP Import create_engine from sqlalchemy. Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>100XP Select all records from the census table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>100XP Select all records from the census table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>100XP Import and_ from the sqlalchemy module. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>100XP Select all records of the state column f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>100XP Import desc from the sqlalchemy module. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>100XP Select all records of the state and age ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>100XP Build a select statement to count the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>100XP Import func from sqlalchemy. Build an ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>100XP Import matplotlib.pyplot as plt. Create ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>100XP Import the create_engine function from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>100XP Define a select statement called stmt to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>100XP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>100XP Build a statement to join the census and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>100XP Build a statement to select ALL the colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>100XP Build a statement to select: The state c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>100XP Save an alias of the employees table as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>100XP Use a while loop that checks if there ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>100XP Import Table, Column, String, Integer, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>100XP Table, Column, String, Integer, Float, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>100XP Import insert and select from the sqlalc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>100XP Build a list of dictionaries called valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>100XP Create a statement for bulk insert into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>100XP Build a statement to select all columns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>707</th>\n",
       "      <td>100XP Build an update statement to update the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>100XP Build a statement to select the name col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>100XP Import delete and select from sqlalchemy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>100XP Build a delete statement to remove data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>100XP Drop the state_fact table by applying th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>100XP Import create_engine and MetaData from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>100XP Import Table, Column, String, and Intege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>100XP Create an empty list called values_list....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>100XP Import insert from sqlalchemy. Build an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>100XP Import select from sqlalchemy. Build a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>100XP Import case, cast and Float from sqlalch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>100XP Build a statement to: Select state. Calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>100XP Import matplotlib.pyplot as its usual al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>100XP Create a set of plot axes with lower cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>100XP Use plt.subplot() to create a figure wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>100XP Create a figure with 2Ã—22Ã—2 subplot layo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>100XP Use plt.xlim() to set the x-axis range t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>100XP Use plt.axis() to select the time period...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>100XP Modify the plot command provided that dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>100XP Compute the maximum enrollment of women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>100XP Import matplotlib.pyplot as its usual al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>100XP Import the numpy and matplotlib.pyplot m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>100XP Using the meshgrid X, Y as axes: Generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>100XP Modify the call to plt.contourf() so the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>100XP Generate a two-dimensional histogram to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>100XP Generate a two-dimensional histogram wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>100XP Load the file '480px-Astronaut-EVA.jpg' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>100XP Print the shape of the existing image ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>100XP Display img in the top left subplot with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>100XP Use the methods .min() and .max() to sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>100XP Import matplotlib.pyplot and seaborn usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>100XP Import matplotlib.pyplot and seaborn usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>100XP Modify the call to plt.scatter() to plot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>100XP Plot a linear regression between 'weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>100XP Plot linear regressions of 'hp' (on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>100XP In the first row of subplots, make a str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>100XP In the first row of subplots, make a swa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>100XP In the first row of subplots, make a vio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>100XP Use sns.jointplot() to visualize the joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>100XP Create a hexbin plot of the joint distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>100XP Print the first five rows of the DataFra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>100XP Plot the pairwise joint distributions se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>100XP Print the covariance matrix cov_matrix t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>100XP Plot the aapl time series in blue with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>100XP Plot the series aapl in 'blue' in the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>100XP Extract a slice named view from the seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>100XP Extract a slice of series aapl from Nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>100XP In the top left subplot, plot the 30-day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>100XP Produce a single plot with four curves o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>100XP Load data from the file '640px-Unequaliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>100XP First, use plt.hist() to plot the histog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>100XP Use the NumPy array method .reshape() to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>100XP Display image in the top subplot of a 2Ã—...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>100XP Make a 2-D histogram in the top left sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>100XP Import the create_engine function from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>100XP Define a select statement called stmt to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824</th>\n",
       "      <td>100XP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>100XP Build a statement to join the census and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>100XP Build a statement to select ALL the colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832</th>\n",
       "      <td>100XP Build a statement to select: The state c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>100XP Save an alias of the employees table as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>100XP Use a while loop that checks if there ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>100XP Import Table, Column, String, Integer, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>100XP Table, Column, String, Integer, Float, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>100XP Import insert and select from the sqlalc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>100XP Build a list of dictionaries called valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>100XP Create a statement for bulk insert into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>100XP Build a statement to select all columns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>100XP Build an update statement to update the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>100XP Build a statement to select the name col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>100XP Import delete and select from sqlalchemy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>100XP Build a delete statement to remove data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>100XP Drop the state_fact table by applying th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>100XP Import create_engine and MetaData from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>100XP Import Table, Column, String, and Intege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>100XP Create an empty list called values_list....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>100XP Import insert from sqlalchemy. Build an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>100XP Import select from sqlalchemy. Build a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>100XP Import case, cast and Float from sqlalch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>100XP Build a statement to: Select state. Calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>100XP Print summary statistics of the numeric ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>100XP Define the lambda function categorize_la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>100XP Create the DataFrame num_unique_labels b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>100XP Using the compute_log_loss() function, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>100XP Create a new DataFrame named numeric_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>100XP Import LogisticRegression from sklearn.l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>100XP Read HoldoutData.csv into a DataFrame ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>100XP Create the prediction_df DataFrame by sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>100XP Use the .drop() method on data_frame wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>100XP Import Pipeline from sklearn.pipeline. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>100XP Compute the selector get_text_data by us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>100XP In the process_and_join_features: Add th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>100XP Complete the call to multilabel_train_te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>100XP Complete the 'numeric_features' transfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>100XP Import the RandomForestClassifier from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>100XP Import the RandomForestClassifier from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>100XP Create text_vector by preprocessing X_tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>100XP Add the interaction terms step using Spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>100XP Import HashingVectorizer from sklearn.fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>100XP Import HashingVectorizer from sklearn.fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>100xp As you saw in the video, loading data fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943</th>\n",
       "      <td>100xp In this exercise, you'll combine the thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>945</th>\n",
       "      <td>0xp It is often useful to rearrange the sequen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>100xp Sorting methods are not the only way to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>949</th>\n",
       "      <td>100xp Another common technique is to reindex a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>952</th>\n",
       "      <td>100xp In this exercise, you'll work with weath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>100xp Your job in this exercise is to compute ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>100XP Create an empty list called units. This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>100XP Create a 'year' column in the DataFrames...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>100XP Create a new DataFrame called weather by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>967</th>\n",
       "      <td>100XP Iterate over medal_types in the for loop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>100XP Within the for loop: Read file_name into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>100XP Create a new DataFrame medals_sorted wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>100XP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>100XP Create a list called month_list consisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>100XP Construct a list of DataFrames called me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>100XP Make a new DataFrame china_annual by res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>100XP Using pd.merge(), merge the DataFrames r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>100XP Merge the DataFrames revenue and manager...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>100XP Create a column called 'state' in the Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>100XP Execute a right merge using pd.merge() w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>100XP Merge sales_and_managers with revenue_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>100XP Perform an ordered merge on austin and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>100XP Merge auto and oil using pd.merge_asof()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>100XP Read file_path into a DataFrame called e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>100XP Read file_path into a DataFrame called i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>100XP Within the for loop: Create the file pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>0XP Construct a pivot table from the DataFrame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>100XP Set the index of the DataFrame editions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>100XP Create mean_fractions by chaining the me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>0XP Create the DataFrame hosts by doing a left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>100XP Create a DataFrame reshaped by reshaping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>100XP Merge reshaped and hosts using an inner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>100XP Create a Series called change by extract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>100xp Now you'll get a chance to write some re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>100xp Here, you'll be using the first scene of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>0xp In this exercise, you'll utilize re.search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>50xp Given the following string, which is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>100xp Twitter is a frequently used source for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>0xp In this exercise, you'll practice advanced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>100xp Try using your new skills to find and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>100xp In this exercise, you'll build your firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>100xp Now, it's your turn to apply the techniq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>100xp It's time to apply the methods you learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>100xp Now, you'll use your new gensim corpus a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>100xp You're now going to have some fun with n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1040</th>\n",
       "      <td>100xp In this exercise, you'll use some extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1042</th>\n",
       "      <td>100xp Using the same text you used in the firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>100xp In this exercise and the next, you'll us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>0xp Here, you'll complete the work you began i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>100xp You'll continue your exploration of poly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>100xp In the final exercise of this NER chapte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>100xp It's time to begin building your text cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>100xp Similar to the sparse CountVectorizer cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>100xp To get a better idea of how the vectors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>100xp Now it's your turn to train the \"fake ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>100xp Now that you have evaluated the model us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>100xp Your job in this exercise is to test a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>100xp Now that you have built a \"fake news\" cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>100XP Import matplotlib.pyplot as plt and netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>100XP Use a list comprehension to get a list o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>100XP Set the 'weight' attribute of the edge b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>100XP Define a function called find_selfloop_n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1082</th>\n",
       "      <td>100XP Import nxviz as nv. Plot the graph T as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>100XP Import CircosPlot from nxviz. Plot the T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>100XP Import ArcPlot from nxviz. Create an un-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>100XP Write a function called nodes_with_m_nbr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>100XP Use a list comprehension along with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>100XP Compute the degree centrality of the Twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>100XP Create a function called path_exists() t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>100XP Using the .add() method, add the current...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098</th>\n",
       "      <td>100XP Check to see if the queue has been empti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>100XP Compute the betweenness centrality bet_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>100XP Write a function find_nodes_with_highest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>100XP Write a function find_node_with_highest_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>100XP Import combinations from itertools. Writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>100XP Write a function nodes_in_triangle() tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>100XP Write a function node_in_open_triangle()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>100XP Write a function maximal_cliques() that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>100XP Write a function get_nodes_and_nbrs(G, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1116</th>\n",
       "      <td>100XP Using a list comprehension, extract node...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>100XP Plot the degree distribution of the GitH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>100XP Plot the betweenness centrality distribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1122</th>\n",
       "      <td>100XP Make a MatrixPlot visualization of the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>100XP Make an ArcPlot of the GitHub collaborat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>100XP Make a CircosPlot of the network, again,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>100XP Count the number of maximal cliques pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>100XP Find the author(s) that are part of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>100XP Go out 1 degree of separation from the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>100XP Compile a list of GitHub users that shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>100xp Pandas depends upon and interoperates wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>100xp In this exercise, you're going to make a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>100xp You can use the DataFrame attribute df.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>100xp You can implicitly use 'broadcasting', a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>100xp In previous exercises, we have preloaded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>100xp Not all data files are clean and tidy. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>100xp Data visualization is often a very effec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>100xp Comparing data from several columns can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>100xp In the previous chapter, you saw that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>100xp Pandas scatter plots are generated using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>100xp While pandas can plot multiple columns o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>100xp Pandas relies on the .hist() method to n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>100xp In this exercise, you will investigate s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>100xp In many data sets, there can be large di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>100xp In this exercise, you'll investigate the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>100xp Let's use the mean and standard deviatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>50xp How many automobiles were manufactured in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>100xp Let's use population filtering to determ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>100xp Population filtering can be used alongsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1159</th>\n",
       "      <td>100xp Pandas time series support \"partial stri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1161</th>\n",
       "      <td>100xp Reindexing is useful in preparation for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>100xp Pandas provides methods for resampling t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>100xp With pandas, you can resample in differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>100xp In this exercise, some hourly weather da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>100xp As of pandas version 0.18.0, the interfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>100xp We've seen that pandas supports method c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1173</th>\n",
       "      <td>100xp One common application of interpolation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1175</th>\n",
       "      <td>0xp Time zone handling with pandas typically a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>100xp Pandas handles datetimes not only in you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1179</th>\n",
       "      <td>100xp Now that you have set the DatetimeIndex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>100xp Now that you have identified the method ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>100xp After the initial step of reading in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>0xp In order to use the full power of pandas t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>100xp The numeric columns contain missing valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>100xp Now that you have the data read and clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191</th>\n",
       "      <td>0xp You're now ready to compare the 2011 weath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>100xp On average, how much hotter is it when t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>100xp Is there a correlation between temperatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>100xp In a previous exercise, you analyzed the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>100xp Dew point is a measure of relative humid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201</th>\n",
       "      <td>100xp We already know that 2011 was hotter tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>100xp Let's work more on your mastery of scope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>0xp You've learned in the last video about nes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>100xp Great job, you've just nested a function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>100xp Let's once again work further on your ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>100xp In the previous chapter, you've learned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>100xp You've now defined a function that uses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>100xp Flexible arguments enable you to pass a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>100xp Let's push further on what you've learne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>100xp Recall the Bringing it all together exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>100xp Wow, you've just generalized your Twitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>100xp Some function definitions are simple eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1224</th>\n",
       "      <td>100xp So far, you've used lambda functions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>100xp In the previous exercise, you used lambd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>100xp You're getting very good at using lambda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>100xp A good practice in writing your own func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>100xp Another way to raise an error is by usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>100xp This is awesome! You have now learned ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>100xp Sometimes, we make mistakes when calling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>100xp In the previous exercise, you built on y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>100xp Great, you're familiar with what iterabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>100xp One of the things you learned about in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1241</th>\n",
       "      <td>100xp You've been using the iter() function to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243</th>\n",
       "      <td>100xp You're really getting the hang of using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>100xp Another interesting function that you've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>100xp You know how to use zip() as well as how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>100xp Sometimes, the data we have to process r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>100xp Great job chunking out that file in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>100xp You now have all the knowledge necessary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>100xp Great! At this point, you have a good gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0xp You've been using list comprehensions to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>100xp In the previous exercise, you used an if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>100xp Comprehensions aren't relegated merely t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>100xp You are familiar with what generators an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>100xp Great! At this point, you already know h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>100xp In previous exercises, you've dealt main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0xp You will now make use of what you've learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>100xp Great, you've successfully extracted the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>0xp For this exercise, you'll use what you've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>100xp Suppose you needed to repeat the same pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>100xp This time, you're going to use the lists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>100xp You've zipped lists together, created a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>100xp Sometimes, data sources can be so large ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>100xp In the previous exercise, you processed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>100xp Great! You've just created a generator f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>100xp Another way to read data too large to st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>100xp In the previous exercise, you used read_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>100xp You're getting used to reading and proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>100xp In the previous exercises, you've only p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>100xp This is the last leg. You've learned a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>100XP Seed the random number generator with 42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>100XP Compute an ECDF from the actual time bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1306</th>\n",
       "      <td>100XP Plot fertility (y-axis) versus illiterac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1308</th>\n",
       "      <td>100XP Compute the slope and intercept of the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>100XP Specify the values of the slope for whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1312</th>\n",
       "      <td>100XP Compute the parameters for the slope and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>100XP Write a for loop to do the following for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>100XP Write a for loop to acquire 50 bootstrap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>100XP Define a function with call signature dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>100XP Draw 10000 bootstrap replicates of the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>100XP Draw 10000 bootstrap replicates of the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>100XP Generate 10000 bootstrap replicates of Ï„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>100XP Define a function with call signature dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>100XP Use your draw_bs_pairs_linreg() function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330</th>\n",
       "      <td>100XP Generate an array of xx-values consistin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>100XP Concatenate the two input arrays into on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>100XP Write a for loop to 50 generate permutat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>100XP Define a function with this signature: d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>100XP Use sns.swarmplot() to make a bee swarm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1341</th>\n",
       "      <td>100XP Define a function with call signature di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>100XP Translate the impact forces of Frog B su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>100XP Compute the observed difference in impac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1347</th>\n",
       "      <td>100XP Compute the mean of all forces (from for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>100XP Construct Boolean arrays, dems and reps ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>100XP Compute the observed difference in mean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>100XP Compute the observed Pearson correlation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>100XP Use your ecdf() function to generate x,y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>100XP Compute the mean alive sperm count of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>100XP Label the axes. Don't forget that you sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>100XP Import numpy as np. This gives access to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>100XP Use ecdf() to compute the ECDF of versic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>100XP Define a function with the signature ecd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>100XP Compute ECDFs for each of the three spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1372</th>\n",
       "      <td>100XP Compute the mean petal length of Iris ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>100XP Plot the percentiles as red diamonds on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>100XP The set-up is exactly the same as for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>100XP Create an array called differences that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>100XP Compute the variance of the data in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>100XP Use plt.plot() with the appropriate keyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1385</th>\n",
       "      <td>100XP Use np.cov() to compute the covariance m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1387</th>\n",
       "      <td>100XP Define a function with signature pearson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>100XP Seed the random number generator using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>100XP Define a function with signature perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393</th>\n",
       "      <td>100XP Seed the random number generator to 42. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>100XP Compute the x and y values for the ECDF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>100XP Draw samples out of the Binomial distrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>100XP Using np.arange(), compute the bin edges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>100XP Using the np.random.poisson() function, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>100XP Draw 10000 samples from a Poisson distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>100XP Use your ecdf() function to generate x a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>100XP Compute mean and standard deviation of B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>100XP Take 1,000,000 samples from the normal d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>100XP Define a function with call signature su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>100XP Use your successive_poisson() function t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1415</th>\n",
       "      <td>100xp In this chapter, you'll be working with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>50xp The Numerical EDA you did in the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1423</th>\n",
       "      <td>0xp Having explored the Congressional voting r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1425</th>\n",
       "      <td>0xp Having fit a k-NN classifier, you can now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>100xp Up until now, you have been performing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>100xp Now that you have learned about the impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>100xp Remember the model complexity curve that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>100xp In this chapter, you will work with Gapm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>100xp Now, you will fit a linear regression an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>100xp As you learned in Chapter 1, train and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>100xp Cross-validation is a vital step in eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>100xp Cross validation is essential but do not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>0xp In the video, you saw how Lasso selected o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>100xp Lasso is great for feature selection, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>100xp In Chapter 1, you evaluated the performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>100xp Time to build your first logistic regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>100xp Great job in the previous exercise - you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>100xp Say you have a binary classifier that in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>100xp Hugo demonstrated how to use to tune the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>100xp GridSearchCV can be computationally expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>100xp You will now practice evaluating a model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>100xp Remember lasso and ridge regression from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>0xp The Gapminder dataset that you worked with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>100xp As Andy discussed in the video, scikit-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>100xp Having created the dummy variables from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>100xp The voting dataset from Chapter 1 contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>100xp As you've come to appreciate, there are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>100xp Having setup the steps of the pipeline i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>100xp In the video, Hugo demonstrated how sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>100xp With regard to whether or not scaling is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>100xp It is time now to piece together everyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>100xp For this final exercise, you will return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>100XP Import: matplotlib.pyplot as plt. pearso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>100XP Import PCA from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1492</th>\n",
       "      <td>100XP Make a scatter plot of the grain measure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>100XP Create an instance of StandardScaler cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1498</th>\n",
       "      <td>100XP Import PCA from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>100XP Import TfidfVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>100XP Import: TruncatedSVD from sklearn.decomp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>100XP Import pandas as pd. Fit the pipeline to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>100XP Import NMF from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>100XP Import matplotlib.pyplot as plt. Select ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>100XP Import NMF from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>100XP Import PCA from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>100XP Import: NMF from sklearn.decomposition. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Questions\n",
       "0     50xp In this chapter, you're going to look at ...\n",
       "2     50xp In the previous exercise, you identified ...\n",
       "4     100xp As you've seen, .describe() can only be ...\n",
       "6     100xp Up until now, you've been looking at des...\n",
       "8     100xp Histograms are great ways of visualizing...\n",
       "10    100xp Boxplots are great when you have a numer...\n",
       "12    100xp Melting data is the process of turning c...\n",
       "14    100xp When melting DataFrames, it would be bet...\n",
       "16    100xp Pivoting data is the opposite of melting...\n",
       "18    100xp After pivoting airquality_melt in the pr...\n",
       "21    100xp The dataset you saw in the video, consis...\n",
       "23    100xp Another common way multiple variables ar...\n",
       "25    100xp The dataset you'll be working with here ...\n",
       "27    100xp Think of column-wise concatenation of da...\n",
       "29    100xp You're now going to practice using the g...\n",
       "31    100xp Now that you have a list of filenames to...\n",
       "33    100xp Merging data allows you to combine dispa...\n",
       "35    100xp In a many-to-one (or one-to-many) merge,...\n",
       "37    100xp The final merging scenario occurs when b...\n",
       "39    100xp In this exercise, you'll see how ensurin...\n",
       "41    100xp If you expect the data type of a column ...\n",
       "43    100xp In the video, Dan introduced you to the ...\n",
       "45    100xp Extracting numbers from strings is a com...\n",
       "47    100xp In this exercise, you'll continue practi...\n",
       "49    100xp You'll now practice writing functions to...\n",
       "51    100xp You'll now be introduced to a powerful P...\n",
       "56    100xp Duplicate data causes a variety of probl...\n",
       "58    100xp Here, you'll return to the airquality da...\n",
       "60    0xp Here, you'll practice writing assert state...\n",
       "62    100xp In this exercise, you'll write code to d...\n",
       "65    0xp As Dan explained to you in the video, an \"...\n",
       "67    100xp You'll now define a function called pred...\n",
       "69    100xp In this exercise, you'll write code to d...\n",
       "71    100xp Now you'll get to change weights in a re...\n",
       "73    100xp You've seen how different weights will h...\n",
       "75    100xp You're now going to practice calculating...\n",
       "77    100xp Hurray! You've just calculated the slope...\n",
       "79    100xp You're now going to make multiple update...\n",
       "81    100xp Now you'll get to work with your first m...\n",
       "83    100xp You're now going to compile the model yo...\n",
       "85    100xp You're at the most fun part. You'll now ...\n",
       "87    100xp You'll now create a classification model...\n",
       "89    100xp The trained network from your previous c...\n",
       "91    100xp It's time to get your hands dirty with o...\n",
       "93    100xp Now it's your turn to monitor model accu...\n",
       "95    100xp Now that you know how to monitor your mo...\n",
       "97    0xp Now you know everything you need to begin ...\n",
       "99    100xp You've seen how to experiment with wider...\n",
       "101   0xp You've reached the final exercise of the c...\n",
       "103   100xp In this exercise, you'll be working with...\n",
       "105   100xp For large files, we may not want to prin...\n",
       "109   100xp In this exercise, you're now going to lo...\n",
       "111   100xp What if there are rows, such as a header...\n",
       "113   100xp The file seaslug.txt has a text header, ...\n",
       "117   100xp You have just used np.genfromtxt() to im...\n",
       "119   100xp In the last exercise, you were able to i...\n",
       "123   100xp The pandas package is also great at deal...\n",
       "125   100xp There are a number of datatypes that can...\n",
       "127   100xp Whether you like it or not, any working ...\n",
       "129   100xp In the previous exercises, you saw that ...\n",
       "131   100xp Here, you'll parse your spreadsheets and...\n",
       "133   100xp In this exercise, you'll figure out how ...\n",
       "136   100xp Here, you'll gain expertise in importing...\n",
       "138   100xp The file 'LIGO_data.hdf5' is already in ...\n",
       "140   100xp In this exercise, you'll extract some of...\n",
       "142   100xp In this exercise, you'll figure out how ...\n",
       "144   100xp Here, you'll discover what is in the MAT...\n",
       "147   100xp Here, you're going to fire up your very ...\n",
       "150   100xp In this exercise, you'll once again crea...\n",
       "152   0xp Now, it's time for liftoff! In this exerci...\n",
       "154   100xp Congratulations on executing your first ...\n",
       "161   100xp You can now execute a basic SQL query to...\n",
       "165   100xp You can also order your SQL query result...\n",
       "169   100xp Here, you'll become more familiar with t...\n",
       "171   100xp Here, you'll perform your first INNER JO...\n",
       "174   100xp Congrats on performing your first INNER ...\n",
       "177   100xp In this exercise, you'll be working with...\n",
       "179   100xp For large files, we may not want to prin...\n",
       "183   100xp In this exercise, you're now going to lo...\n",
       "185   100xp What if there are rows, such as a header...\n",
       "187   100xp The file seaslug.txt has a text header, ...\n",
       "191   100xp You have just used np.genfromtxt() to im...\n",
       "193   100xp In the last exercise, you were able to i...\n",
       "197   100xp The pandas package is also great at deal...\n",
       "199   100xp There are a number of datatypes that can...\n",
       "201   100xp Whether you like it or not, any working ...\n",
       "203   100xp In the previous exercises, you saw that ...\n",
       "205   100xp Here, you'll parse your spreadsheets and...\n",
       "207   100xp In this exercise, you'll figure out how ...\n",
       "210   100xp Here, you'll gain expertise in importing...\n",
       "212   100xp The file 'LIGO_data.hdf5' is already in ...\n",
       "214   100xp In this exercise, you'll extract some of...\n",
       "216   100xp In this exercise, you'll figure out how ...\n",
       "218   100xp Here, you'll discover what is in the MAT...\n",
       "221   100xp Here, you're going to fire up your very ...\n",
       "224   100xp In this exercise, you'll once again crea...\n",
       "226   0xp Now, it's time for liftoff! In this exerci...\n",
       "228   100xp Congratulations on executing your first ...\n",
       "235   100xp You can now execute a basic SQL query to...\n",
       "239   100xp You can also order your SQL query result...\n",
       "243   100xp Here, you'll become more familiar with t...\n",
       "245   100xp Here, you'll perform your first INNER JO...\n",
       "248   100xp Congrats on performing your first INNER ...\n",
       "251   100xp You are about to import your first file ...\n",
       "254   100xp You have just imported a file from the w...\n",
       "256   100xp Congrats! You've just loaded a flat file...\n",
       "259   100xp Now that you know the basics behind HTTP...\n",
       "261   100xp You have just packaged and sent a GET re...\n",
       "263   100xp Now that you've got your head and hands ...\n",
       "265   100xp In this interactive exercise, you'll lea...\n",
       "267   100xp As promised, in the following exercises,...\n",
       "269   100xp In this exercise, you'll figure out how ...\n",
       "271   0xp Now that you know what a JSON is, you'll l...\n",
       "273   100xp Now it's your turn to pull some movie da...\n",
       "275   100xp Wow, congrats! You've just queried your ...\n",
       "277   100xp You're doing so well and having so much ...\n",
       "279   100xp The package tweepy is great at handling ...\n",
       "281   100xp Now that you have set up your authentica...\n",
       "283   100xp Now that you've got your Twitter data si...\n",
       "285   100xp Now you have the Twitter data in a list ...\n",
       "287   100xp Now that you have your DataFrame of twee...\n",
       "291   100xp Now that you have the number of tweets t...\n",
       "294   100XP Import the figure function from bokeh.pl...\n",
       "296   100XP Create the figure p with the figure() fu...\n",
       "298   100XP Using the Latin America data (fertility_...\n",
       "300   100XP Import the figure function from bokeh.pl...\n",
       "302   100XP Plot date along the x-axis and price alo...\n",
       "304   100XP Create a list of the longitude positions...\n",
       "306   100XP Import numpy as np. Create an array x us...\n",
       "308   100XP Import pandas as pd. Use the read_csv() ...\n",
       "310   100XP Import the ColumnDataSource class from b...\n",
       "312   100XP Create a figure p with an x-axis label o...\n",
       "314   100XP Import HoverTool from bokeh.models. Add ...\n",
       "316   100XP Import CategoricalColorMapper from bokeh...\n",
       "318   100XP Import row from the bokeh.layouts module...\n",
       "320   100XP Import column from the bokeh.layouts mod...\n",
       "322   100XP Import row and column from bokeh.layouts...\n",
       "324   100XP Import gridplot from the bokeh.layouts m...\n",
       "326   100XP Import Panel from bokeh.models.widgets. ...\n",
       "328   100XP Import Tabs from bokeh.models.widgets. C...\n",
       "330   100XP Link the x_range of p2 to p1. Link the y...\n",
       "332   100XP Create a ColumnDataSource object called ...\n",
       "334   100XP Add a red circle glyph to the figure p u...\n",
       "336   100XP Use p.legend.location to adjust the lege...\n",
       "338   100XP Import the HoverTool class from bokeh.mo...\n",
       "340   100XP Import curdoc from bokeh.io and figure f...\n",
       "342   100XP Import curdoc from bokeh.io, widgetbox f...\n",
       "344   100XP Create the first slider, slider1, using ...\n",
       "346   100XP Create a ColumnDataSource called source....\n",
       "348   100XP Define a callback function callback with...\n",
       "350   100XP Define a callback function called update...\n",
       "352   100XP Create select1, the first dropdown selec...\n",
       "354   0XP Create a button called button using the fu...\n",
       "356   100XP Import CheckboxGroup, RadioGroup, Toggle...\n",
       "358   100XP Import output_file and show from bokeh.i...\n",
       "360   100XP Make a ColumnDataSource object called so...\n",
       "362   100XP Make a list of the unique values from th...\n",
       "364   100XP Import the widgetbox and row functions f...\n",
       "366   100XP Define the update_plot callback function...\n",
       "368   100XP Import HoverTool from bokeh.models. Crea...\n",
       "370   100XP Inside the update_plot() callback functi...\n",
       "371   100xp With matplotlib, you can create a bunch ...\n",
       "374   100xp Now that you've built your first line pl...\n",
       "376   100xp When you have a time scale along the hor...\n",
       "379   100xp In the previous exercise, you saw that t...\n",
       "381   100xp life_exp, the list containing data on th...\n",
       "383   100xp In the previous exercise, you didn't spe...\n",
       "386   100xp It's time to customize your own plot. Th...\n",
       "388   100xp The customizations you've coded up to no...\n",
       "391   100xp Right now, the scatter plot is just a cl...\n",
       "393   100xp The code you've written up to now is ava...\n",
       "396   100xp If you have another look at the script, ...\n",
       "398   100xp To see why dictionaries are useful, have...\n",
       "400   100xp The countries and capitals lists are aga...\n",
       "402   100xp If the keys of a dictionary are chosen w...\n",
       "405   0xp If you know how to access a dictionary, yo...\n",
       "407   100xp Somebody thought it would be funny to me...\n",
       "409   100xp Remember lists? They could contain anyth...\n",
       "411   100xp Pandas is an open source library, provid...\n",
       "413   100xp The Python code that solves the previous...\n",
       "415   100xp Putting data in a dictionary and then bu...\n",
       "416   100xp Your read_csv() call to import the CSV d...\n",
       "418   100xp In the video, you saw that you can index...\n",
       "421   100xp Square brackets can do more than just se...\n",
       "424   100xp With loc and iloc you can do practically...\n",
       "429   100xp loc and iloc also allow you to select bo...\n",
       "433   100xp It's also possible to select only column...\n",
       "436   100xp To check if two Python values, or variab...\n",
       "439   100xp In the video, Filip also talked about th...\n",
       "442   100xp Out of the box, you can also use compari...\n",
       "444   100xp A boolean is either 1 or 0, True or Fals...\n",
       "448   100xp It's time to take a closer look around i...\n",
       "450   100xp On the right, the if construct for room ...\n",
       "452   100xp It's also possible to have a look around...\n",
       "454   100xp Remember that cars dataset, containing t...\n",
       "456   100xp The code in the previous example worked ...\n",
       "458   100xp Let's stick to the cars data some more. ...\n",
       "460   100xp Remember about np.logical_and(), np.logi...\n",
       "462   100xp Below you can find the example from the ...\n",
       "464   100xp The while loop that corrects the offset ...\n",
       "465   100xp Have another look at the for loop that F...\n",
       "468   100xp Using a for loop to iterate over a list ...\n",
       "470   100xp For non-programmer folks, room 0: 11.25 ...\n",
       "472   100xp Remember the house variable from the Int...\n",
       "474   100xp In Python 3, you need the items() method...\n",
       "478   100xp If you're dealing with a 1D Numpy array,...\n",
       "482   100xp Iterating over a Pandas DataFrame is typ...\n",
       "485   100xp The row data that's generated by iterrow...\n",
       "487   0xp In the video, Filip showed you how to add ...\n",
       "490   100xp Using iterrows() to iterate over every o...\n",
       "494   100xp Below you can find the example from the ...\n",
       "497   100xp The while loop that corrects the offset ...\n",
       "499   100xp Have another look at the for loop that F...\n",
       "502   100xp Using a for loop to iterate over a list ...\n",
       "504   100xp For non-programmer folks, room 0: 11.25 ...\n",
       "506   100xp Remember the house variable from the Int...\n",
       "508   100xp In Python 3, you need the items() method...\n",
       "512   100xp If you're dealing with a 1D Numpy array,...\n",
       "516   100xp Iterating over a Pandas DataFrame is typ...\n",
       "519   100xp The row data that's generated by iterrow...\n",
       "521   0xp In the video, Filip showed you how to add ...\n",
       "524   100xp Using iterrows() to iterate over every o...\n",
       "528   100xp Randomness has many uses in science, art...\n",
       "530   100xp In the previous exercise, you used rand(...\n",
       "533   100xp In the Empire State Building bet, your n...\n",
       "535   100xp Before, you have already written Python ...\n",
       "537   0xp Things are shaping up nicely! You already ...\n",
       "539   100xp Let's visualize this random walk! Rememb...\n",
       "542   100xp A single random walk is one thing, but t...\n",
       "544   100xp all_walks is a list of lists: every sub-...\n",
       "548   100xp With this neatly written code of yours, ...\n",
       "550   100xp All these fancy visualizations have put ...\n",
       "574   100xp Subsetting Python lists is a piece of ca...\n",
       "583   50xp You saw before that a Python list can con...\n",
       "586   100xp Replacing list elements is pretty easy. ...\n",
       "589   100xp If you can change elements in a list, yo...\n",
       "597   100xp Out of the box, Python offers a bunch of...\n",
       "599   50xp Maybe you already know the name of a Pyth...\n",
       "602   100xp In the previous exercise, the square bra...\n",
       "604   100xp Strings come with a bunch of methods. Fo...\n",
       "605   100xp Strings are not the only Python types th...\n",
       "607   100xp Most list methods will change the list t...\n",
       "608   100xp As a data scientist, some notions of geo...\n",
       "609   100xp General imports, like import math, make ...\n",
       "611   50xp There are several ways to import packages...\n",
       "613   100xp We're going to dive into the world of ba...\n",
       "614   100xp You are a huge baseball fan. You decide ...\n",
       "615   100xp The MLB also offers to let you analyze t...\n",
       "616   100xp To subset both regular Python lists and ...\n",
       "619   100xp You've seen it with your own eyes: Pytho...\n",
       "622   100xp Before working on the actual MLB data, l...\n",
       "623   100xp You have another look at the MLB data an...\n",
       "624   100xp If your 2D Numpy array has a regular str...\n",
       "628   100xp Remember how you calculated the Body Mas...\n",
       "630   100xp You now know how to use Numpy functions ...\n",
       "632   0xp Because the mean and median are so far apa...\n",
       "633   100xp In the last few exercises you've learned...\n",
       "635   0XP Import create_engine from the sqlalchemy m...\n",
       "637   100XP Import the Table object from sqlalchemy....\n",
       "639   100XP Reflect the census table as you did in t...\n",
       "641   100XP Build a SQL statement to query all the c...\n",
       "643   100XP Import select from the sqlalchemy module...\n",
       "645   100XP Extract the first row of results and ass...\n",
       "647   50XP Import create_engine from sqlalchemy. Cre...\n",
       "649   100XP Select all records from the census table...\n",
       "651   100XP Select all records from the census table...\n",
       "653   100XP Import and_ from the sqlalchemy module. ...\n",
       "655   100XP Select all records of the state column f...\n",
       "657   100XP Import desc from the sqlalchemy module. ...\n",
       "659   100XP Select all records of the state and age ...\n",
       "664   100XP Build a select statement to count the di...\n",
       "668   100XP Import func from sqlalchemy. Build an ex...\n",
       "670   100XP Import pandas as pd. Create a DataFrame ...\n",
       "672   100XP Import matplotlib.pyplot as plt. Create ...\n",
       "674   100XP Import the create_engine function from t...\n",
       "676   100XP Define a select statement called stmt to...\n",
       "678                                               100XP\n",
       "682   100XP Build a statement to join the census and...\n",
       "684   100XP Build a statement to select ALL the colu...\n",
       "686   100XP Build a statement to select: The state c...\n",
       "690   100XP Save an alias of the employees table as ...\n",
       "692   100XP Use a while loop that checks if there ar...\n",
       "694   100XP Import Table, Column, String, Integer, F...\n",
       "696   100XP Table, Column, String, Integer, Float, B...\n",
       "698   100XP Import insert and select from the sqlalc...\n",
       "700   100XP Build a list of dictionaries called valu...\n",
       "702   100XP Create a statement for bulk insert into ...\n",
       "705   100XP Build a statement to select all columns ...\n",
       "707   100XP Build an update statement to update the ...\n",
       "709   100XP Build a statement to select the name col...\n",
       "712   100XP Import delete and select from sqlalchemy...\n",
       "715   100XP Build a delete statement to remove data ...\n",
       "717   100XP Drop the state_fact table by applying th...\n",
       "719   100XP Import create_engine and MetaData from s...\n",
       "721   100XP Import Table, Column, String, and Intege...\n",
       "723   100XP Create an empty list called values_list....\n",
       "725   100XP Import insert from sqlalchemy. Build an ...\n",
       "727   100XP Import select from sqlalchemy. Build a s...\n",
       "729   100XP Import case, cast and Float from sqlalch...\n",
       "731   100XP Build a statement to: Select state. Calc...\n",
       "733   100XP Import matplotlib.pyplot as its usual al...\n",
       "735   100XP Create a set of plot axes with lower cor...\n",
       "737   100XP Use plt.subplot() to create a figure wit...\n",
       "739   100XP Create a figure with 2Ã—22Ã—2 subplot layo...\n",
       "741   100XP Use plt.xlim() to set the x-axis range t...\n",
       "743   100XP Use plt.axis() to select the time period...\n",
       "745   100XP Modify the plot command provided that dr...\n",
       "747   100XP Compute the maximum enrollment of women ...\n",
       "749   100XP Import matplotlib.pyplot as its usual al...\n",
       "752   100XP Import the numpy and matplotlib.pyplot m...\n",
       "754   100XP Using the meshgrid X, Y as axes: Generat...\n",
       "756   100XP Modify the call to plt.contourf() so the...\n",
       "758   100XP Generate a two-dimensional histogram to ...\n",
       "760   100XP Generate a two-dimensional histogram wit...\n",
       "762   100XP Load the file '480px-Astronaut-EVA.jpg' ...\n",
       "764   100XP Print the shape of the existing image ar...\n",
       "766   100XP Display img in the top left subplot with...\n",
       "768   100XP Use the methods .min() and .max() to sav...\n",
       "770   100XP Import matplotlib.pyplot and seaborn usi...\n",
       "772   100XP Import matplotlib.pyplot and seaborn usi...\n",
       "774   100XP Modify the call to plt.scatter() to plot...\n",
       "776   100XP Plot a linear regression between 'weight...\n",
       "778   100XP Plot linear regressions of 'hp' (on the ...\n",
       "780   100XP In the first row of subplots, make a str...\n",
       "782   100XP In the first row of subplots, make a swa...\n",
       "784   100XP In the first row of subplots, make a vio...\n",
       "786   100XP Use sns.jointplot() to visualize the joi...\n",
       "788   100XP Create a hexbin plot of the joint distri...\n",
       "790   100XP Print the first five rows of the DataFra...\n",
       "792   100XP Plot the pairwise joint distributions se...\n",
       "794   100XP Print the covariance matrix cov_matrix t...\n",
       "797   100XP Plot the aapl time series in blue with a...\n",
       "799   100XP Plot the series aapl in 'blue' in the to...\n",
       "801   100XP Extract a slice named view from the seri...\n",
       "803   100XP Extract a slice of series aapl from Nove...\n",
       "805   100XP In the top left subplot, plot the 30-day...\n",
       "807   100XP Produce a single plot with four curves o...\n",
       "809   100XP Load data from the file '640px-Unequaliz...\n",
       "811   100XP First, use plt.hist() to plot the histog...\n",
       "813   100XP Use the NumPy array method .reshape() to...\n",
       "815   100XP Display image in the top subplot of a 2Ã—...\n",
       "817   100XP Make a 2-D histogram in the top left sub...\n",
       "820   100XP Import the create_engine function from t...\n",
       "822   100XP Define a select statement called stmt to...\n",
       "824                                               100XP\n",
       "828   100XP Build a statement to join the census and...\n",
       "830   100XP Build a statement to select ALL the colu...\n",
       "832   100XP Build a statement to select: The state c...\n",
       "836   100XP Save an alias of the employees table as ...\n",
       "838   100XP Use a while loop that checks if there ar...\n",
       "840   100XP Import Table, Column, String, Integer, F...\n",
       "842   100XP Table, Column, String, Integer, Float, B...\n",
       "844   100XP Import insert and select from the sqlalc...\n",
       "846   100XP Build a list of dictionaries called valu...\n",
       "848   100XP Create a statement for bulk insert into ...\n",
       "851   100XP Build a statement to select all columns ...\n",
       "853   100XP Build an update statement to update the ...\n",
       "855   100XP Build a statement to select the name col...\n",
       "858   100XP Import delete and select from sqlalchemy...\n",
       "861   100XP Build a delete statement to remove data ...\n",
       "863   100XP Drop the state_fact table by applying th...\n",
       "865   100XP Import create_engine and MetaData from s...\n",
       "867   100XP Import Table, Column, String, and Intege...\n",
       "869   100XP Create an empty list called values_list....\n",
       "871   100XP Import insert from sqlalchemy. Build an ...\n",
       "873   100XP Import select from sqlalchemy. Build a s...\n",
       "875   100XP Import case, cast and Float from sqlalch...\n",
       "877   100XP Build a statement to: Select state. Calc...\n",
       "885   100XP Print summary statistics of the numeric ...\n",
       "888   100XP Define the lambda function categorize_la...\n",
       "890   100XP Create the DataFrame num_unique_labels b...\n",
       "893   100XP Using the compute_log_loss() function, c...\n",
       "895   100XP Create a new DataFrame named numeric_dat...\n",
       "897   100XP Import LogisticRegression from sklearn.l...\n",
       "899   100XP Read HoldoutData.csv into a DataFrame ca...\n",
       "901   100XP Create the prediction_df DataFrame by sp...\n",
       "903   100XP Import CountVectorizer from sklearn.feat...\n",
       "905   100XP Use the .drop() method on data_frame wit...\n",
       "907   100XP Import CountVectorizer from sklearn.feat...\n",
       "909   100XP Import Pipeline from sklearn.pipeline. C...\n",
       "911   100XP Import CountVectorizer from sklearn.feat...\n",
       "913   100XP Compute the selector get_text_data by us...\n",
       "915   100XP In the process_and_join_features: Add th...\n",
       "917   100XP Complete the call to multilabel_train_te...\n",
       "919   100XP Complete the 'numeric_features' transfor...\n",
       "921   100XP Import the RandomForestClassifier from s...\n",
       "923   100XP Import the RandomForestClassifier from s...\n",
       "928   100XP Create text_vector by preprocessing X_tr...\n",
       "930   100XP Import CountVectorizer from sklearn.feat...\n",
       "934   100XP Add the interaction terms step using Spa...\n",
       "938   100XP Import HashingVectorizer from sklearn.fe...\n",
       "940   100XP Import HashingVectorizer from sklearn.fe...\n",
       "941   100xp As you saw in the video, loading data fr...\n",
       "943   100xp In this exercise, you'll combine the thr...\n",
       "945   0xp It is often useful to rearrange the sequen...\n",
       "947   100xp Sorting methods are not the only way to ...\n",
       "949   100xp Another common technique is to reindex a...\n",
       "952   100xp In this exercise, you'll work with weath...\n",
       "954   100xp Your job in this exercise is to compute ...\n",
       "961   100XP Create an empty list called units. This ...\n",
       "963   100XP Create a 'year' column in the DataFrames...\n",
       "965   100XP Create a new DataFrame called weather by...\n",
       "967   100XP Iterate over medal_types in the for loop...\n",
       "969   100XP Within the for loop: Read file_name into...\n",
       "971   100XP Create a new DataFrame medals_sorted wit...\n",
       "973                                               100XP\n",
       "976   100XP Create a list called month_list consisti...\n",
       "978   100XP Construct a list of DataFrames called me...\n",
       "980   100XP Make a new DataFrame china_annual by res...\n",
       "982   100XP Using pd.merge(), merge the DataFrames r...\n",
       "986   100XP Merge the DataFrames revenue and manager...\n",
       "988   100XP Create a column called 'state' in the Da...\n",
       "993   100XP Execute a right merge using pd.merge() w...\n",
       "995   100XP Merge sales_and_managers with revenue_an...\n",
       "997   100XP Perform an ordered merge on austin and h...\n",
       "999   100XP Merge auto and oil using pd.merge_asof()...\n",
       "1001  100XP Read file_path into a DataFrame called e...\n",
       "1003  100XP Read file_path into a DataFrame called i...\n",
       "1005  100XP Within the for loop: Create the file pat...\n",
       "1007  0XP Construct a pivot table from the DataFrame...\n",
       "1009  100XP Set the index of the DataFrame editions ...\n",
       "1011  100XP Create mean_fractions by chaining the me...\n",
       "1013  0XP Create the DataFrame hosts by doing a left...\n",
       "1015  100XP Create a DataFrame reshaped by reshaping...\n",
       "1017  100XP Merge reshaped and hosts using an inner ...\n",
       "1019  100XP Create a Series called change by extract...\n",
       "1021  100xp Now you'll get a chance to write some re...\n",
       "1022  100xp Here, you'll be using the first scene of...\n",
       "1023  0xp In this exercise, you'll utilize re.search...\n",
       "1024  50xp Given the following string, which is the ...\n",
       "1025  100xp Twitter is a frequently used source for ...\n",
       "1026  0xp In this exercise, you'll practice advanced...\n",
       "1027  100xp Try using your new skills to find and ch...\n",
       "1028  100xp In this exercise, you'll build your firs...\n",
       "1030  100xp Now, it's your turn to apply the techniq...\n",
       "1032  100xp It's time to apply the methods you learn...\n",
       "1034  100xp Now, you'll use your new gensim corpus a...\n",
       "1038  100xp You're now going to have some fun with n...\n",
       "1040  100xp In this exercise, you'll use some extrac...\n",
       "1042  100xp Using the same text you used in the firs...\n",
       "1044  100xp In this exercise and the next, you'll us...\n",
       "1046  0xp Here, you'll complete the work you began i...\n",
       "1048  100xp You'll continue your exploration of poly...\n",
       "1050  100xp In the final exercise of this NER chapte...\n",
       "1052  100xp It's time to begin building your text cl...\n",
       "1054  100xp Similar to the sparse CountVectorizer cr...\n",
       "1056  100xp To get a better idea of how the vectors ...\n",
       "1062  100xp Now it's your turn to train the \"fake ne...\n",
       "1064  100xp Now that you have evaluated the model us...\n",
       "1066  100xp Your job in this exercise is to test a f...\n",
       "1068  100xp Now that you have built a \"fake news\" cl...\n",
       "1073  100XP Import matplotlib.pyplot as plt and netw...\n",
       "1075  100XP Use a list comprehension to get a list o...\n",
       "1078  100XP Set the 'weight' attribute of the edge b...\n",
       "1080  100XP Define a function called find_selfloop_n...\n",
       "1082  100XP Import nxviz as nv. Plot the graph T as ...\n",
       "1084  100XP Import CircosPlot from nxviz. Plot the T...\n",
       "1086  100XP Import ArcPlot from nxviz. Create an un-...\n",
       "1088  100XP Write a function called nodes_with_m_nbr...\n",
       "1090  100XP Use a list comprehension along with the ...\n",
       "1092  100XP Compute the degree centrality of the Twi...\n",
       "1094  100XP Create a function called path_exists() t...\n",
       "1096  100XP Using the .add() method, add the current...\n",
       "1098  100XP Check to see if the queue has been empti...\n",
       "1100  100XP Compute the betweenness centrality bet_c...\n",
       "1102  100XP Write a function find_nodes_with_highest...\n",
       "1104  100XP Write a function find_node_with_highest_...\n",
       "1106  100XP Import combinations from itertools. Writ...\n",
       "1108  100XP Write a function nodes_in_triangle() tha...\n",
       "1110  100XP Write a function node_in_open_triangle()...\n",
       "1112  100XP Write a function maximal_cliques() that ...\n",
       "1114  100XP Write a function get_nodes_and_nbrs(G, n...\n",
       "1116  100XP Using a list comprehension, extract node...\n",
       "1118  100XP Plot the degree distribution of the GitH...\n",
       "1120  100XP Plot the betweenness centrality distribu...\n",
       "1122  100XP Make a MatrixPlot visualization of the l...\n",
       "1124  100XP Make an ArcPlot of the GitHub collaborat...\n",
       "1126  100XP Make a CircosPlot of the network, again,...\n",
       "1128  100XP Count the number of maximal cliques pres...\n",
       "1130  100XP Find the author(s) that are part of the ...\n",
       "1133  100XP Go out 1 degree of separation from the c...\n",
       "1135  100XP Compile a list of GitHub users that shou...\n",
       "1136  100xp Pandas depends upon and interoperates wi...\n",
       "1138  100xp In this exercise, you're going to make a...\n",
       "1139  100xp You can use the DataFrame attribute df.c...\n",
       "1140  100xp You can implicitly use 'broadcasting', a...\n",
       "1141  100xp In previous exercises, we have preloaded...\n",
       "1142  100xp Not all data files are clean and tidy. P...\n",
       "1143  100xp Data visualization is often a very effec...\n",
       "1144  100xp Comparing data from several columns can ...\n",
       "1145  100xp In the previous chapter, you saw that th...\n",
       "1146  100xp Pandas scatter plots are generated using...\n",
       "1147  100xp While pandas can plot multiple columns o...\n",
       "1148  100xp Pandas relies on the .hist() method to n...\n",
       "1150  100xp In this exercise, you will investigate s...\n",
       "1152  100xp In many data sets, there can be large di...\n",
       "1153  100xp In this exercise, you'll investigate the...\n",
       "1154  100xp Let's use the mean and standard deviatio...\n",
       "1155  50xp How many automobiles were manufactured in...\n",
       "1157  100xp Let's use population filtering to determ...\n",
       "1158  100xp Population filtering can be used alongsi...\n",
       "1159  100xp Pandas time series support \"partial stri...\n",
       "1161  100xp Reindexing is useful in preparation for ...\n",
       "1163  100xp Pandas provides methods for resampling t...\n",
       "1165  100xp With pandas, you can resample in differe...\n",
       "1167  100xp In this exercise, some hourly weather da...\n",
       "1169  100xp As of pandas version 0.18.0, the interfa...\n",
       "1171  100xp We've seen that pandas supports method c...\n",
       "1173  100xp One common application of interpolation ...\n",
       "1175  0xp Time zone handling with pandas typically a...\n",
       "1177  100xp Pandas handles datetimes not only in you...\n",
       "1179  100xp Now that you have set the DatetimeIndex ...\n",
       "1181  100xp Now that you have identified the method ...\n",
       "1183  100xp After the initial step of reading in the...\n",
       "1185  0xp In order to use the full power of pandas t...\n",
       "1187  100xp The numeric columns contain missing valu...\n",
       "1189  100xp Now that you have the data read and clea...\n",
       "1191  0xp You're now ready to compare the 2011 weath...\n",
       "1193  100xp On average, how much hotter is it when t...\n",
       "1195  100xp Is there a correlation between temperatu...\n",
       "1197  100xp In a previous exercise, you analyzed the...\n",
       "1199  100xp Dew point is a measure of relative humid...\n",
       "1201  100xp We already know that 2011 was hotter tha...\n",
       "1203  100xp Let's work more on your mastery of scope...\n",
       "1204  0xp You've learned in the last video about nes...\n",
       "1206  100xp Great job, you've just nested a function...\n",
       "1208  100xp Let's once again work further on your ma...\n",
       "1210  100xp In the previous chapter, you've learned ...\n",
       "1212  100xp You've now defined a function that uses ...\n",
       "1214  100xp Flexible arguments enable you to pass a ...\n",
       "1216  100xp Let's push further on what you've learne...\n",
       "1218  100xp Recall the Bringing it all together exer...\n",
       "1220  100xp Wow, you've just generalized your Twitte...\n",
       "1222  100xp Some function definitions are simple eno...\n",
       "1224  100xp So far, you've used lambda functions to ...\n",
       "1227  100xp In the previous exercise, you used lambd...\n",
       "1228  100xp You're getting very good at using lambda...\n",
       "1231  100xp A good practice in writing your own func...\n",
       "1232  100xp Another way to raise an error is by usin...\n",
       "1233  100xp This is awesome! You have now learned ho...\n",
       "1234  100xp Sometimes, we make mistakes when calling...\n",
       "1235  100xp In the previous exercise, you built on y...\n",
       "1236  100xp Great, you're familiar with what iterabl...\n",
       "1238  100xp One of the things you learned about in t...\n",
       "1241  100xp You've been using the iter() function to...\n",
       "1243  100xp You're really getting the hang of using ...\n",
       "1245  100xp Another interesting function that you've...\n",
       "1247  100xp You know how to use zip() as well as how...\n",
       "1249  100xp Sometimes, the data we have to process r...\n",
       "1251  100xp Great job chunking out that file in the ...\n",
       "1253  100xp You now have all the knowledge necessary...\n",
       "1255  100xp Great! At this point, you have a good gr...\n",
       "1258  0xp You've been using list comprehensions to b...\n",
       "1260  100xp In the previous exercise, you used an if...\n",
       "1262  100xp Comprehensions aren't relegated merely t...\n",
       "1264  100xp You are familiar with what generators an...\n",
       "1266  100xp Great! At this point, you already know h...\n",
       "1268  100xp In previous exercises, you've dealt main...\n",
       "1270  0xp You will now make use of what you've learn...\n",
       "1272  100xp Great, you've successfully extracted the...\n",
       "1274  0xp For this exercise, you'll use what you've ...\n",
       "1276  100xp Suppose you needed to repeat the same pr...\n",
       "1278  100xp This time, you're going to use the lists...\n",
       "1280  100xp You've zipped lists together, created a ...\n",
       "1282  100xp Sometimes, data sources can be so large ...\n",
       "1284  100xp In the previous exercise, you processed ...\n",
       "1286  100xp Great! You've just created a generator f...\n",
       "1288  100xp Another way to read data too large to st...\n",
       "1290  100xp In the previous exercise, you used read_...\n",
       "1292  100xp You're getting used to reading and proce...\n",
       "1294  100xp In the previous exercises, you've only p...\n",
       "1296  100xp This is the last leg. You've learned a l...\n",
       "1300  100XP Seed the random number generator with 42...\n",
       "1302  100XP Compute an ECDF from the actual time bet...\n",
       "1306  100XP Plot fertility (y-axis) versus illiterac...\n",
       "1308  100XP Compute the slope and intercept of the r...\n",
       "1310  100XP Specify the values of the slope for whic...\n",
       "1312  100XP Compute the parameters for the slope and...\n",
       "1314  100XP Write a for loop to do the following for...\n",
       "1316  100XP Write a for loop to acquire 50 bootstrap...\n",
       "1318  100XP Define a function with call signature dr...\n",
       "1320  100XP Draw 10000 bootstrap replicates of the m...\n",
       "1322  100XP Draw 10000 bootstrap replicates of the v...\n",
       "1324  100XP Generate 10000 bootstrap replicates of Ï„...\n",
       "1326  100XP Define a function with call signature dr...\n",
       "1328  100XP Use your draw_bs_pairs_linreg() function...\n",
       "1330  100XP Generate an array of xx-values consistin...\n",
       "1332  100XP Concatenate the two input arrays into on...\n",
       "1334  100XP Write a for loop to 50 generate permutat...\n",
       "1337  100XP Define a function with this signature: d...\n",
       "1339  100XP Use sns.swarmplot() to make a bee swarm ...\n",
       "1341  100XP Define a function with call signature di...\n",
       "1343  100XP Translate the impact forces of Frog B su...\n",
       "1345  100XP Compute the observed difference in impac...\n",
       "1347  100XP Compute the mean of all forces (from for...\n",
       "1349  100XP Construct Boolean arrays, dems and reps ...\n",
       "1351  100XP Compute the observed difference in mean ...\n",
       "1355  100XP Compute the observed Pearson correlation...\n",
       "1357  100XP Use your ecdf() function to generate x,y...\n",
       "1359  100XP Compute the mean alive sperm count of co...\n",
       "1361  100XP Label the axes. Don't forget that you sh...\n",
       "1363  100XP Import numpy as np. This gives access to...\n",
       "1365  100XP Use ecdf() to compute the ECDF of versic...\n",
       "1368  100XP Define a function with the signature ecd...\n",
       "1370  100XP Compute ECDFs for each of the three spec...\n",
       "1372  100XP Compute the mean petal length of Iris ve...\n",
       "1374  100XP Plot the percentiles as red diamonds on ...\n",
       "1376  100XP The set-up is exactly the same as for th...\n",
       "1379  100XP Create an array called differences that ...\n",
       "1381  100XP Compute the variance of the data in the ...\n",
       "1383  100XP Use plt.plot() with the appropriate keyw...\n",
       "1385  100XP Use np.cov() to compute the covariance m...\n",
       "1387  100XP Define a function with signature pearson...\n",
       "1389  100XP Seed the random number generator using t...\n",
       "1391  100XP Define a function with signature perform...\n",
       "1393  100XP Seed the random number generator to 42. ...\n",
       "1395  100XP Compute the x and y values for the ECDF ...\n",
       "1397  100XP Draw samples out of the Binomial distrib...\n",
       "1399  100XP Using np.arange(), compute the bin edges...\n",
       "1401  100XP Using the np.random.poisson() function, ...\n",
       "1403  100XP Draw 10000 samples from a Poisson distri...\n",
       "1406  100XP Use your ecdf() function to generate x a...\n",
       "1408  100XP Compute mean and standard deviation of B...\n",
       "1410  100XP Take 1,000,000 samples from the normal d...\n",
       "1412  100XP Define a function with call signature su...\n",
       "1414  100XP Use your successive_poisson() function t...\n",
       "1415  100xp In this chapter, you'll be working with ...\n",
       "1421  50xp The Numerical EDA you did in the previous...\n",
       "1423  0xp Having explored the Congressional voting r...\n",
       "1425  0xp Having fit a k-NN classifier, you can now ...\n",
       "1426  100xp Up until now, you have been performing b...\n",
       "1428  100xp Now that you have learned about the impo...\n",
       "1430  100xp Remember the model complexity curve that...\n",
       "1432  100xp In this chapter, you will work with Gapm...\n",
       "1434  100xp Now, you will fit a linear regression an...\n",
       "1436  100xp As you learned in Chapter 1, train and t...\n",
       "1438  100xp Cross-validation is a vital step in eval...\n",
       "1440  100xp Cross validation is essential but do not...\n",
       "1443  0xp In the video, you saw how Lasso selected o...\n",
       "1445  100xp Lasso is great for feature selection, bu...\n",
       "1448  100xp In Chapter 1, you evaluated the performa...\n",
       "1450  100xp Time to build your first logistic regres...\n",
       "1452  100xp Great job in the previous exercise - you...\n",
       "1454  100xp Say you have a binary classifier that in...\n",
       "1456  100xp Hugo demonstrated how to use to tune the...\n",
       "1458  100xp GridSearchCV can be computationally expe...\n",
       "1460  100xp You will now practice evaluating a model...\n",
       "1462  100xp Remember lasso and ridge regression from...\n",
       "1464  0xp The Gapminder dataset that you worked with...\n",
       "1466  100xp As Andy discussed in the video, scikit-l...\n",
       "1468  100xp Having created the dummy variables from ...\n",
       "1470  100xp The voting dataset from Chapter 1 contai...\n",
       "1472  100xp As you've come to appreciate, there are ...\n",
       "1474  100xp Having setup the steps of the pipeline i...\n",
       "1476  100xp In the video, Hugo demonstrated how sign...\n",
       "1478  100xp With regard to whether or not scaling is...\n",
       "1480  100xp It is time now to piece together everyth...\n",
       "1482  100xp For this final exercise, you will return...\n",
       "1486  100XP Import: matplotlib.pyplot as plt. pearso...\n",
       "1488  100XP Import PCA from sklearn.decomposition. C...\n",
       "1492  100XP Make a scatter plot of the grain measure...\n",
       "1494  100XP Create an instance of StandardScaler cal...\n",
       "1498  100XP Import PCA from sklearn.decomposition. C...\n",
       "1500  100XP Import TfidfVectorizer from sklearn.feat...\n",
       "1502  100XP Import: TruncatedSVD from sklearn.decomp...\n",
       "1504  100XP Import pandas as pd. Fit the pipeline to...\n",
       "1507  100XP Import NMF from sklearn.decomposition. C...\n",
       "1509  100XP Import pandas as pd. Create a DataFrame ...\n",
       "1512  100XP Import pandas as pd. Create a DataFrame ...\n",
       "1514  100XP Import matplotlib.pyplot as plt. Select ...\n",
       "1517  100XP Import NMF from sklearn.decomposition. C...\n",
       "1519  100XP Import PCA from sklearn.decomposition. C...\n",
       "1522  100XP Import: NMF from sklearn.decomposition. ...\n",
       "1524  100XP Import pandas as pd. Create a DataFrame ..."
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a18c3518-2ac1-480a-89f9-9911b201c329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50xp In this chapter, you're going to look at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50xp In the previous exercise, you identified ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>100xp As you've seen, .describe() can only be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>100xp Up until now, you've been looking at des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>100xp Histograms are great ways of visualizing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>100xp Boxplots are great when you have a numer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>100xp Melting data is the process of turning c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>100xp When melting DataFrames, it would be bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16</td>\n",
       "      <td>100xp Pivoting data is the opposite of melting...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18</td>\n",
       "      <td>100xp After pivoting airquality_melt in the pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21</td>\n",
       "      <td>100xp The dataset you saw in the video, consis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>100xp Another common way multiple variables ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25</td>\n",
       "      <td>100xp The dataset you'll be working with here ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>27</td>\n",
       "      <td>100xp Think of column-wise concatenation of da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>29</td>\n",
       "      <td>100xp You're now going to practice using the g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31</td>\n",
       "      <td>100xp Now that you have a list of filenames to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33</td>\n",
       "      <td>100xp Merging data allows you to combine dispa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>35</td>\n",
       "      <td>100xp In a many-to-one (or one-to-many) merge,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>37</td>\n",
       "      <td>100xp The final merging scenario occurs when b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>39</td>\n",
       "      <td>100xp In this exercise, you'll see how ensurin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>41</td>\n",
       "      <td>100xp If you expect the data type of a column ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>43</td>\n",
       "      <td>100xp In the video, Dan introduced you to the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>45</td>\n",
       "      <td>100xp Extracting numbers from strings is a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>47</td>\n",
       "      <td>100xp In this exercise, you'll continue practi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>49</td>\n",
       "      <td>100xp You'll now practice writing functions to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>51</td>\n",
       "      <td>100xp You'll now be introduced to a powerful P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>56</td>\n",
       "      <td>100xp Duplicate data causes a variety of probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>58</td>\n",
       "      <td>100xp Here, you'll return to the airquality da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>0xp Here, you'll practice writing assert state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>62</td>\n",
       "      <td>100xp In this exercise, you'll write code to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>65</td>\n",
       "      <td>0xp As Dan explained to you in the video, an \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>67</td>\n",
       "      <td>100xp You'll now define a function called pred...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>69</td>\n",
       "      <td>100xp In this exercise, you'll write code to d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>71</td>\n",
       "      <td>100xp Now you'll get to change weights in a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>73</td>\n",
       "      <td>100xp You've seen how different weights will h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>75</td>\n",
       "      <td>100xp You're now going to practice calculating...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>77</td>\n",
       "      <td>100xp Hurray! You've just calculated the slope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>79</td>\n",
       "      <td>100xp You're now going to make multiple update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>81</td>\n",
       "      <td>100xp Now you'll get to work with your first m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>83</td>\n",
       "      <td>100xp You're now going to compile the model yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>85</td>\n",
       "      <td>100xp You're at the most fun part. You'll now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>87</td>\n",
       "      <td>100xp You'll now create a classification model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>89</td>\n",
       "      <td>100xp The trained network from your previous c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>91</td>\n",
       "      <td>100xp It's time to get your hands dirty with o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>93</td>\n",
       "      <td>100xp Now it's your turn to monitor model accu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>95</td>\n",
       "      <td>100xp Now that you know how to monitor your mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>97</td>\n",
       "      <td>0xp Now you know everything you need to begin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>99</td>\n",
       "      <td>100xp You've seen how to experiment with wider...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>101</td>\n",
       "      <td>0xp You've reached the final exercise of the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>103</td>\n",
       "      <td>100xp In this exercise, you'll be working with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>105</td>\n",
       "      <td>100xp For large files, we may not want to prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>109</td>\n",
       "      <td>100xp In this exercise, you're now going to lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>111</td>\n",
       "      <td>100xp What if there are rows, such as a header...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>113</td>\n",
       "      <td>100xp The file seaslug.txt has a text header, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>117</td>\n",
       "      <td>100xp You have just used np.genfromtxt() to im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>119</td>\n",
       "      <td>100xp In the last exercise, you were able to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>123</td>\n",
       "      <td>100xp The pandas package is also great at deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>125</td>\n",
       "      <td>100xp There are a number of datatypes that can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>127</td>\n",
       "      <td>100xp Whether you like it or not, any working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>129</td>\n",
       "      <td>100xp In the previous exercises, you saw that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>131</td>\n",
       "      <td>100xp Here, you'll parse your spreadsheets and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>133</td>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>136</td>\n",
       "      <td>100xp Here, you'll gain expertise in importing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>138</td>\n",
       "      <td>100xp The file 'LIGO_data.hdf5' is already in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>140</td>\n",
       "      <td>100xp In this exercise, you'll extract some of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>142</td>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>144</td>\n",
       "      <td>100xp Here, you'll discover what is in the MAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>147</td>\n",
       "      <td>100xp Here, you're going to fire up your very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>150</td>\n",
       "      <td>100xp In this exercise, you'll once again crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>152</td>\n",
       "      <td>0xp Now, it's time for liftoff! In this exerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>154</td>\n",
       "      <td>100xp Congratulations on executing your first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>161</td>\n",
       "      <td>100xp You can now execute a basic SQL query to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>165</td>\n",
       "      <td>100xp You can also order your SQL query result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>169</td>\n",
       "      <td>100xp Here, you'll become more familiar with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>171</td>\n",
       "      <td>100xp Here, you'll perform your first INNER JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>174</td>\n",
       "      <td>100xp Congrats on performing your first INNER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>177</td>\n",
       "      <td>100xp In this exercise, you'll be working with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>179</td>\n",
       "      <td>100xp For large files, we may not want to prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>183</td>\n",
       "      <td>100xp In this exercise, you're now going to lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>185</td>\n",
       "      <td>100xp What if there are rows, such as a header...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>187</td>\n",
       "      <td>100xp The file seaslug.txt has a text header, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>191</td>\n",
       "      <td>100xp You have just used np.genfromtxt() to im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>193</td>\n",
       "      <td>100xp In the last exercise, you were able to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>197</td>\n",
       "      <td>100xp The pandas package is also great at deal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>199</td>\n",
       "      <td>100xp There are a number of datatypes that can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>201</td>\n",
       "      <td>100xp Whether you like it or not, any working ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>203</td>\n",
       "      <td>100xp In the previous exercises, you saw that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>205</td>\n",
       "      <td>100xp Here, you'll parse your spreadsheets and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>207</td>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>210</td>\n",
       "      <td>100xp Here, you'll gain expertise in importing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>212</td>\n",
       "      <td>100xp The file 'LIGO_data.hdf5' is already in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>214</td>\n",
       "      <td>100xp In this exercise, you'll extract some of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>216</td>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>218</td>\n",
       "      <td>100xp Here, you'll discover what is in the MAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>221</td>\n",
       "      <td>100xp Here, you're going to fire up your very ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>224</td>\n",
       "      <td>100xp In this exercise, you'll once again crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>226</td>\n",
       "      <td>0xp Now, it's time for liftoff! In this exerci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>228</td>\n",
       "      <td>100xp Congratulations on executing your first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>235</td>\n",
       "      <td>100xp You can now execute a basic SQL query to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>239</td>\n",
       "      <td>100xp You can also order your SQL query result...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>243</td>\n",
       "      <td>100xp Here, you'll become more familiar with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>245</td>\n",
       "      <td>100xp Here, you'll perform your first INNER JO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>248</td>\n",
       "      <td>100xp Congrats on performing your first INNER ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>251</td>\n",
       "      <td>100xp You are about to import your first file ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>254</td>\n",
       "      <td>100xp You have just imported a file from the w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>256</td>\n",
       "      <td>100xp Congrats! You've just loaded a flat file...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>259</td>\n",
       "      <td>100xp Now that you know the basics behind HTTP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>261</td>\n",
       "      <td>100xp You have just packaged and sent a GET re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>263</td>\n",
       "      <td>100xp Now that you've got your head and hands ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>265</td>\n",
       "      <td>100xp In this interactive exercise, you'll lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>267</td>\n",
       "      <td>100xp As promised, in the following exercises,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>269</td>\n",
       "      <td>100xp In this exercise, you'll figure out how ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>271</td>\n",
       "      <td>0xp Now that you know what a JSON is, you'll l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>273</td>\n",
       "      <td>100xp Now it's your turn to pull some movie da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>275</td>\n",
       "      <td>100xp Wow, congrats! You've just queried your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>277</td>\n",
       "      <td>100xp You're doing so well and having so much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>279</td>\n",
       "      <td>100xp The package tweepy is great at handling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>281</td>\n",
       "      <td>100xp Now that you have set up your authentica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>283</td>\n",
       "      <td>100xp Now that you've got your Twitter data si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>285</td>\n",
       "      <td>100xp Now you have the Twitter data in a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>287</td>\n",
       "      <td>100xp Now that you have your DataFrame of twee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>291</td>\n",
       "      <td>100xp Now that you have the number of tweets t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>294</td>\n",
       "      <td>100XP Import the figure function from bokeh.pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>296</td>\n",
       "      <td>100XP Create the figure p with the figure() fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>298</td>\n",
       "      <td>100XP Using the Latin America data (fertility_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>300</td>\n",
       "      <td>100XP Import the figure function from bokeh.pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>302</td>\n",
       "      <td>100XP Plot date along the x-axis and price alo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>304</td>\n",
       "      <td>100XP Create a list of the longitude positions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>306</td>\n",
       "      <td>100XP Import numpy as np. Create an array x us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>308</td>\n",
       "      <td>100XP Import pandas as pd. Use the read_csv() ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>310</td>\n",
       "      <td>100XP Import the ColumnDataSource class from b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>312</td>\n",
       "      <td>100XP Create a figure p with an x-axis label o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>314</td>\n",
       "      <td>100XP Import HoverTool from bokeh.models. Add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>316</td>\n",
       "      <td>100XP Import CategoricalColorMapper from bokeh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>318</td>\n",
       "      <td>100XP Import row from the bokeh.layouts module...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>320</td>\n",
       "      <td>100XP Import column from the bokeh.layouts mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>322</td>\n",
       "      <td>100XP Import row and column from bokeh.layouts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>324</td>\n",
       "      <td>100XP Import gridplot from the bokeh.layouts m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>326</td>\n",
       "      <td>100XP Import Panel from bokeh.models.widgets. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>328</td>\n",
       "      <td>100XP Import Tabs from bokeh.models.widgets. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>330</td>\n",
       "      <td>100XP Link the x_range of p2 to p1. Link the y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>332</td>\n",
       "      <td>100XP Create a ColumnDataSource object called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>334</td>\n",
       "      <td>100XP Add a red circle glyph to the figure p u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>336</td>\n",
       "      <td>100XP Use p.legend.location to adjust the lege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>338</td>\n",
       "      <td>100XP Import the HoverTool class from bokeh.mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>340</td>\n",
       "      <td>100XP Import curdoc from bokeh.io and figure f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>342</td>\n",
       "      <td>100XP Import curdoc from bokeh.io, widgetbox f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>344</td>\n",
       "      <td>100XP Create the first slider, slider1, using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>346</td>\n",
       "      <td>100XP Create a ColumnDataSource called source....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>348</td>\n",
       "      <td>100XP Define a callback function callback with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>350</td>\n",
       "      <td>100XP Define a callback function called update...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>352</td>\n",
       "      <td>100XP Create select1, the first dropdown selec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>354</td>\n",
       "      <td>0XP Create a button called button using the fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>356</td>\n",
       "      <td>100XP Import CheckboxGroup, RadioGroup, Toggle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>358</td>\n",
       "      <td>100XP Import output_file and show from bokeh.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>360</td>\n",
       "      <td>100XP Make a ColumnDataSource object called so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>362</td>\n",
       "      <td>100XP Make a list of the unique values from th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>364</td>\n",
       "      <td>100XP Import the widgetbox and row functions f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>366</td>\n",
       "      <td>100XP Define the update_plot callback function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>368</td>\n",
       "      <td>100XP Import HoverTool from bokeh.models. Crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>370</td>\n",
       "      <td>100XP Inside the update_plot() callback functi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>371</td>\n",
       "      <td>100xp With matplotlib, you can create a bunch ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>374</td>\n",
       "      <td>100xp Now that you've built your first line pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>376</td>\n",
       "      <td>100xp When you have a time scale along the hor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>379</td>\n",
       "      <td>100xp In the previous exercise, you saw that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>381</td>\n",
       "      <td>100xp life_exp, the list containing data on th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>383</td>\n",
       "      <td>100xp In the previous exercise, you didn't spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>386</td>\n",
       "      <td>100xp It's time to customize your own plot. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>388</td>\n",
       "      <td>100xp The customizations you've coded up to no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>391</td>\n",
       "      <td>100xp Right now, the scatter plot is just a cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>393</td>\n",
       "      <td>100xp The code you've written up to now is ava...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>396</td>\n",
       "      <td>100xp If you have another look at the script, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>398</td>\n",
       "      <td>100xp To see why dictionaries are useful, have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>400</td>\n",
       "      <td>100xp The countries and capitals lists are aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>402</td>\n",
       "      <td>100xp If the keys of a dictionary are chosen w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>405</td>\n",
       "      <td>0xp If you know how to access a dictionary, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>407</td>\n",
       "      <td>100xp Somebody thought it would be funny to me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>409</td>\n",
       "      <td>100xp Remember lists? They could contain anyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>411</td>\n",
       "      <td>100xp Pandas is an open source library, provid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>413</td>\n",
       "      <td>100xp The Python code that solves the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>415</td>\n",
       "      <td>100xp Putting data in a dictionary and then bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>416</td>\n",
       "      <td>100xp Your read_csv() call to import the CSV d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>418</td>\n",
       "      <td>100xp In the video, you saw that you can index...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>421</td>\n",
       "      <td>100xp Square brackets can do more than just se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>424</td>\n",
       "      <td>100xp With loc and iloc you can do practically...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>429</td>\n",
       "      <td>100xp loc and iloc also allow you to select bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>433</td>\n",
       "      <td>100xp It's also possible to select only column...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>436</td>\n",
       "      <td>100xp To check if two Python values, or variab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>439</td>\n",
       "      <td>100xp In the video, Filip also talked about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>442</td>\n",
       "      <td>100xp Out of the box, you can also use compari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>444</td>\n",
       "      <td>100xp A boolean is either 1 or 0, True or Fals...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>448</td>\n",
       "      <td>100xp It's time to take a closer look around i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>450</td>\n",
       "      <td>100xp On the right, the if construct for room ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>452</td>\n",
       "      <td>100xp It's also possible to have a look around...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>454</td>\n",
       "      <td>100xp Remember that cars dataset, containing t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>456</td>\n",
       "      <td>100xp The code in the previous example worked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>458</td>\n",
       "      <td>100xp Let's stick to the cars data some more. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>460</td>\n",
       "      <td>100xp Remember about np.logical_and(), np.logi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>462</td>\n",
       "      <td>100xp Below you can find the example from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>464</td>\n",
       "      <td>100xp The while loop that corrects the offset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>465</td>\n",
       "      <td>100xp Have another look at the for loop that F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>468</td>\n",
       "      <td>100xp Using a for loop to iterate over a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>470</td>\n",
       "      <td>100xp For non-programmer folks, room 0: 11.25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>472</td>\n",
       "      <td>100xp Remember the house variable from the Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>474</td>\n",
       "      <td>100xp In Python 3, you need the items() method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>478</td>\n",
       "      <td>100xp If you're dealing with a 1D Numpy array,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>482</td>\n",
       "      <td>100xp Iterating over a Pandas DataFrame is typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>485</td>\n",
       "      <td>100xp The row data that's generated by iterrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>487</td>\n",
       "      <td>0xp In the video, Filip showed you how to add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>490</td>\n",
       "      <td>100xp Using iterrows() to iterate over every o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>494</td>\n",
       "      <td>100xp Below you can find the example from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>497</td>\n",
       "      <td>100xp The while loop that corrects the offset ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>499</td>\n",
       "      <td>100xp Have another look at the for loop that F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>502</td>\n",
       "      <td>100xp Using a for loop to iterate over a list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>504</td>\n",
       "      <td>100xp For non-programmer folks, room 0: 11.25 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>506</td>\n",
       "      <td>100xp Remember the house variable from the Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>508</td>\n",
       "      <td>100xp In Python 3, you need the items() method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>512</td>\n",
       "      <td>100xp If you're dealing with a 1D Numpy array,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>516</td>\n",
       "      <td>100xp Iterating over a Pandas DataFrame is typ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>519</td>\n",
       "      <td>100xp The row data that's generated by iterrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>521</td>\n",
       "      <td>0xp In the video, Filip showed you how to add ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>524</td>\n",
       "      <td>100xp Using iterrows() to iterate over every o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>528</td>\n",
       "      <td>100xp Randomness has many uses in science, art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>530</td>\n",
       "      <td>100xp In the previous exercise, you used rand(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>533</td>\n",
       "      <td>100xp In the Empire State Building bet, your n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>535</td>\n",
       "      <td>100xp Before, you have already written Python ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>537</td>\n",
       "      <td>0xp Things are shaping up nicely! You already ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>539</td>\n",
       "      <td>100xp Let's visualize this random walk! Rememb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>542</td>\n",
       "      <td>100xp A single random walk is one thing, but t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>544</td>\n",
       "      <td>100xp all_walks is a list of lists: every sub-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>548</td>\n",
       "      <td>100xp With this neatly written code of yours, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>550</td>\n",
       "      <td>100xp All these fancy visualizations have put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>574</td>\n",
       "      <td>100xp Subsetting Python lists is a piece of ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>583</td>\n",
       "      <td>50xp You saw before that a Python list can con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>586</td>\n",
       "      <td>100xp Replacing list elements is pretty easy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>589</td>\n",
       "      <td>100xp If you can change elements in a list, yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>597</td>\n",
       "      <td>100xp Out of the box, Python offers a bunch of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>599</td>\n",
       "      <td>50xp Maybe you already know the name of a Pyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>602</td>\n",
       "      <td>100xp In the previous exercise, the square bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>604</td>\n",
       "      <td>100xp Strings come with a bunch of methods. Fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>605</td>\n",
       "      <td>100xp Strings are not the only Python types th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>607</td>\n",
       "      <td>100xp Most list methods will change the list t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>608</td>\n",
       "      <td>100xp As a data scientist, some notions of geo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>609</td>\n",
       "      <td>100xp General imports, like import math, make ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>611</td>\n",
       "      <td>50xp There are several ways to import packages...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>613</td>\n",
       "      <td>100xp We're going to dive into the world of ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>614</td>\n",
       "      <td>100xp You are a huge baseball fan. You decide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>615</td>\n",
       "      <td>100xp The MLB also offers to let you analyze t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>616</td>\n",
       "      <td>100xp To subset both regular Python lists and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>619</td>\n",
       "      <td>100xp You've seen it with your own eyes: Pytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>622</td>\n",
       "      <td>100xp Before working on the actual MLB data, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>623</td>\n",
       "      <td>100xp You have another look at the MLB data an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>624</td>\n",
       "      <td>100xp If your 2D Numpy array has a regular str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>628</td>\n",
       "      <td>100xp Remember how you calculated the Body Mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>630</td>\n",
       "      <td>100xp You now know how to use Numpy functions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>632</td>\n",
       "      <td>0xp Because the mean and median are so far apa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>633</td>\n",
       "      <td>100xp In the last few exercises you've learned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>635</td>\n",
       "      <td>0XP Import create_engine from the sqlalchemy m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>637</td>\n",
       "      <td>100XP Import the Table object from sqlalchemy....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>639</td>\n",
       "      <td>100XP Reflect the census table as you did in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>641</td>\n",
       "      <td>100XP Build a SQL statement to query all the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>643</td>\n",
       "      <td>100XP Import select from the sqlalchemy module...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>645</td>\n",
       "      <td>100XP Extract the first row of results and ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>647</td>\n",
       "      <td>50XP Import create_engine from sqlalchemy. Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>649</td>\n",
       "      <td>100XP Select all records from the census table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>651</td>\n",
       "      <td>100XP Select all records from the census table...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>653</td>\n",
       "      <td>100XP Import and_ from the sqlalchemy module. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>655</td>\n",
       "      <td>100XP Select all records of the state column f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>657</td>\n",
       "      <td>100XP Import desc from the sqlalchemy module. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>659</td>\n",
       "      <td>100XP Select all records of the state and age ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>664</td>\n",
       "      <td>100XP Build a select statement to count the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>668</td>\n",
       "      <td>100XP Import func from sqlalchemy. Build an ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>670</td>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>672</td>\n",
       "      <td>100XP Import matplotlib.pyplot as plt. Create ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>674</td>\n",
       "      <td>100XP Import the create_engine function from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>676</td>\n",
       "      <td>100XP Define a select statement called stmt to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>678</td>\n",
       "      <td>100XP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>682</td>\n",
       "      <td>100XP Build a statement to join the census and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>684</td>\n",
       "      <td>100XP Build a statement to select ALL the colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>686</td>\n",
       "      <td>100XP Build a statement to select: The state c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>690</td>\n",
       "      <td>100XP Save an alias of the employees table as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>692</td>\n",
       "      <td>100XP Use a while loop that checks if there ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>694</td>\n",
       "      <td>100XP Import Table, Column, String, Integer, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>696</td>\n",
       "      <td>100XP Table, Column, String, Integer, Float, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>698</td>\n",
       "      <td>100XP Import insert and select from the sqlalc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>700</td>\n",
       "      <td>100XP Build a list of dictionaries called valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>702</td>\n",
       "      <td>100XP Create a statement for bulk insert into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>705</td>\n",
       "      <td>100XP Build a statement to select all columns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>707</td>\n",
       "      <td>100XP Build an update statement to update the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>709</td>\n",
       "      <td>100XP Build a statement to select the name col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>712</td>\n",
       "      <td>100XP Import delete and select from sqlalchemy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>715</td>\n",
       "      <td>100XP Build a delete statement to remove data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>717</td>\n",
       "      <td>100XP Drop the state_fact table by applying th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>719</td>\n",
       "      <td>100XP Import create_engine and MetaData from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>721</td>\n",
       "      <td>100XP Import Table, Column, String, and Intege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>723</td>\n",
       "      <td>100XP Create an empty list called values_list....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>725</td>\n",
       "      <td>100XP Import insert from sqlalchemy. Build an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>727</td>\n",
       "      <td>100XP Import select from sqlalchemy. Build a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>729</td>\n",
       "      <td>100XP Import case, cast and Float from sqlalch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>731</td>\n",
       "      <td>100XP Build a statement to: Select state. Calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>733</td>\n",
       "      <td>100XP Import matplotlib.pyplot as its usual al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>735</td>\n",
       "      <td>100XP Create a set of plot axes with lower cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>737</td>\n",
       "      <td>100XP Use plt.subplot() to create a figure wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>739</td>\n",
       "      <td>100XP Create a figure with 2Ã—22Ã—2 subplot layo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>741</td>\n",
       "      <td>100XP Use plt.xlim() to set the x-axis range t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>743</td>\n",
       "      <td>100XP Use plt.axis() to select the time period...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>745</td>\n",
       "      <td>100XP Modify the plot command provided that dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>747</td>\n",
       "      <td>100XP Compute the maximum enrollment of women ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>749</td>\n",
       "      <td>100XP Import matplotlib.pyplot as its usual al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>752</td>\n",
       "      <td>100XP Import the numpy and matplotlib.pyplot m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>754</td>\n",
       "      <td>100XP Using the meshgrid X, Y as axes: Generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>756</td>\n",
       "      <td>100XP Modify the call to plt.contourf() so the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>758</td>\n",
       "      <td>100XP Generate a two-dimensional histogram to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>760</td>\n",
       "      <td>100XP Generate a two-dimensional histogram wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>762</td>\n",
       "      <td>100XP Load the file '480px-Astronaut-EVA.jpg' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>764</td>\n",
       "      <td>100XP Print the shape of the existing image ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>766</td>\n",
       "      <td>100XP Display img in the top left subplot with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>768</td>\n",
       "      <td>100XP Use the methods .min() and .max() to sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>770</td>\n",
       "      <td>100XP Import matplotlib.pyplot and seaborn usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>772</td>\n",
       "      <td>100XP Import matplotlib.pyplot and seaborn usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>774</td>\n",
       "      <td>100XP Modify the call to plt.scatter() to plot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>776</td>\n",
       "      <td>100XP Plot a linear regression between 'weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>778</td>\n",
       "      <td>100XP Plot linear regressions of 'hp' (on the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>780</td>\n",
       "      <td>100XP In the first row of subplots, make a str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>782</td>\n",
       "      <td>100XP In the first row of subplots, make a swa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>784</td>\n",
       "      <td>100XP In the first row of subplots, make a vio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>786</td>\n",
       "      <td>100XP Use sns.jointplot() to visualize the joi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>788</td>\n",
       "      <td>100XP Create a hexbin plot of the joint distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>790</td>\n",
       "      <td>100XP Print the first five rows of the DataFra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>792</td>\n",
       "      <td>100XP Plot the pairwise joint distributions se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>794</td>\n",
       "      <td>100XP Print the covariance matrix cov_matrix t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>797</td>\n",
       "      <td>100XP Plot the aapl time series in blue with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>799</td>\n",
       "      <td>100XP Plot the series aapl in 'blue' in the to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>801</td>\n",
       "      <td>100XP Extract a slice named view from the seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>803</td>\n",
       "      <td>100XP Extract a slice of series aapl from Nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>805</td>\n",
       "      <td>100XP In the top left subplot, plot the 30-day...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>807</td>\n",
       "      <td>100XP Produce a single plot with four curves o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>809</td>\n",
       "      <td>100XP Load data from the file '640px-Unequaliz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>811</td>\n",
       "      <td>100XP First, use plt.hist() to plot the histog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>813</td>\n",
       "      <td>100XP Use the NumPy array method .reshape() to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>815</td>\n",
       "      <td>100XP Display image in the top subplot of a 2Ã—...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>817</td>\n",
       "      <td>100XP Make a 2-D histogram in the top left sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>820</td>\n",
       "      <td>100XP Import the create_engine function from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>822</td>\n",
       "      <td>100XP Define a select statement called stmt to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>824</td>\n",
       "      <td>100XP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>828</td>\n",
       "      <td>100XP Build a statement to join the census and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>830</td>\n",
       "      <td>100XP Build a statement to select ALL the colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>832</td>\n",
       "      <td>100XP Build a statement to select: The state c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>836</td>\n",
       "      <td>100XP Save an alias of the employees table as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>838</td>\n",
       "      <td>100XP Use a while loop that checks if there ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>840</td>\n",
       "      <td>100XP Import Table, Column, String, Integer, F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>842</td>\n",
       "      <td>100XP Table, Column, String, Integer, Float, B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>844</td>\n",
       "      <td>100XP Import insert and select from the sqlalc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>846</td>\n",
       "      <td>100XP Build a list of dictionaries called valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>848</td>\n",
       "      <td>100XP Create a statement for bulk insert into ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>851</td>\n",
       "      <td>100XP Build a statement to select all columns ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>853</td>\n",
       "      <td>100XP Build an update statement to update the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>855</td>\n",
       "      <td>100XP Build a statement to select the name col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>858</td>\n",
       "      <td>100XP Import delete and select from sqlalchemy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>861</td>\n",
       "      <td>100XP Build a delete statement to remove data ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>863</td>\n",
       "      <td>100XP Drop the state_fact table by applying th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>865</td>\n",
       "      <td>100XP Import create_engine and MetaData from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>867</td>\n",
       "      <td>100XP Import Table, Column, String, and Intege...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>869</td>\n",
       "      <td>100XP Create an empty list called values_list....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>871</td>\n",
       "      <td>100XP Import insert from sqlalchemy. Build an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>873</td>\n",
       "      <td>100XP Import select from sqlalchemy. Build a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>875</td>\n",
       "      <td>100XP Import case, cast and Float from sqlalch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>877</td>\n",
       "      <td>100XP Build a statement to: Select state. Calc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>885</td>\n",
       "      <td>100XP Print summary statistics of the numeric ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>888</td>\n",
       "      <td>100XP Define the lambda function categorize_la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>890</td>\n",
       "      <td>100XP Create the DataFrame num_unique_labels b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>893</td>\n",
       "      <td>100XP Using the compute_log_loss() function, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>895</td>\n",
       "      <td>100XP Create a new DataFrame named numeric_dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>897</td>\n",
       "      <td>100XP Import LogisticRegression from sklearn.l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>899</td>\n",
       "      <td>100XP Read HoldoutData.csv into a DataFrame ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>901</td>\n",
       "      <td>100XP Create the prediction_df DataFrame by sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>903</td>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>905</td>\n",
       "      <td>100XP Use the .drop() method on data_frame wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>907</td>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>909</td>\n",
       "      <td>100XP Import Pipeline from sklearn.pipeline. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>911</td>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>913</td>\n",
       "      <td>100XP Compute the selector get_text_data by us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>915</td>\n",
       "      <td>100XP In the process_and_join_features: Add th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>917</td>\n",
       "      <td>100XP Complete the call to multilabel_train_te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>919</td>\n",
       "      <td>100XP Complete the 'numeric_features' transfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>921</td>\n",
       "      <td>100XP Import the RandomForestClassifier from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>923</td>\n",
       "      <td>100XP Import the RandomForestClassifier from s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>928</td>\n",
       "      <td>100XP Create text_vector by preprocessing X_tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>930</td>\n",
       "      <td>100XP Import CountVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>934</td>\n",
       "      <td>100XP Add the interaction terms step using Spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>938</td>\n",
       "      <td>100XP Import HashingVectorizer from sklearn.fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>940</td>\n",
       "      <td>100XP Import HashingVectorizer from sklearn.fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>941</td>\n",
       "      <td>100xp As you saw in the video, loading data fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>943</td>\n",
       "      <td>100xp In this exercise, you'll combine the thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>945</td>\n",
       "      <td>0xp It is often useful to rearrange the sequen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>947</td>\n",
       "      <td>100xp Sorting methods are not the only way to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>949</td>\n",
       "      <td>100xp Another common technique is to reindex a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>952</td>\n",
       "      <td>100xp In this exercise, you'll work with weath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>954</td>\n",
       "      <td>100xp Your job in this exercise is to compute ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>961</td>\n",
       "      <td>100XP Create an empty list called units. This ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>963</td>\n",
       "      <td>100XP Create a 'year' column in the DataFrames...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>965</td>\n",
       "      <td>100XP Create a new DataFrame called weather by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>967</td>\n",
       "      <td>100XP Iterate over medal_types in the for loop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>969</td>\n",
       "      <td>100XP Within the for loop: Read file_name into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>971</td>\n",
       "      <td>100XP Create a new DataFrame medals_sorted wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>973</td>\n",
       "      <td>100XP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>976</td>\n",
       "      <td>100XP Create a list called month_list consisti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>978</td>\n",
       "      <td>100XP Construct a list of DataFrames called me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>980</td>\n",
       "      <td>100XP Make a new DataFrame china_annual by res...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>982</td>\n",
       "      <td>100XP Using pd.merge(), merge the DataFrames r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>986</td>\n",
       "      <td>100XP Merge the DataFrames revenue and manager...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>988</td>\n",
       "      <td>100XP Create a column called 'state' in the Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>993</td>\n",
       "      <td>100XP Execute a right merge using pd.merge() w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>995</td>\n",
       "      <td>100XP Merge sales_and_managers with revenue_an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>997</td>\n",
       "      <td>100XP Perform an ordered merge on austin and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>999</td>\n",
       "      <td>100XP Merge auto and oil using pd.merge_asof()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1001</td>\n",
       "      <td>100XP Read file_path into a DataFrame called e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1003</td>\n",
       "      <td>100XP Read file_path into a DataFrame called i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>1005</td>\n",
       "      <td>100XP Within the for loop: Create the file pat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1007</td>\n",
       "      <td>0XP Construct a pivot table from the DataFrame...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>1009</td>\n",
       "      <td>100XP Set the index of the DataFrame editions ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>1011</td>\n",
       "      <td>100XP Create mean_fractions by chaining the me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>1013</td>\n",
       "      <td>0XP Create the DataFrame hosts by doing a left...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1015</td>\n",
       "      <td>100XP Create a DataFrame reshaped by reshaping...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1017</td>\n",
       "      <td>100XP Merge reshaped and hosts using an inner ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>1019</td>\n",
       "      <td>100XP Create a Series called change by extract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>1021</td>\n",
       "      <td>100xp Now you'll get a chance to write some re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>1022</td>\n",
       "      <td>100xp Here, you'll be using the first scene of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>1023</td>\n",
       "      <td>0xp In this exercise, you'll utilize re.search...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>1024</td>\n",
       "      <td>50xp Given the following string, which is the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>1025</td>\n",
       "      <td>100xp Twitter is a frequently used source for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1026</td>\n",
       "      <td>0xp In this exercise, you'll practice advanced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>1027</td>\n",
       "      <td>100xp Try using your new skills to find and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>1028</td>\n",
       "      <td>100xp In this exercise, you'll build your firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>1030</td>\n",
       "      <td>100xp Now, it's your turn to apply the techniq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1032</td>\n",
       "      <td>100xp It's time to apply the methods you learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1034</td>\n",
       "      <td>100xp Now, you'll use your new gensim corpus a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1038</td>\n",
       "      <td>100xp You're now going to have some fun with n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1040</td>\n",
       "      <td>100xp In this exercise, you'll use some extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1042</td>\n",
       "      <td>100xp Using the same text you used in the firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>1044</td>\n",
       "      <td>100xp In this exercise and the next, you'll us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>1046</td>\n",
       "      <td>0xp Here, you'll complete the work you began i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1048</td>\n",
       "      <td>100xp You'll continue your exploration of poly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>1050</td>\n",
       "      <td>100xp In the final exercise of this NER chapte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1052</td>\n",
       "      <td>100xp It's time to begin building your text cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>1054</td>\n",
       "      <td>100xp Similar to the sparse CountVectorizer cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>1056</td>\n",
       "      <td>100xp To get a better idea of how the vectors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1062</td>\n",
       "      <td>100xp Now it's your turn to train the \"fake ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>1064</td>\n",
       "      <td>100xp Now that you have evaluated the model us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>1066</td>\n",
       "      <td>100xp Your job in this exercise is to test a f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>1068</td>\n",
       "      <td>100xp Now that you have built a \"fake news\" cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>1073</td>\n",
       "      <td>100XP Import matplotlib.pyplot as plt and netw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>1075</td>\n",
       "      <td>100XP Use a list comprehension to get a list o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>1078</td>\n",
       "      <td>100XP Set the 'weight' attribute of the edge b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1080</td>\n",
       "      <td>100XP Define a function called find_selfloop_n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1082</td>\n",
       "      <td>100XP Import nxviz as nv. Plot the graph T as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1084</td>\n",
       "      <td>100XP Import CircosPlot from nxviz. Plot the T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>1086</td>\n",
       "      <td>100XP Import ArcPlot from nxviz. Create an un-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>1088</td>\n",
       "      <td>100XP Write a function called nodes_with_m_nbr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>1090</td>\n",
       "      <td>100XP Use a list comprehension along with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>1092</td>\n",
       "      <td>100XP Compute the degree centrality of the Twi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>1094</td>\n",
       "      <td>100XP Create a function called path_exists() t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>1096</td>\n",
       "      <td>100XP Using the .add() method, add the current...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>1098</td>\n",
       "      <td>100XP Check to see if the queue has been empti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1100</td>\n",
       "      <td>100XP Compute the betweenness centrality bet_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>1102</td>\n",
       "      <td>100XP Write a function find_nodes_with_highest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>1104</td>\n",
       "      <td>100XP Write a function find_node_with_highest_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>1106</td>\n",
       "      <td>100XP Import combinations from itertools. Writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>1108</td>\n",
       "      <td>100XP Write a function nodes_in_triangle() tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>1110</td>\n",
       "      <td>100XP Write a function node_in_open_triangle()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>1112</td>\n",
       "      <td>100XP Write a function maximal_cliques() that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1114</td>\n",
       "      <td>100XP Write a function get_nodes_and_nbrs(G, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1116</td>\n",
       "      <td>100XP Using a list comprehension, extract node...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1118</td>\n",
       "      <td>100XP Plot the degree distribution of the GitH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1120</td>\n",
       "      <td>100XP Plot the betweenness centrality distribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1122</td>\n",
       "      <td>100XP Make a MatrixPlot visualization of the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1124</td>\n",
       "      <td>100XP Make an ArcPlot of the GitHub collaborat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1126</td>\n",
       "      <td>100XP Make a CircosPlot of the network, again,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1128</td>\n",
       "      <td>100XP Count the number of maximal cliques pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1130</td>\n",
       "      <td>100XP Find the author(s) that are part of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1133</td>\n",
       "      <td>100XP Go out 1 degree of separation from the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1135</td>\n",
       "      <td>100XP Compile a list of GitHub users that shou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1136</td>\n",
       "      <td>100xp Pandas depends upon and interoperates wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1138</td>\n",
       "      <td>100xp In this exercise, you're going to make a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1139</td>\n",
       "      <td>100xp You can use the DataFrame attribute df.c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1140</td>\n",
       "      <td>100xp You can implicitly use 'broadcasting', a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1141</td>\n",
       "      <td>100xp In previous exercises, we have preloaded...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1142</td>\n",
       "      <td>100xp Not all data files are clean and tidy. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1143</td>\n",
       "      <td>100xp Data visualization is often a very effec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1144</td>\n",
       "      <td>100xp Comparing data from several columns can ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1145</td>\n",
       "      <td>100xp In the previous chapter, you saw that th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1146</td>\n",
       "      <td>100xp Pandas scatter plots are generated using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1147</td>\n",
       "      <td>100xp While pandas can plot multiple columns o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1148</td>\n",
       "      <td>100xp Pandas relies on the .hist() method to n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1150</td>\n",
       "      <td>100xp In this exercise, you will investigate s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1152</td>\n",
       "      <td>100xp In many data sets, there can be large di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1153</td>\n",
       "      <td>100xp In this exercise, you'll investigate the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1154</td>\n",
       "      <td>100xp Let's use the mean and standard deviatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1155</td>\n",
       "      <td>50xp How many automobiles were manufactured in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1157</td>\n",
       "      <td>100xp Let's use population filtering to determ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1158</td>\n",
       "      <td>100xp Population filtering can be used alongsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1159</td>\n",
       "      <td>100xp Pandas time series support \"partial stri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1161</td>\n",
       "      <td>100xp Reindexing is useful in preparation for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>1163</td>\n",
       "      <td>100xp Pandas provides methods for resampling t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1165</td>\n",
       "      <td>100xp With pandas, you can resample in differe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1167</td>\n",
       "      <td>100xp In this exercise, some hourly weather da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>1169</td>\n",
       "      <td>100xp As of pandas version 0.18.0, the interfa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1171</td>\n",
       "      <td>100xp We've seen that pandas supports method c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>1173</td>\n",
       "      <td>100xp One common application of interpolation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>1175</td>\n",
       "      <td>0xp Time zone handling with pandas typically a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1177</td>\n",
       "      <td>100xp Pandas handles datetimes not only in you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>1179</td>\n",
       "      <td>100xp Now that you have set the DatetimeIndex ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1181</td>\n",
       "      <td>100xp Now that you have identified the method ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>1183</td>\n",
       "      <td>100xp After the initial step of reading in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>1185</td>\n",
       "      <td>0xp In order to use the full power of pandas t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1187</td>\n",
       "      <td>100xp The numeric columns contain missing valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>1189</td>\n",
       "      <td>100xp Now that you have the data read and clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>1191</td>\n",
       "      <td>0xp You're now ready to compare the 2011 weath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>1193</td>\n",
       "      <td>100xp On average, how much hotter is it when t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>1195</td>\n",
       "      <td>100xp Is there a correlation between temperatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>1197</td>\n",
       "      <td>100xp In a previous exercise, you analyzed the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>1199</td>\n",
       "      <td>100xp Dew point is a measure of relative humid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>1201</td>\n",
       "      <td>100xp We already know that 2011 was hotter tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>1203</td>\n",
       "      <td>100xp Let's work more on your mastery of scope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>1204</td>\n",
       "      <td>0xp You've learned in the last video about nes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>1206</td>\n",
       "      <td>100xp Great job, you've just nested a function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>1208</td>\n",
       "      <td>100xp Let's once again work further on your ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>1210</td>\n",
       "      <td>100xp In the previous chapter, you've learned ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1212</td>\n",
       "      <td>100xp You've now defined a function that uses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>1214</td>\n",
       "      <td>100xp Flexible arguments enable you to pass a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>1216</td>\n",
       "      <td>100xp Let's push further on what you've learne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>1218</td>\n",
       "      <td>100xp Recall the Bringing it all together exer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>1220</td>\n",
       "      <td>100xp Wow, you've just generalized your Twitte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>1222</td>\n",
       "      <td>100xp Some function definitions are simple eno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>1224</td>\n",
       "      <td>100xp So far, you've used lambda functions to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>1227</td>\n",
       "      <td>100xp In the previous exercise, you used lambd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>1228</td>\n",
       "      <td>100xp You're getting very good at using lambda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>1231</td>\n",
       "      <td>100xp A good practice in writing your own func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>1232</td>\n",
       "      <td>100xp Another way to raise an error is by usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>1233</td>\n",
       "      <td>100xp This is awesome! You have now learned ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>1234</td>\n",
       "      <td>100xp Sometimes, we make mistakes when calling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1235</td>\n",
       "      <td>100xp In the previous exercise, you built on y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>1236</td>\n",
       "      <td>100xp Great, you're familiar with what iterabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1238</td>\n",
       "      <td>100xp One of the things you learned about in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1241</td>\n",
       "      <td>100xp You've been using the iter() function to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>1243</td>\n",
       "      <td>100xp You're really getting the hang of using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>1245</td>\n",
       "      <td>100xp Another interesting function that you've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>1247</td>\n",
       "      <td>100xp You know how to use zip() as well as how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>1249</td>\n",
       "      <td>100xp Sometimes, the data we have to process r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>1251</td>\n",
       "      <td>100xp Great job chunking out that file in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>1253</td>\n",
       "      <td>100xp You now have all the knowledge necessary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>1255</td>\n",
       "      <td>100xp Great! At this point, you have a good gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>1258</td>\n",
       "      <td>0xp You've been using list comprehensions to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1260</td>\n",
       "      <td>100xp In the previous exercise, you used an if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1262</td>\n",
       "      <td>100xp Comprehensions aren't relegated merely t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>1264</td>\n",
       "      <td>100xp You are familiar with what generators an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1266</td>\n",
       "      <td>100xp Great! At this point, you already know h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1268</td>\n",
       "      <td>100xp In previous exercises, you've dealt main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1270</td>\n",
       "      <td>0xp You will now make use of what you've learn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>1272</td>\n",
       "      <td>100xp Great, you've successfully extracted the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1274</td>\n",
       "      <td>0xp For this exercise, you'll use what you've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1276</td>\n",
       "      <td>100xp Suppose you needed to repeat the same pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>1278</td>\n",
       "      <td>100xp This time, you're going to use the lists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>1280</td>\n",
       "      <td>100xp You've zipped lists together, created a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1282</td>\n",
       "      <td>100xp Sometimes, data sources can be so large ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1284</td>\n",
       "      <td>100xp In the previous exercise, you processed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1286</td>\n",
       "      <td>100xp Great! You've just created a generator f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1288</td>\n",
       "      <td>100xp Another way to read data too large to st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1290</td>\n",
       "      <td>100xp In the previous exercise, you used read_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>1292</td>\n",
       "      <td>100xp You're getting used to reading and proce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>1294</td>\n",
       "      <td>100xp In the previous exercises, you've only p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1296</td>\n",
       "      <td>100xp This is the last leg. You've learned a l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>1300</td>\n",
       "      <td>100XP Seed the random number generator with 42...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1302</td>\n",
       "      <td>100XP Compute an ECDF from the actual time bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>1306</td>\n",
       "      <td>100XP Plot fertility (y-axis) versus illiterac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>1308</td>\n",
       "      <td>100XP Compute the slope and intercept of the r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>1310</td>\n",
       "      <td>100XP Specify the values of the slope for whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>1312</td>\n",
       "      <td>100XP Compute the parameters for the slope and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>1314</td>\n",
       "      <td>100XP Write a for loop to do the following for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>1316</td>\n",
       "      <td>100XP Write a for loop to acquire 50 bootstrap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1318</td>\n",
       "      <td>100XP Define a function with call signature dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>1320</td>\n",
       "      <td>100XP Draw 10000 bootstrap replicates of the m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>1322</td>\n",
       "      <td>100XP Draw 10000 bootstrap replicates of the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1324</td>\n",
       "      <td>100XP Generate 10000 bootstrap replicates of Ï„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>1326</td>\n",
       "      <td>100XP Define a function with call signature dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1328</td>\n",
       "      <td>100XP Use your draw_bs_pairs_linreg() function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>1330</td>\n",
       "      <td>100XP Generate an array of xx-values consistin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>1332</td>\n",
       "      <td>100XP Concatenate the two input arrays into on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>1334</td>\n",
       "      <td>100XP Write a for loop to 50 generate permutat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>1337</td>\n",
       "      <td>100XP Define a function with this signature: d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>1339</td>\n",
       "      <td>100XP Use sns.swarmplot() to make a bee swarm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>1341</td>\n",
       "      <td>100XP Define a function with call signature di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>1343</td>\n",
       "      <td>100XP Translate the impact forces of Frog B su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>1345</td>\n",
       "      <td>100XP Compute the observed difference in impac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>1347</td>\n",
       "      <td>100XP Compute the mean of all forces (from for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1349</td>\n",
       "      <td>100XP Construct Boolean arrays, dems and reps ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1351</td>\n",
       "      <td>100XP Compute the observed difference in mean ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1355</td>\n",
       "      <td>100XP Compute the observed Pearson correlation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1357</td>\n",
       "      <td>100XP Use your ecdf() function to generate x,y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1359</td>\n",
       "      <td>100XP Compute the mean alive sperm count of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1361</td>\n",
       "      <td>100XP Label the axes. Don't forget that you sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>1363</td>\n",
       "      <td>100XP Import numpy as np. This gives access to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>1365</td>\n",
       "      <td>100XP Use ecdf() to compute the ECDF of versic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>1368</td>\n",
       "      <td>100XP Define a function with the signature ecd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>1370</td>\n",
       "      <td>100XP Compute ECDFs for each of the three spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>1372</td>\n",
       "      <td>100XP Compute the mean petal length of Iris ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>1374</td>\n",
       "      <td>100XP Plot the percentiles as red diamonds on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>1376</td>\n",
       "      <td>100XP The set-up is exactly the same as for th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>1379</td>\n",
       "      <td>100XP Create an array called differences that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>1381</td>\n",
       "      <td>100XP Compute the variance of the data in the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>1383</td>\n",
       "      <td>100XP Use plt.plot() with the appropriate keyw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>1385</td>\n",
       "      <td>100XP Use np.cov() to compute the covariance m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>1387</td>\n",
       "      <td>100XP Define a function with signature pearson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1389</td>\n",
       "      <td>100XP Seed the random number generator using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1391</td>\n",
       "      <td>100XP Define a function with signature perform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>1393</td>\n",
       "      <td>100XP Seed the random number generator to 42. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>1395</td>\n",
       "      <td>100XP Compute the x and y values for the ECDF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>1397</td>\n",
       "      <td>100XP Draw samples out of the Binomial distrib...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>1399</td>\n",
       "      <td>100XP Using np.arange(), compute the bin edges...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>1401</td>\n",
       "      <td>100XP Using the np.random.poisson() function, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>1403</td>\n",
       "      <td>100XP Draw 10000 samples from a Poisson distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>1406</td>\n",
       "      <td>100XP Use your ecdf() function to generate x a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>1408</td>\n",
       "      <td>100XP Compute mean and standard deviation of B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>1410</td>\n",
       "      <td>100XP Take 1,000,000 samples from the normal d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>1412</td>\n",
       "      <td>100XP Define a function with call signature su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>1414</td>\n",
       "      <td>100XP Use your successive_poisson() function t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>1415</td>\n",
       "      <td>100xp In this chapter, you'll be working with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>1421</td>\n",
       "      <td>50xp The Numerical EDA you did in the previous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>1423</td>\n",
       "      <td>0xp Having explored the Congressional voting r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>1425</td>\n",
       "      <td>0xp Having fit a k-NN classifier, you can now ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>1426</td>\n",
       "      <td>100xp Up until now, you have been performing b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1428</td>\n",
       "      <td>100xp Now that you have learned about the impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>1430</td>\n",
       "      <td>100xp Remember the model complexity curve that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>1432</td>\n",
       "      <td>100xp In this chapter, you will work with Gapm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>1434</td>\n",
       "      <td>100xp Now, you will fit a linear regression an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>1436</td>\n",
       "      <td>100xp As you learned in Chapter 1, train and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>1438</td>\n",
       "      <td>100xp Cross-validation is a vital step in eval...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>1440</td>\n",
       "      <td>100xp Cross validation is essential but do not...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>1443</td>\n",
       "      <td>0xp In the video, you saw how Lasso selected o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1445</td>\n",
       "      <td>100xp Lasso is great for feature selection, bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1448</td>\n",
       "      <td>100xp In Chapter 1, you evaluated the performa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1450</td>\n",
       "      <td>100xp Time to build your first logistic regres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1452</td>\n",
       "      <td>100xp Great job in the previous exercise - you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1454</td>\n",
       "      <td>100xp Say you have a binary classifier that in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>1456</td>\n",
       "      <td>100xp Hugo demonstrated how to use to tune the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1458</td>\n",
       "      <td>100xp GridSearchCV can be computationally expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1460</td>\n",
       "      <td>100xp You will now practice evaluating a model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>1462</td>\n",
       "      <td>100xp Remember lasso and ridge regression from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>1464</td>\n",
       "      <td>0xp The Gapminder dataset that you worked with...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>1466</td>\n",
       "      <td>100xp As Andy discussed in the video, scikit-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1468</td>\n",
       "      <td>100xp Having created the dummy variables from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>1470</td>\n",
       "      <td>100xp The voting dataset from Chapter 1 contai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>1472</td>\n",
       "      <td>100xp As you've come to appreciate, there are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>1474</td>\n",
       "      <td>100xp Having setup the steps of the pipeline i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>1476</td>\n",
       "      <td>100xp In the video, Hugo demonstrated how sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>1478</td>\n",
       "      <td>100xp With regard to whether or not scaling is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>1480</td>\n",
       "      <td>100xp It is time now to piece together everyth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>1482</td>\n",
       "      <td>100xp For this final exercise, you will return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>1486</td>\n",
       "      <td>100XP Import: matplotlib.pyplot as plt. pearso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>1488</td>\n",
       "      <td>100XP Import PCA from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>1492</td>\n",
       "      <td>100XP Make a scatter plot of the grain measure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>1494</td>\n",
       "      <td>100XP Create an instance of StandardScaler cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>1498</td>\n",
       "      <td>100XP Import PCA from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>1500</td>\n",
       "      <td>100XP Import TfidfVectorizer from sklearn.feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>1502</td>\n",
       "      <td>100XP Import: TruncatedSVD from sklearn.decomp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1504</td>\n",
       "      <td>100XP Import pandas as pd. Fit the pipeline to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>1507</td>\n",
       "      <td>100XP Import NMF from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>1509</td>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>1512</td>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>1514</td>\n",
       "      <td>100XP Import matplotlib.pyplot as plt. Select ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>1517</td>\n",
       "      <td>100XP Import NMF from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>1519</td>\n",
       "      <td>100XP Import PCA from sklearn.decomposition. C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>1522</td>\n",
       "      <td>100XP Import: NMF from sklearn.decomposition. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>1524</td>\n",
       "      <td>100XP Import pandas as pd. Create a DataFrame ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                          Questions\n",
       "0        0  50xp In this chapter, you're going to look at ...\n",
       "1        2  50xp In the previous exercise, you identified ...\n",
       "2        4  100xp As you've seen, .describe() can only be ...\n",
       "3        6  100xp Up until now, you've been looking at des...\n",
       "4        8  100xp Histograms are great ways of visualizing...\n",
       "5       10  100xp Boxplots are great when you have a numer...\n",
       "6       12  100xp Melting data is the process of turning c...\n",
       "7       14  100xp When melting DataFrames, it would be bet...\n",
       "8       16  100xp Pivoting data is the opposite of melting...\n",
       "9       18  100xp After pivoting airquality_melt in the pr...\n",
       "10      21  100xp The dataset you saw in the video, consis...\n",
       "11      23  100xp Another common way multiple variables ar...\n",
       "12      25  100xp The dataset you'll be working with here ...\n",
       "13      27  100xp Think of column-wise concatenation of da...\n",
       "14      29  100xp You're now going to practice using the g...\n",
       "15      31  100xp Now that you have a list of filenames to...\n",
       "16      33  100xp Merging data allows you to combine dispa...\n",
       "17      35  100xp In a many-to-one (or one-to-many) merge,...\n",
       "18      37  100xp The final merging scenario occurs when b...\n",
       "19      39  100xp In this exercise, you'll see how ensurin...\n",
       "20      41  100xp If you expect the data type of a column ...\n",
       "21      43  100xp In the video, Dan introduced you to the ...\n",
       "22      45  100xp Extracting numbers from strings is a com...\n",
       "23      47  100xp In this exercise, you'll continue practi...\n",
       "24      49  100xp You'll now practice writing functions to...\n",
       "25      51  100xp You'll now be introduced to a powerful P...\n",
       "26      56  100xp Duplicate data causes a variety of probl...\n",
       "27      58  100xp Here, you'll return to the airquality da...\n",
       "28      60  0xp Here, you'll practice writing assert state...\n",
       "29      62  100xp In this exercise, you'll write code to d...\n",
       "30      65  0xp As Dan explained to you in the video, an \"...\n",
       "31      67  100xp You'll now define a function called pred...\n",
       "32      69  100xp In this exercise, you'll write code to d...\n",
       "33      71  100xp Now you'll get to change weights in a re...\n",
       "34      73  100xp You've seen how different weights will h...\n",
       "35      75  100xp You're now going to practice calculating...\n",
       "36      77  100xp Hurray! You've just calculated the slope...\n",
       "37      79  100xp You're now going to make multiple update...\n",
       "38      81  100xp Now you'll get to work with your first m...\n",
       "39      83  100xp You're now going to compile the model yo...\n",
       "40      85  100xp You're at the most fun part. You'll now ...\n",
       "41      87  100xp You'll now create a classification model...\n",
       "42      89  100xp The trained network from your previous c...\n",
       "43      91  100xp It's time to get your hands dirty with o...\n",
       "44      93  100xp Now it's your turn to monitor model accu...\n",
       "45      95  100xp Now that you know how to monitor your mo...\n",
       "46      97  0xp Now you know everything you need to begin ...\n",
       "47      99  100xp You've seen how to experiment with wider...\n",
       "48     101  0xp You've reached the final exercise of the c...\n",
       "49     103  100xp In this exercise, you'll be working with...\n",
       "50     105  100xp For large files, we may not want to prin...\n",
       "51     109  100xp In this exercise, you're now going to lo...\n",
       "52     111  100xp What if there are rows, such as a header...\n",
       "53     113  100xp The file seaslug.txt has a text header, ...\n",
       "54     117  100xp You have just used np.genfromtxt() to im...\n",
       "55     119  100xp In the last exercise, you were able to i...\n",
       "56     123  100xp The pandas package is also great at deal...\n",
       "57     125  100xp There are a number of datatypes that can...\n",
       "58     127  100xp Whether you like it or not, any working ...\n",
       "59     129  100xp In the previous exercises, you saw that ...\n",
       "60     131  100xp Here, you'll parse your spreadsheets and...\n",
       "61     133  100xp In this exercise, you'll figure out how ...\n",
       "62     136  100xp Here, you'll gain expertise in importing...\n",
       "63     138  100xp The file 'LIGO_data.hdf5' is already in ...\n",
       "64     140  100xp In this exercise, you'll extract some of...\n",
       "65     142  100xp In this exercise, you'll figure out how ...\n",
       "66     144  100xp Here, you'll discover what is in the MAT...\n",
       "67     147  100xp Here, you're going to fire up your very ...\n",
       "68     150  100xp In this exercise, you'll once again crea...\n",
       "69     152  0xp Now, it's time for liftoff! In this exerci...\n",
       "70     154  100xp Congratulations on executing your first ...\n",
       "71     161  100xp You can now execute a basic SQL query to...\n",
       "72     165  100xp You can also order your SQL query result...\n",
       "73     169  100xp Here, you'll become more familiar with t...\n",
       "74     171  100xp Here, you'll perform your first INNER JO...\n",
       "75     174  100xp Congrats on performing your first INNER ...\n",
       "76     177  100xp In this exercise, you'll be working with...\n",
       "77     179  100xp For large files, we may not want to prin...\n",
       "78     183  100xp In this exercise, you're now going to lo...\n",
       "79     185  100xp What if there are rows, such as a header...\n",
       "80     187  100xp The file seaslug.txt has a text header, ...\n",
       "81     191  100xp You have just used np.genfromtxt() to im...\n",
       "82     193  100xp In the last exercise, you were able to i...\n",
       "83     197  100xp The pandas package is also great at deal...\n",
       "84     199  100xp There are a number of datatypes that can...\n",
       "85     201  100xp Whether you like it or not, any working ...\n",
       "86     203  100xp In the previous exercises, you saw that ...\n",
       "87     205  100xp Here, you'll parse your spreadsheets and...\n",
       "88     207  100xp In this exercise, you'll figure out how ...\n",
       "89     210  100xp Here, you'll gain expertise in importing...\n",
       "90     212  100xp The file 'LIGO_data.hdf5' is already in ...\n",
       "91     214  100xp In this exercise, you'll extract some of...\n",
       "92     216  100xp In this exercise, you'll figure out how ...\n",
       "93     218  100xp Here, you'll discover what is in the MAT...\n",
       "94     221  100xp Here, you're going to fire up your very ...\n",
       "95     224  100xp In this exercise, you'll once again crea...\n",
       "96     226  0xp Now, it's time for liftoff! In this exerci...\n",
       "97     228  100xp Congratulations on executing your first ...\n",
       "98     235  100xp You can now execute a basic SQL query to...\n",
       "99     239  100xp You can also order your SQL query result...\n",
       "100    243  100xp Here, you'll become more familiar with t...\n",
       "101    245  100xp Here, you'll perform your first INNER JO...\n",
       "102    248  100xp Congrats on performing your first INNER ...\n",
       "103    251  100xp You are about to import your first file ...\n",
       "104    254  100xp You have just imported a file from the w...\n",
       "105    256  100xp Congrats! You've just loaded a flat file...\n",
       "106    259  100xp Now that you know the basics behind HTTP...\n",
       "107    261  100xp You have just packaged and sent a GET re...\n",
       "108    263  100xp Now that you've got your head and hands ...\n",
       "109    265  100xp In this interactive exercise, you'll lea...\n",
       "110    267  100xp As promised, in the following exercises,...\n",
       "111    269  100xp In this exercise, you'll figure out how ...\n",
       "112    271  0xp Now that you know what a JSON is, you'll l...\n",
       "113    273  100xp Now it's your turn to pull some movie da...\n",
       "114    275  100xp Wow, congrats! You've just queried your ...\n",
       "115    277  100xp You're doing so well and having so much ...\n",
       "116    279  100xp The package tweepy is great at handling ...\n",
       "117    281  100xp Now that you have set up your authentica...\n",
       "118    283  100xp Now that you've got your Twitter data si...\n",
       "119    285  100xp Now you have the Twitter data in a list ...\n",
       "120    287  100xp Now that you have your DataFrame of twee...\n",
       "121    291  100xp Now that you have the number of tweets t...\n",
       "122    294  100XP Import the figure function from bokeh.pl...\n",
       "123    296  100XP Create the figure p with the figure() fu...\n",
       "124    298  100XP Using the Latin America data (fertility_...\n",
       "125    300  100XP Import the figure function from bokeh.pl...\n",
       "126    302  100XP Plot date along the x-axis and price alo...\n",
       "127    304  100XP Create a list of the longitude positions...\n",
       "128    306  100XP Import numpy as np. Create an array x us...\n",
       "129    308  100XP Import pandas as pd. Use the read_csv() ...\n",
       "130    310  100XP Import the ColumnDataSource class from b...\n",
       "131    312  100XP Create a figure p with an x-axis label o...\n",
       "132    314  100XP Import HoverTool from bokeh.models. Add ...\n",
       "133    316  100XP Import CategoricalColorMapper from bokeh...\n",
       "134    318  100XP Import row from the bokeh.layouts module...\n",
       "135    320  100XP Import column from the bokeh.layouts mod...\n",
       "136    322  100XP Import row and column from bokeh.layouts...\n",
       "137    324  100XP Import gridplot from the bokeh.layouts m...\n",
       "138    326  100XP Import Panel from bokeh.models.widgets. ...\n",
       "139    328  100XP Import Tabs from bokeh.models.widgets. C...\n",
       "140    330  100XP Link the x_range of p2 to p1. Link the y...\n",
       "141    332  100XP Create a ColumnDataSource object called ...\n",
       "142    334  100XP Add a red circle glyph to the figure p u...\n",
       "143    336  100XP Use p.legend.location to adjust the lege...\n",
       "144    338  100XP Import the HoverTool class from bokeh.mo...\n",
       "145    340  100XP Import curdoc from bokeh.io and figure f...\n",
       "146    342  100XP Import curdoc from bokeh.io, widgetbox f...\n",
       "147    344  100XP Create the first slider, slider1, using ...\n",
       "148    346  100XP Create a ColumnDataSource called source....\n",
       "149    348  100XP Define a callback function callback with...\n",
       "150    350  100XP Define a callback function called update...\n",
       "151    352  100XP Create select1, the first dropdown selec...\n",
       "152    354  0XP Create a button called button using the fu...\n",
       "153    356  100XP Import CheckboxGroup, RadioGroup, Toggle...\n",
       "154    358  100XP Import output_file and show from bokeh.i...\n",
       "155    360  100XP Make a ColumnDataSource object called so...\n",
       "156    362  100XP Make a list of the unique values from th...\n",
       "157    364  100XP Import the widgetbox and row functions f...\n",
       "158    366  100XP Define the update_plot callback function...\n",
       "159    368  100XP Import HoverTool from bokeh.models. Crea...\n",
       "160    370  100XP Inside the update_plot() callback functi...\n",
       "161    371  100xp With matplotlib, you can create a bunch ...\n",
       "162    374  100xp Now that you've built your first line pl...\n",
       "163    376  100xp When you have a time scale along the hor...\n",
       "164    379  100xp In the previous exercise, you saw that t...\n",
       "165    381  100xp life_exp, the list containing data on th...\n",
       "166    383  100xp In the previous exercise, you didn't spe...\n",
       "167    386  100xp It's time to customize your own plot. Th...\n",
       "168    388  100xp The customizations you've coded up to no...\n",
       "169    391  100xp Right now, the scatter plot is just a cl...\n",
       "170    393  100xp The code you've written up to now is ava...\n",
       "171    396  100xp If you have another look at the script, ...\n",
       "172    398  100xp To see why dictionaries are useful, have...\n",
       "173    400  100xp The countries and capitals lists are aga...\n",
       "174    402  100xp If the keys of a dictionary are chosen w...\n",
       "175    405  0xp If you know how to access a dictionary, yo...\n",
       "176    407  100xp Somebody thought it would be funny to me...\n",
       "177    409  100xp Remember lists? They could contain anyth...\n",
       "178    411  100xp Pandas is an open source library, provid...\n",
       "179    413  100xp The Python code that solves the previous...\n",
       "180    415  100xp Putting data in a dictionary and then bu...\n",
       "181    416  100xp Your read_csv() call to import the CSV d...\n",
       "182    418  100xp In the video, you saw that you can index...\n",
       "183    421  100xp Square brackets can do more than just se...\n",
       "184    424  100xp With loc and iloc you can do practically...\n",
       "185    429  100xp loc and iloc also allow you to select bo...\n",
       "186    433  100xp It's also possible to select only column...\n",
       "187    436  100xp To check if two Python values, or variab...\n",
       "188    439  100xp In the video, Filip also talked about th...\n",
       "189    442  100xp Out of the box, you can also use compari...\n",
       "190    444  100xp A boolean is either 1 or 0, True or Fals...\n",
       "191    448  100xp It's time to take a closer look around i...\n",
       "192    450  100xp On the right, the if construct for room ...\n",
       "193    452  100xp It's also possible to have a look around...\n",
       "194    454  100xp Remember that cars dataset, containing t...\n",
       "195    456  100xp The code in the previous example worked ...\n",
       "196    458  100xp Let's stick to the cars data some more. ...\n",
       "197    460  100xp Remember about np.logical_and(), np.logi...\n",
       "198    462  100xp Below you can find the example from the ...\n",
       "199    464  100xp The while loop that corrects the offset ...\n",
       "200    465  100xp Have another look at the for loop that F...\n",
       "201    468  100xp Using a for loop to iterate over a list ...\n",
       "202    470  100xp For non-programmer folks, room 0: 11.25 ...\n",
       "203    472  100xp Remember the house variable from the Int...\n",
       "204    474  100xp In Python 3, you need the items() method...\n",
       "205    478  100xp If you're dealing with a 1D Numpy array,...\n",
       "206    482  100xp Iterating over a Pandas DataFrame is typ...\n",
       "207    485  100xp The row data that's generated by iterrow...\n",
       "208    487  0xp In the video, Filip showed you how to add ...\n",
       "209    490  100xp Using iterrows() to iterate over every o...\n",
       "210    494  100xp Below you can find the example from the ...\n",
       "211    497  100xp The while loop that corrects the offset ...\n",
       "212    499  100xp Have another look at the for loop that F...\n",
       "213    502  100xp Using a for loop to iterate over a list ...\n",
       "214    504  100xp For non-programmer folks, room 0: 11.25 ...\n",
       "215    506  100xp Remember the house variable from the Int...\n",
       "216    508  100xp In Python 3, you need the items() method...\n",
       "217    512  100xp If you're dealing with a 1D Numpy array,...\n",
       "218    516  100xp Iterating over a Pandas DataFrame is typ...\n",
       "219    519  100xp The row data that's generated by iterrow...\n",
       "220    521  0xp In the video, Filip showed you how to add ...\n",
       "221    524  100xp Using iterrows() to iterate over every o...\n",
       "222    528  100xp Randomness has many uses in science, art...\n",
       "223    530  100xp In the previous exercise, you used rand(...\n",
       "224    533  100xp In the Empire State Building bet, your n...\n",
       "225    535  100xp Before, you have already written Python ...\n",
       "226    537  0xp Things are shaping up nicely! You already ...\n",
       "227    539  100xp Let's visualize this random walk! Rememb...\n",
       "228    542  100xp A single random walk is one thing, but t...\n",
       "229    544  100xp all_walks is a list of lists: every sub-...\n",
       "230    548  100xp With this neatly written code of yours, ...\n",
       "231    550  100xp All these fancy visualizations have put ...\n",
       "232    574  100xp Subsetting Python lists is a piece of ca...\n",
       "233    583  50xp You saw before that a Python list can con...\n",
       "234    586  100xp Replacing list elements is pretty easy. ...\n",
       "235    589  100xp If you can change elements in a list, yo...\n",
       "236    597  100xp Out of the box, Python offers a bunch of...\n",
       "237    599  50xp Maybe you already know the name of a Pyth...\n",
       "238    602  100xp In the previous exercise, the square bra...\n",
       "239    604  100xp Strings come with a bunch of methods. Fo...\n",
       "240    605  100xp Strings are not the only Python types th...\n",
       "241    607  100xp Most list methods will change the list t...\n",
       "242    608  100xp As a data scientist, some notions of geo...\n",
       "243    609  100xp General imports, like import math, make ...\n",
       "244    611  50xp There are several ways to import packages...\n",
       "245    613  100xp We're going to dive into the world of ba...\n",
       "246    614  100xp You are a huge baseball fan. You decide ...\n",
       "247    615  100xp The MLB also offers to let you analyze t...\n",
       "248    616  100xp To subset both regular Python lists and ...\n",
       "249    619  100xp You've seen it with your own eyes: Pytho...\n",
       "250    622  100xp Before working on the actual MLB data, l...\n",
       "251    623  100xp You have another look at the MLB data an...\n",
       "252    624  100xp If your 2D Numpy array has a regular str...\n",
       "253    628  100xp Remember how you calculated the Body Mas...\n",
       "254    630  100xp You now know how to use Numpy functions ...\n",
       "255    632  0xp Because the mean and median are so far apa...\n",
       "256    633  100xp In the last few exercises you've learned...\n",
       "257    635  0XP Import create_engine from the sqlalchemy m...\n",
       "258    637  100XP Import the Table object from sqlalchemy....\n",
       "259    639  100XP Reflect the census table as you did in t...\n",
       "260    641  100XP Build a SQL statement to query all the c...\n",
       "261    643  100XP Import select from the sqlalchemy module...\n",
       "262    645  100XP Extract the first row of results and ass...\n",
       "263    647  50XP Import create_engine from sqlalchemy. Cre...\n",
       "264    649  100XP Select all records from the census table...\n",
       "265    651  100XP Select all records from the census table...\n",
       "266    653  100XP Import and_ from the sqlalchemy module. ...\n",
       "267    655  100XP Select all records of the state column f...\n",
       "268    657  100XP Import desc from the sqlalchemy module. ...\n",
       "269    659  100XP Select all records of the state and age ...\n",
       "270    664  100XP Build a select statement to count the di...\n",
       "271    668  100XP Import func from sqlalchemy. Build an ex...\n",
       "272    670  100XP Import pandas as pd. Create a DataFrame ...\n",
       "273    672  100XP Import matplotlib.pyplot as plt. Create ...\n",
       "274    674  100XP Import the create_engine function from t...\n",
       "275    676  100XP Define a select statement called stmt to...\n",
       "276    678                                              100XP\n",
       "277    682  100XP Build a statement to join the census and...\n",
       "278    684  100XP Build a statement to select ALL the colu...\n",
       "279    686  100XP Build a statement to select: The state c...\n",
       "280    690  100XP Save an alias of the employees table as ...\n",
       "281    692  100XP Use a while loop that checks if there ar...\n",
       "282    694  100XP Import Table, Column, String, Integer, F...\n",
       "283    696  100XP Table, Column, String, Integer, Float, B...\n",
       "284    698  100XP Import insert and select from the sqlalc...\n",
       "285    700  100XP Build a list of dictionaries called valu...\n",
       "286    702  100XP Create a statement for bulk insert into ...\n",
       "287    705  100XP Build a statement to select all columns ...\n",
       "288    707  100XP Build an update statement to update the ...\n",
       "289    709  100XP Build a statement to select the name col...\n",
       "290    712  100XP Import delete and select from sqlalchemy...\n",
       "291    715  100XP Build a delete statement to remove data ...\n",
       "292    717  100XP Drop the state_fact table by applying th...\n",
       "293    719  100XP Import create_engine and MetaData from s...\n",
       "294    721  100XP Import Table, Column, String, and Intege...\n",
       "295    723  100XP Create an empty list called values_list....\n",
       "296    725  100XP Import insert from sqlalchemy. Build an ...\n",
       "297    727  100XP Import select from sqlalchemy. Build a s...\n",
       "298    729  100XP Import case, cast and Float from sqlalch...\n",
       "299    731  100XP Build a statement to: Select state. Calc...\n",
       "300    733  100XP Import matplotlib.pyplot as its usual al...\n",
       "301    735  100XP Create a set of plot axes with lower cor...\n",
       "302    737  100XP Use plt.subplot() to create a figure wit...\n",
       "303    739  100XP Create a figure with 2Ã—22Ã—2 subplot layo...\n",
       "304    741  100XP Use plt.xlim() to set the x-axis range t...\n",
       "305    743  100XP Use plt.axis() to select the time period...\n",
       "306    745  100XP Modify the plot command provided that dr...\n",
       "307    747  100XP Compute the maximum enrollment of women ...\n",
       "308    749  100XP Import matplotlib.pyplot as its usual al...\n",
       "309    752  100XP Import the numpy and matplotlib.pyplot m...\n",
       "310    754  100XP Using the meshgrid X, Y as axes: Generat...\n",
       "311    756  100XP Modify the call to plt.contourf() so the...\n",
       "312    758  100XP Generate a two-dimensional histogram to ...\n",
       "313    760  100XP Generate a two-dimensional histogram wit...\n",
       "314    762  100XP Load the file '480px-Astronaut-EVA.jpg' ...\n",
       "315    764  100XP Print the shape of the existing image ar...\n",
       "316    766  100XP Display img in the top left subplot with...\n",
       "317    768  100XP Use the methods .min() and .max() to sav...\n",
       "318    770  100XP Import matplotlib.pyplot and seaborn usi...\n",
       "319    772  100XP Import matplotlib.pyplot and seaborn usi...\n",
       "320    774  100XP Modify the call to plt.scatter() to plot...\n",
       "321    776  100XP Plot a linear regression between 'weight...\n",
       "322    778  100XP Plot linear regressions of 'hp' (on the ...\n",
       "323    780  100XP In the first row of subplots, make a str...\n",
       "324    782  100XP In the first row of subplots, make a swa...\n",
       "325    784  100XP In the first row of subplots, make a vio...\n",
       "326    786  100XP Use sns.jointplot() to visualize the joi...\n",
       "327    788  100XP Create a hexbin plot of the joint distri...\n",
       "328    790  100XP Print the first five rows of the DataFra...\n",
       "329    792  100XP Plot the pairwise joint distributions se...\n",
       "330    794  100XP Print the covariance matrix cov_matrix t...\n",
       "331    797  100XP Plot the aapl time series in blue with a...\n",
       "332    799  100XP Plot the series aapl in 'blue' in the to...\n",
       "333    801  100XP Extract a slice named view from the seri...\n",
       "334    803  100XP Extract a slice of series aapl from Nove...\n",
       "335    805  100XP In the top left subplot, plot the 30-day...\n",
       "336    807  100XP Produce a single plot with four curves o...\n",
       "337    809  100XP Load data from the file '640px-Unequaliz...\n",
       "338    811  100XP First, use plt.hist() to plot the histog...\n",
       "339    813  100XP Use the NumPy array method .reshape() to...\n",
       "340    815  100XP Display image in the top subplot of a 2Ã—...\n",
       "341    817  100XP Make a 2-D histogram in the top left sub...\n",
       "342    820  100XP Import the create_engine function from t...\n",
       "343    822  100XP Define a select statement called stmt to...\n",
       "344    824                                              100XP\n",
       "345    828  100XP Build a statement to join the census and...\n",
       "346    830  100XP Build a statement to select ALL the colu...\n",
       "347    832  100XP Build a statement to select: The state c...\n",
       "348    836  100XP Save an alias of the employees table as ...\n",
       "349    838  100XP Use a while loop that checks if there ar...\n",
       "350    840  100XP Import Table, Column, String, Integer, F...\n",
       "351    842  100XP Table, Column, String, Integer, Float, B...\n",
       "352    844  100XP Import insert and select from the sqlalc...\n",
       "353    846  100XP Build a list of dictionaries called valu...\n",
       "354    848  100XP Create a statement for bulk insert into ...\n",
       "355    851  100XP Build a statement to select all columns ...\n",
       "356    853  100XP Build an update statement to update the ...\n",
       "357    855  100XP Build a statement to select the name col...\n",
       "358    858  100XP Import delete and select from sqlalchemy...\n",
       "359    861  100XP Build a delete statement to remove data ...\n",
       "360    863  100XP Drop the state_fact table by applying th...\n",
       "361    865  100XP Import create_engine and MetaData from s...\n",
       "362    867  100XP Import Table, Column, String, and Intege...\n",
       "363    869  100XP Create an empty list called values_list....\n",
       "364    871  100XP Import insert from sqlalchemy. Build an ...\n",
       "365    873  100XP Import select from sqlalchemy. Build a s...\n",
       "366    875  100XP Import case, cast and Float from sqlalch...\n",
       "367    877  100XP Build a statement to: Select state. Calc...\n",
       "368    885  100XP Print summary statistics of the numeric ...\n",
       "369    888  100XP Define the lambda function categorize_la...\n",
       "370    890  100XP Create the DataFrame num_unique_labels b...\n",
       "371    893  100XP Using the compute_log_loss() function, c...\n",
       "372    895  100XP Create a new DataFrame named numeric_dat...\n",
       "373    897  100XP Import LogisticRegression from sklearn.l...\n",
       "374    899  100XP Read HoldoutData.csv into a DataFrame ca...\n",
       "375    901  100XP Create the prediction_df DataFrame by sp...\n",
       "376    903  100XP Import CountVectorizer from sklearn.feat...\n",
       "377    905  100XP Use the .drop() method on data_frame wit...\n",
       "378    907  100XP Import CountVectorizer from sklearn.feat...\n",
       "379    909  100XP Import Pipeline from sklearn.pipeline. C...\n",
       "380    911  100XP Import CountVectorizer from sklearn.feat...\n",
       "381    913  100XP Compute the selector get_text_data by us...\n",
       "382    915  100XP In the process_and_join_features: Add th...\n",
       "383    917  100XP Complete the call to multilabel_train_te...\n",
       "384    919  100XP Complete the 'numeric_features' transfor...\n",
       "385    921  100XP Import the RandomForestClassifier from s...\n",
       "386    923  100XP Import the RandomForestClassifier from s...\n",
       "387    928  100XP Create text_vector by preprocessing X_tr...\n",
       "388    930  100XP Import CountVectorizer from sklearn.feat...\n",
       "389    934  100XP Add the interaction terms step using Spa...\n",
       "390    938  100XP Import HashingVectorizer from sklearn.fe...\n",
       "391    940  100XP Import HashingVectorizer from sklearn.fe...\n",
       "392    941  100xp As you saw in the video, loading data fr...\n",
       "393    943  100xp In this exercise, you'll combine the thr...\n",
       "394    945  0xp It is often useful to rearrange the sequen...\n",
       "395    947  100xp Sorting methods are not the only way to ...\n",
       "396    949  100xp Another common technique is to reindex a...\n",
       "397    952  100xp In this exercise, you'll work with weath...\n",
       "398    954  100xp Your job in this exercise is to compute ...\n",
       "399    961  100XP Create an empty list called units. This ...\n",
       "400    963  100XP Create a 'year' column in the DataFrames...\n",
       "401    965  100XP Create a new DataFrame called weather by...\n",
       "402    967  100XP Iterate over medal_types in the for loop...\n",
       "403    969  100XP Within the for loop: Read file_name into...\n",
       "404    971  100XP Create a new DataFrame medals_sorted wit...\n",
       "405    973                                              100XP\n",
       "406    976  100XP Create a list called month_list consisti...\n",
       "407    978  100XP Construct a list of DataFrames called me...\n",
       "408    980  100XP Make a new DataFrame china_annual by res...\n",
       "409    982  100XP Using pd.merge(), merge the DataFrames r...\n",
       "410    986  100XP Merge the DataFrames revenue and manager...\n",
       "411    988  100XP Create a column called 'state' in the Da...\n",
       "412    993  100XP Execute a right merge using pd.merge() w...\n",
       "413    995  100XP Merge sales_and_managers with revenue_an...\n",
       "414    997  100XP Perform an ordered merge on austin and h...\n",
       "415    999  100XP Merge auto and oil using pd.merge_asof()...\n",
       "416   1001  100XP Read file_path into a DataFrame called e...\n",
       "417   1003  100XP Read file_path into a DataFrame called i...\n",
       "418   1005  100XP Within the for loop: Create the file pat...\n",
       "419   1007  0XP Construct a pivot table from the DataFrame...\n",
       "420   1009  100XP Set the index of the DataFrame editions ...\n",
       "421   1011  100XP Create mean_fractions by chaining the me...\n",
       "422   1013  0XP Create the DataFrame hosts by doing a left...\n",
       "423   1015  100XP Create a DataFrame reshaped by reshaping...\n",
       "424   1017  100XP Merge reshaped and hosts using an inner ...\n",
       "425   1019  100XP Create a Series called change by extract...\n",
       "426   1021  100xp Now you'll get a chance to write some re...\n",
       "427   1022  100xp Here, you'll be using the first scene of...\n",
       "428   1023  0xp In this exercise, you'll utilize re.search...\n",
       "429   1024  50xp Given the following string, which is the ...\n",
       "430   1025  100xp Twitter is a frequently used source for ...\n",
       "431   1026  0xp In this exercise, you'll practice advanced...\n",
       "432   1027  100xp Try using your new skills to find and ch...\n",
       "433   1028  100xp In this exercise, you'll build your firs...\n",
       "434   1030  100xp Now, it's your turn to apply the techniq...\n",
       "435   1032  100xp It's time to apply the methods you learn...\n",
       "436   1034  100xp Now, you'll use your new gensim corpus a...\n",
       "437   1038  100xp You're now going to have some fun with n...\n",
       "438   1040  100xp In this exercise, you'll use some extrac...\n",
       "439   1042  100xp Using the same text you used in the firs...\n",
       "440   1044  100xp In this exercise and the next, you'll us...\n",
       "441   1046  0xp Here, you'll complete the work you began i...\n",
       "442   1048  100xp You'll continue your exploration of poly...\n",
       "443   1050  100xp In the final exercise of this NER chapte...\n",
       "444   1052  100xp It's time to begin building your text cl...\n",
       "445   1054  100xp Similar to the sparse CountVectorizer cr...\n",
       "446   1056  100xp To get a better idea of how the vectors ...\n",
       "447   1062  100xp Now it's your turn to train the \"fake ne...\n",
       "448   1064  100xp Now that you have evaluated the model us...\n",
       "449   1066  100xp Your job in this exercise is to test a f...\n",
       "450   1068  100xp Now that you have built a \"fake news\" cl...\n",
       "451   1073  100XP Import matplotlib.pyplot as plt and netw...\n",
       "452   1075  100XP Use a list comprehension to get a list o...\n",
       "453   1078  100XP Set the 'weight' attribute of the edge b...\n",
       "454   1080  100XP Define a function called find_selfloop_n...\n",
       "455   1082  100XP Import nxviz as nv. Plot the graph T as ...\n",
       "456   1084  100XP Import CircosPlot from nxviz. Plot the T...\n",
       "457   1086  100XP Import ArcPlot from nxviz. Create an un-...\n",
       "458   1088  100XP Write a function called nodes_with_m_nbr...\n",
       "459   1090  100XP Use a list comprehension along with the ...\n",
       "460   1092  100XP Compute the degree centrality of the Twi...\n",
       "461   1094  100XP Create a function called path_exists() t...\n",
       "462   1096  100XP Using the .add() method, add the current...\n",
       "463   1098  100XP Check to see if the queue has been empti...\n",
       "464   1100  100XP Compute the betweenness centrality bet_c...\n",
       "465   1102  100XP Write a function find_nodes_with_highest...\n",
       "466   1104  100XP Write a function find_node_with_highest_...\n",
       "467   1106  100XP Import combinations from itertools. Writ...\n",
       "468   1108  100XP Write a function nodes_in_triangle() tha...\n",
       "469   1110  100XP Write a function node_in_open_triangle()...\n",
       "470   1112  100XP Write a function maximal_cliques() that ...\n",
       "471   1114  100XP Write a function get_nodes_and_nbrs(G, n...\n",
       "472   1116  100XP Using a list comprehension, extract node...\n",
       "473   1118  100XP Plot the degree distribution of the GitH...\n",
       "474   1120  100XP Plot the betweenness centrality distribu...\n",
       "475   1122  100XP Make a MatrixPlot visualization of the l...\n",
       "476   1124  100XP Make an ArcPlot of the GitHub collaborat...\n",
       "477   1126  100XP Make a CircosPlot of the network, again,...\n",
       "478   1128  100XP Count the number of maximal cliques pres...\n",
       "479   1130  100XP Find the author(s) that are part of the ...\n",
       "480   1133  100XP Go out 1 degree of separation from the c...\n",
       "481   1135  100XP Compile a list of GitHub users that shou...\n",
       "482   1136  100xp Pandas depends upon and interoperates wi...\n",
       "483   1138  100xp In this exercise, you're going to make a...\n",
       "484   1139  100xp You can use the DataFrame attribute df.c...\n",
       "485   1140  100xp You can implicitly use 'broadcasting', a...\n",
       "486   1141  100xp In previous exercises, we have preloaded...\n",
       "487   1142  100xp Not all data files are clean and tidy. P...\n",
       "488   1143  100xp Data visualization is often a very effec...\n",
       "489   1144  100xp Comparing data from several columns can ...\n",
       "490   1145  100xp In the previous chapter, you saw that th...\n",
       "491   1146  100xp Pandas scatter plots are generated using...\n",
       "492   1147  100xp While pandas can plot multiple columns o...\n",
       "493   1148  100xp Pandas relies on the .hist() method to n...\n",
       "494   1150  100xp In this exercise, you will investigate s...\n",
       "495   1152  100xp In many data sets, there can be large di...\n",
       "496   1153  100xp In this exercise, you'll investigate the...\n",
       "497   1154  100xp Let's use the mean and standard deviatio...\n",
       "498   1155  50xp How many automobiles were manufactured in...\n",
       "499   1157  100xp Let's use population filtering to determ...\n",
       "500   1158  100xp Population filtering can be used alongsi...\n",
       "501   1159  100xp Pandas time series support \"partial stri...\n",
       "502   1161  100xp Reindexing is useful in preparation for ...\n",
       "503   1163  100xp Pandas provides methods for resampling t...\n",
       "504   1165  100xp With pandas, you can resample in differe...\n",
       "505   1167  100xp In this exercise, some hourly weather da...\n",
       "506   1169  100xp As of pandas version 0.18.0, the interfa...\n",
       "507   1171  100xp We've seen that pandas supports method c...\n",
       "508   1173  100xp One common application of interpolation ...\n",
       "509   1175  0xp Time zone handling with pandas typically a...\n",
       "510   1177  100xp Pandas handles datetimes not only in you...\n",
       "511   1179  100xp Now that you have set the DatetimeIndex ...\n",
       "512   1181  100xp Now that you have identified the method ...\n",
       "513   1183  100xp After the initial step of reading in the...\n",
       "514   1185  0xp In order to use the full power of pandas t...\n",
       "515   1187  100xp The numeric columns contain missing valu...\n",
       "516   1189  100xp Now that you have the data read and clea...\n",
       "517   1191  0xp You're now ready to compare the 2011 weath...\n",
       "518   1193  100xp On average, how much hotter is it when t...\n",
       "519   1195  100xp Is there a correlation between temperatu...\n",
       "520   1197  100xp In a previous exercise, you analyzed the...\n",
       "521   1199  100xp Dew point is a measure of relative humid...\n",
       "522   1201  100xp We already know that 2011 was hotter tha...\n",
       "523   1203  100xp Let's work more on your mastery of scope...\n",
       "524   1204  0xp You've learned in the last video about nes...\n",
       "525   1206  100xp Great job, you've just nested a function...\n",
       "526   1208  100xp Let's once again work further on your ma...\n",
       "527   1210  100xp In the previous chapter, you've learned ...\n",
       "528   1212  100xp You've now defined a function that uses ...\n",
       "529   1214  100xp Flexible arguments enable you to pass a ...\n",
       "530   1216  100xp Let's push further on what you've learne...\n",
       "531   1218  100xp Recall the Bringing it all together exer...\n",
       "532   1220  100xp Wow, you've just generalized your Twitte...\n",
       "533   1222  100xp Some function definitions are simple eno...\n",
       "534   1224  100xp So far, you've used lambda functions to ...\n",
       "535   1227  100xp In the previous exercise, you used lambd...\n",
       "536   1228  100xp You're getting very good at using lambda...\n",
       "537   1231  100xp A good practice in writing your own func...\n",
       "538   1232  100xp Another way to raise an error is by usin...\n",
       "539   1233  100xp This is awesome! You have now learned ho...\n",
       "540   1234  100xp Sometimes, we make mistakes when calling...\n",
       "541   1235  100xp In the previous exercise, you built on y...\n",
       "542   1236  100xp Great, you're familiar with what iterabl...\n",
       "543   1238  100xp One of the things you learned about in t...\n",
       "544   1241  100xp You've been using the iter() function to...\n",
       "545   1243  100xp You're really getting the hang of using ...\n",
       "546   1245  100xp Another interesting function that you've...\n",
       "547   1247  100xp You know how to use zip() as well as how...\n",
       "548   1249  100xp Sometimes, the data we have to process r...\n",
       "549   1251  100xp Great job chunking out that file in the ...\n",
       "550   1253  100xp You now have all the knowledge necessary...\n",
       "551   1255  100xp Great! At this point, you have a good gr...\n",
       "552   1258  0xp You've been using list comprehensions to b...\n",
       "553   1260  100xp In the previous exercise, you used an if...\n",
       "554   1262  100xp Comprehensions aren't relegated merely t...\n",
       "555   1264  100xp You are familiar with what generators an...\n",
       "556   1266  100xp Great! At this point, you already know h...\n",
       "557   1268  100xp In previous exercises, you've dealt main...\n",
       "558   1270  0xp You will now make use of what you've learn...\n",
       "559   1272  100xp Great, you've successfully extracted the...\n",
       "560   1274  0xp For this exercise, you'll use what you've ...\n",
       "561   1276  100xp Suppose you needed to repeat the same pr...\n",
       "562   1278  100xp This time, you're going to use the lists...\n",
       "563   1280  100xp You've zipped lists together, created a ...\n",
       "564   1282  100xp Sometimes, data sources can be so large ...\n",
       "565   1284  100xp In the previous exercise, you processed ...\n",
       "566   1286  100xp Great! You've just created a generator f...\n",
       "567   1288  100xp Another way to read data too large to st...\n",
       "568   1290  100xp In the previous exercise, you used read_...\n",
       "569   1292  100xp You're getting used to reading and proce...\n",
       "570   1294  100xp In the previous exercises, you've only p...\n",
       "571   1296  100xp This is the last leg. You've learned a l...\n",
       "572   1300  100XP Seed the random number generator with 42...\n",
       "573   1302  100XP Compute an ECDF from the actual time bet...\n",
       "574   1306  100XP Plot fertility (y-axis) versus illiterac...\n",
       "575   1308  100XP Compute the slope and intercept of the r...\n",
       "576   1310  100XP Specify the values of the slope for whic...\n",
       "577   1312  100XP Compute the parameters for the slope and...\n",
       "578   1314  100XP Write a for loop to do the following for...\n",
       "579   1316  100XP Write a for loop to acquire 50 bootstrap...\n",
       "580   1318  100XP Define a function with call signature dr...\n",
       "581   1320  100XP Draw 10000 bootstrap replicates of the m...\n",
       "582   1322  100XP Draw 10000 bootstrap replicates of the v...\n",
       "583   1324  100XP Generate 10000 bootstrap replicates of Ï„...\n",
       "584   1326  100XP Define a function with call signature dr...\n",
       "585   1328  100XP Use your draw_bs_pairs_linreg() function...\n",
       "586   1330  100XP Generate an array of xx-values consistin...\n",
       "587   1332  100XP Concatenate the two input arrays into on...\n",
       "588   1334  100XP Write a for loop to 50 generate permutat...\n",
       "589   1337  100XP Define a function with this signature: d...\n",
       "590   1339  100XP Use sns.swarmplot() to make a bee swarm ...\n",
       "591   1341  100XP Define a function with call signature di...\n",
       "592   1343  100XP Translate the impact forces of Frog B su...\n",
       "593   1345  100XP Compute the observed difference in impac...\n",
       "594   1347  100XP Compute the mean of all forces (from for...\n",
       "595   1349  100XP Construct Boolean arrays, dems and reps ...\n",
       "596   1351  100XP Compute the observed difference in mean ...\n",
       "597   1355  100XP Compute the observed Pearson correlation...\n",
       "598   1357  100XP Use your ecdf() function to generate x,y...\n",
       "599   1359  100XP Compute the mean alive sperm count of co...\n",
       "600   1361  100XP Label the axes. Don't forget that you sh...\n",
       "601   1363  100XP Import numpy as np. This gives access to...\n",
       "602   1365  100XP Use ecdf() to compute the ECDF of versic...\n",
       "603   1368  100XP Define a function with the signature ecd...\n",
       "604   1370  100XP Compute ECDFs for each of the three spec...\n",
       "605   1372  100XP Compute the mean petal length of Iris ve...\n",
       "606   1374  100XP Plot the percentiles as red diamonds on ...\n",
       "607   1376  100XP The set-up is exactly the same as for th...\n",
       "608   1379  100XP Create an array called differences that ...\n",
       "609   1381  100XP Compute the variance of the data in the ...\n",
       "610   1383  100XP Use plt.plot() with the appropriate keyw...\n",
       "611   1385  100XP Use np.cov() to compute the covariance m...\n",
       "612   1387  100XP Define a function with signature pearson...\n",
       "613   1389  100XP Seed the random number generator using t...\n",
       "614   1391  100XP Define a function with signature perform...\n",
       "615   1393  100XP Seed the random number generator to 42. ...\n",
       "616   1395  100XP Compute the x and y values for the ECDF ...\n",
       "617   1397  100XP Draw samples out of the Binomial distrib...\n",
       "618   1399  100XP Using np.arange(), compute the bin edges...\n",
       "619   1401  100XP Using the np.random.poisson() function, ...\n",
       "620   1403  100XP Draw 10000 samples from a Poisson distri...\n",
       "621   1406  100XP Use your ecdf() function to generate x a...\n",
       "622   1408  100XP Compute mean and standard deviation of B...\n",
       "623   1410  100XP Take 1,000,000 samples from the normal d...\n",
       "624   1412  100XP Define a function with call signature su...\n",
       "625   1414  100XP Use your successive_poisson() function t...\n",
       "626   1415  100xp In this chapter, you'll be working with ...\n",
       "627   1421  50xp The Numerical EDA you did in the previous...\n",
       "628   1423  0xp Having explored the Congressional voting r...\n",
       "629   1425  0xp Having fit a k-NN classifier, you can now ...\n",
       "630   1426  100xp Up until now, you have been performing b...\n",
       "631   1428  100xp Now that you have learned about the impo...\n",
       "632   1430  100xp Remember the model complexity curve that...\n",
       "633   1432  100xp In this chapter, you will work with Gapm...\n",
       "634   1434  100xp Now, you will fit a linear regression an...\n",
       "635   1436  100xp As you learned in Chapter 1, train and t...\n",
       "636   1438  100xp Cross-validation is a vital step in eval...\n",
       "637   1440  100xp Cross validation is essential but do not...\n",
       "638   1443  0xp In the video, you saw how Lasso selected o...\n",
       "639   1445  100xp Lasso is great for feature selection, bu...\n",
       "640   1448  100xp In Chapter 1, you evaluated the performa...\n",
       "641   1450  100xp Time to build your first logistic regres...\n",
       "642   1452  100xp Great job in the previous exercise - you...\n",
       "643   1454  100xp Say you have a binary classifier that in...\n",
       "644   1456  100xp Hugo demonstrated how to use to tune the...\n",
       "645   1458  100xp GridSearchCV can be computationally expe...\n",
       "646   1460  100xp You will now practice evaluating a model...\n",
       "647   1462  100xp Remember lasso and ridge regression from...\n",
       "648   1464  0xp The Gapminder dataset that you worked with...\n",
       "649   1466  100xp As Andy discussed in the video, scikit-l...\n",
       "650   1468  100xp Having created the dummy variables from ...\n",
       "651   1470  100xp The voting dataset from Chapter 1 contai...\n",
       "652   1472  100xp As you've come to appreciate, there are ...\n",
       "653   1474  100xp Having setup the steps of the pipeline i...\n",
       "654   1476  100xp In the video, Hugo demonstrated how sign...\n",
       "655   1478  100xp With regard to whether or not scaling is...\n",
       "656   1480  100xp It is time now to piece together everyth...\n",
       "657   1482  100xp For this final exercise, you will return...\n",
       "658   1486  100XP Import: matplotlib.pyplot as plt. pearso...\n",
       "659   1488  100XP Import PCA from sklearn.decomposition. C...\n",
       "660   1492  100XP Make a scatter plot of the grain measure...\n",
       "661   1494  100XP Create an instance of StandardScaler cal...\n",
       "662   1498  100XP Import PCA from sklearn.decomposition. C...\n",
       "663   1500  100XP Import TfidfVectorizer from sklearn.feat...\n",
       "664   1502  100XP Import: TruncatedSVD from sklearn.decomp...\n",
       "665   1504  100XP Import pandas as pd. Fit the pipeline to...\n",
       "666   1507  100XP Import NMF from sklearn.decomposition. C...\n",
       "667   1509  100XP Import pandas as pd. Create a DataFrame ...\n",
       "668   1512  100XP Import pandas as pd. Create a DataFrame ...\n",
       "669   1514  100XP Import matplotlib.pyplot as plt. Select ...\n",
       "670   1517  100XP Import NMF from sklearn.decomposition. C...\n",
       "671   1519  100XP Import PCA from sklearn.decomposition. C...\n",
       "672   1522  100XP Import: NMF from sklearn.decomposition. ...\n",
       "673   1524  100XP Import pandas as pd. Create a DataFrame ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b62cf66-a803-450e-bcc5-13ac8efc4e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = ~(df['Questions'].fillna('').str.startswith(('50xp', '100xp', '100XP', '50XP', '0XP', '0xp')).astype(bool)).to_frame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "59525a09-ae21-4359-b893-5614fb66d7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " \"Import pandas as pd. Read 'dob_job_application_filings_subset.csv' into a DataFrame called df. Print the head and tail of df. Print the shape of df and its columns. Note: .shape and .columns are attributes, not methods, so you don't need to follow these with parentheses (). Hit 'Submit Answer' to view the results! Notice the suspicious number of 0 values. Perhaps these represent missing data.\",\n",
       " nan,\n",
       " 'Print the info of df. Print the info of the subset dataframe, df_subset.',\n",
       " nan,\n",
       " \"Print the value counts for: The 'Borough' column. The 'State' column. The 'Site Fill' column.\",\n",
       " nan,\n",
       " \"Import matplotlib.pyplot as plt. Create a histogram of the 'Existing Zoning Sqft' column. Rotate the axis labels by 70 degrees and use a log scale for both axes. Display the histogram using plt.show().\",\n",
       " nan,\n",
       " \"Using the .boxplot() method of df, create a boxplot of 'initial_cost' across the different values of 'Borough'. Display the plot.\",\n",
       " nan,\n",
       " \"Using df, create a scatter plot (kind='scatter') with 'initial_cost' on the x-axis and the 'total_est_fee'on the y-axis. Rotate the x-axis labels by 70 degrees. Create another scatter plot exactly as above, substituting df_subset in place of df.\",\n",
       " nan,\n",
       " \"Print the head of airquality. Use pd.melt() to melt the Ozone, Solar.R, Wind, and Temp columns of airquality into rows. Do this by using id_vars to specify the columns you do not wish to melt: 'Month' and 'Day'. Print the head of airquality_melt.\",\n",
       " nan,\n",
       " \"Print the head of airquality. Melt the Ozone, Solar.R, Wind, and Temp columns of airquality into rows, with the default variable column renamed to 'measurement' and the default value column renamed to 'reading'. You can do this by specifying, respectively, the var_name and value_name parameters. Print the head of airquality_melt.\",\n",
       " nan,\n",
       " \"Print the head of airquality_melt. Pivot airquality_melt by using .pivot_table() with the rows indexed by 'Month' and 'Day', the columns indexed by 'measurement', and the values populated with 'reading'. Print the head of airquality_pivot.\",\n",
       " nan,\n",
       " 'Print the index of airquality_pivot by accessing its .index attribute. This has been done for you. Reset the index of airquality_pivot using its .reset_index() method. Print the new index of airquality_pivot. Print the head of airquality_pivot.',\n",
       " \"Pivoting duplicate values 0xp So far, you've used the .pivot_table() method when there are multiple index values you want to hold constant during a pivot. In the video, Dan showed you how you can also use pivot tables to deal with duplicate values by providing an aggregation function through the aggfunc parameter. Here, you're going to combine both these uses of pivot tables. Let's say your data collection method accidentally duplicated your dataset. Such a dataset, in which each row is duplicated, has been pre-loaded as airquality_dup. In addition, the airquality_melt DataFrame from the previous exercise has been pre-loaded. Explore their shapes in the IPython Shell by accessing their .shape attributes to confirm the duplicate rows present in airquality_dup. You'll see that by using .pivot_table() and the aggfunc parameter, you can not only reshape your data, but also remove duplicates. Finally, you can then flatten the columns of the pivoted DataFrame using .reset_index(). NumPy and pandas have been imported as np and pd respectively.\",\n",
       " nan,\n",
       " \"Melt tb keeping 'country' and 'year' fixed. Create a 'gender' column by slicing the first letter of the variable column of tb_melt. Create an 'age_group' column by slicing the rest of the variable column of tb_melt. Print the head of tb_melt. This has been done for you, so hit 'Submit Answer' to see the results!\",\n",
       " nan,\n",
       " \"Melt ebola using 'Date' and 'Day' as the id_vars, 'type_country' as the var_name, and 'counts' as the value_name. Create a column called 'str_split' by splitting the 'type_country' column of ebola_melt on '_'. Note that you will first have to access the str attribute of type_country before you can use .split(). Create a column called 'type' by using the .get()method to retrieve index 0 of the 'str_split' column of ebola_melt. Create a column called 'country' by using the .get()method to retrieve index 1 of the 'str_split' column of ebola_melt. Print the head of ebola. This has been done for you, so hit 'Submit Answer' to view the results!\",\n",
       " nan,\n",
       " \"Concatenate uber1, uber2, and uber3 together using pd.concat(). You'll have to pass the DataFrames in as a list. Print the shape and then the head of the concatenated DataFrame, row_concat.\",\n",
       " nan,\n",
       " 'Concatenate ebola_melt and status_country column-wise into a single DataFrame called ebola_tidy. Be sure to specify axis=1 and to pass the two DataFrames in as a list. Print the shape and then the head of the concatenated DataFrame, ebola_tidy.',\n",
       " nan,\n",
       " \"Import the glob module along with pandas (as its usual alias pd). Write a pattern to match all .csv files. Save all files that match the pattern using the glob() function within the glob module. That is, by using glob.glob(). Print the list of file names. This has been done for you. Read the second file in csv_files (i.e., index 1) into a DataFrame called csv2. Hit 'Submit Answer' to print the head of csv2. Does it look familiar?\",\n",
       " nan,\n",
       " \"Write a for loop to iterate though csv_files: In each iteration of the loop, read csv into a DataFrame called df. After creating df, append it to the list frames using the .append() method. Concatenate frames into a single DataFrame called uber. Hit 'Submit Answer' to see the head and shape of the concatenated DataFrame!\",\n",
       " nan,\n",
       " \"Merge the site and visited DataFrames on the 'name' column of site and 'site' column of visited. Print the merged DataFrame o2o\",\n",
       " nan,\n",
       " \"Merge the site and visited DataFrames on the 'name' column of site and 'site' column of visited, exactly as you did in the previous exercise. Print the merged DataFrame and then hit 'Submit Answer' to see the different output produced by this merge!\",\n",
       " nan,\n",
       " \"Merge the site and visited DataFrames on the 'name' column of site and 'site' column of visited, exactly as you did in the previous two exercises. Save the result as m2m. Merge the m2m and survey DataFrames on the 'ident'column of m2m and 'taken' column of survey. Hit 'Submit Answer' to print the first 20 lines of the merged DataFrame!\",\n",
       " nan,\n",
       " \"Convert the sex column of the tips DataFrame to type 'category' using the .astype() method. Convert the smoker column of the tips DataFrame. Print the memory usage of tips after converting the data types of the columns. Use the .info() method to do this.\",\n",
       " nan,\n",
       " \"Use pd.to_numeric() to convert the 'total_bill'column of tips to a numeric data type. Coerce the errors to NaN by specifying the keyword argument errors='coerce'. Convert the 'tip' column of 'tips' to a numeric data type exactly as you did for the 'total_bill' column. Print the info of tips to confirm that the data types of 'total_bill' and 'tips' are numeric.\",\n",
       " nan,\n",
       " \"Import re. Compile a pattern that matches a phone number of the format xxx-xxx-xxxx. Use \\\\d{x} to match x digits. Here you'll need to use it three times: twice to match 3 digits, and once to match 4 digits. Place the regular expression inside re.compile(). Using the .match() method on prog, check whether the pattern matches the string '123-456-7890'. Check whether the pattern matches the string '1123-456-7890'.\",\n",
       " nan,\n",
       " \"Import re. Write a pattern that will find all the numbers in the following string: 'the recipe calls for 10 strawberries and 1 banana'. To do this: Use the re.findall() function and pass it two arguments: the pattern, followed by the string. \\\\d is the pattern required to find digits. This should be followed with a + so that the previous element is matched one or more times. This ensures that 10 is viewed as one number and not as 1 and 0. Print the matches to confirm that your regular expression found the values 10 and 1.\",\n",
       " nan,\n",
       " 'Write patterns to match: A telephone number of the format xxx-xxx-xxxx. You already did this in a previous exercise. A string of the format: A dollar sign, an arbitrary number of digits, a decimal point, 2 digits. Use $ to match the dollar sign, \\\\d* to match an arbitrary number of digits, . to match the decimal point, and \\\\d{x} to match x number of digits. A capital letter, followed by an arbitrary number of alphanumeric characters. Use [A-Z] to match any capital letter followed by \\\\w* to match an arbitrary number of alphanumeric characters.',\n",
       " nan,\n",
       " \"Define a function named recode_sex() that has one parameter: sex_value. If sex_value equals 'Male', return 1. Else, if sex_value equals 'Female', return 0. If sex_value does not equal 'Male' or 'Female', return np.nan. NumPy has been pre-imported for you. Apply your recode_sex() function over tips.sex using the .apply() method to create a new column: 'sex_recode'. Note that when passing in a function inside the .apply() method, you don't need to specify the parentheses after the function name. Hit 'Submit Answer' and take note of the new 'sex_recode'column in the tips DataFrame!\",\n",
       " nan,\n",
       " 'df.apply(my_square)',\n",
       " 'The equivalent code using a lambda function is: df.apply(lambda x: x ** 2)',\n",
       " \"The lambda function takes one parameter - the variable x. The function itself just squares x and returns the result, which is whatever the one line of code evaluates to. In this way, lambda functions can make your code concise and Pythonic. The tips dataset has been pre-loaded into a DataFrame called tips. Your job is to clean its 'total_dollar' column by removing the dollar sign. You'll do this using two different methods: With the .replace() method, and with regular expressions. The regular expression module re has been pre-imported.\",\n",
       " \"Use the .replace() method inside a lambda function to remove the dollar sign from the 'total_dollar' column of tips. You need to specify two arguments to the .replace()method: The string to be replaced ('$'), and the string to replace it by (''). Apply the lambda function over the 'total_dollar'column of tips. Use a regular expression to remove the dollar sign from the 'total_dollar' column of tips. The pattern has been provided for you: It is the first argument of the re.findall() function. Complete the rest of the lambda function and apply it over the 'total_dollar' column of tips. Notice that because re.findall() returns a list, you have to slice it in order to access the actual value. Hit 'Submit Answer' to verify that you have removed the dollar sign from the column.\",\n",
       " nan,\n",
       " \"Create a new DataFrame called tracks that contains the following columns from billboard: 'year', 'artist', 'track', and 'time'. Print the info of tracks. This has been done for you. Drop duplicate rows from tracks using the .drop_duplicates() method. Save the result to tracks_no_duplicates. Print the info of tracks_no_duplicates. This has been done for you, so hit 'Submit Answer' to see the results!\",\n",
       " nan,\n",
       " \"Calculate the mean of the Ozone column of airqualityusing the .mean() method on airquality.Ozone. Use the .fillna() method to replace all the missing values in the Ozone column of airquality with the mean, oz_mean. Hit 'Submit Answer' to see the result of filling in the missing values!\",\n",
       " nan,\n",
       " 'Write an assert statement to confirm that there are no missing values in ebola. Use the pd.notnull() function on ebola (or the .notnull() method of ebola) and chain two .all() methods (that is, .all().all()). The first .all() method will return a True or False for each column, while the second .all() method will return a single True or False. Write an assert statement to confirm that all values in ebolaare greater than or equal to 0. Chain two all() methods to the Boolean condition (ebola >= 0).',\n",
       " nan,\n",
       " \"Each data point is a customer. The first input is how many accounts they have, and the second input is how many children they have. The model will predict how many transactions the user makes in the next year. You will use this data throughout the first 2 chapters of this course. The input data has been pre-loaded as input_data, and the weights are available in a dictionary called weights. The array of weights for the first node in the hidden layer are in weights['node_0'], and the array of weights for the second node in the hidden layer are in weights['node_1']. The weights feeding into the output node are available in weights['output']. NumPy will be pre-imported for you as np in all exercises.\",\n",
       " \"Calculate the value in node 0 by multiplying input_data by its weights weights['node_0'] and computing their sum. This is the 1st node in the hidden layer. Calculate the value in node 1 using input_data and weights['node_1']. This is the 2nd node in the hidden layer. Put the hidden layer values into an array. This has been done for you. Generate the prediction by multiplying hidden_layer_outputs by weights['output'] and computing their sum. Hit 'Submit Answer' to print the output!\",\n",
       " nan,\n",
       " 'Fill in the definition of the relu() function: Use the max() function to calculate the value for the output of relu(). Apply the relu() function to node_0_input to calculate node_0_output. Apply the relu() function to node_1_input to calculate node_1_output.',\n",
       " nan,\n",
       " 'Define a function called predict_with_network() that accepts two arguments - input_data_row and weights - and returns a prediction from the network as the output. Calculate the input and output values for each node, storing them as: node_0_input, node_0_output, node_1_input, and node_1_output. To calculate the input value of a node, multiply the relevant arrays together and compute their sum. To calculate the output value of a node, apply the relu()function to the input value of the node. Use a for loop to iterate over input_data: Use your predict_with_network() to generate predictions for each row of the input_data - input_data_row. Append each prediction to results.',\n",
       " nan,\n",
       " \"Calculate node_0_0_input using its weights weights['node_0_0'] and the given input_data. Then apply the relu() function to get node_0_0_output. Do the same as above for node_0_1_input to get node_0_1_output. Calculate node_1_0_input using its weights weights['node_1_0'] and the outputs from the first hidden layer - hidden_0_outputs. Then apply the relu() function to get node_1_0_output. Do the same as above for node_1_1_input to get node_1_1_output. Calculate model_output using its weights weights['output'] and the outputs from the second hidden layer hidden_1_outputs array. Do not apply the relu() function to this output.\",\n",
       " nan,\n",
       " \"Create a dictionary of weights called weights_1 where you have changed 1 weight from weights_0 (You only need to make 1 edit to weights_0 to generate the perfect prediction). Obtain predictions with the new weights using the predict_with_network() function with input_data and weights_1. Calculate the error for the new weights by subtracting target_actual from model_output_1. Hit 'Submit Answer' to see how the errors compare!\",\n",
       " nan,\n",
       " 'Import mean_squared_error from sklearn.metrics. Using a for loop to iterate over each row of input_data: Make predictions for each row with weights_0 using the predict_with_network()function and append it to model_output_0. Do the same for weights_1, appending the predictions to model_output_1. Calculate the mean squared error of model_output_0 and then model_output_1 using the mean_squared_error() function. The first argument should be the actual values (target_actuals), and the second argument should be the predicted values (model_output_0 or model_output_1).',\n",
       " nan,\n",
       " 'Calculate the predictions, preds, by multiplying weightsby the input_data and computing their sum. Calculate the error, which is the difference between targetand preds. Notice that this error corresponds to y-xb in the gradient expression. Calculate the slope of the loss function with respect to the prediction. To do this, you need to take the product of input_data and error and multiply that by 2.',\n",
       " nan,\n",
       " \"Set the learning rate to be 0.01 and calculate the error from the original predictions. This has been done for you. Calculate the updated weights by subtracting the product of learning_rate and slope from weights. Calculate the updated predictions by multiplying weights_updated with input_data and computing their sum. Calculate the error for the new predictions. Store the result as error_updated. Hit 'Submit Answer' to compare the updated error to the original!\",\n",
       " nan,\n",
       " \"Using a for loop to iteratively update weights: Calculate the slope using the get_slope() function. Update the weights using a learning rate of 0.01. Calculate the mean squared error (mse) with the updated weights using the get_mse() function. Append mse to mse_hist. Hit 'Submit Answer' to visualize mse_hist. What trend do you notice?\",\n",
       " nan,\n",
       " \"Store the number of columns in the predictors data to n_cols. This has been done for you. Start by creating a Sequential model called model. Use the .add() method on model to add a Dense layer. Add 50 units, specify activation='relu', and the input_shape parameter to be the tuple (n_cols,) which means it has n_cols items in each row of data, and any number of rows of data are acceptable as inputs. Add another Dense layer. This should have 32 units and a 'relu'activation. Finally, add an output layer, which is a Dense layer with a single node. Don't use any activation function here.\",\n",
       " nan,\n",
       " \"Compile the model using model.compile(). Your optimizer should be 'adam' and the loss should be 'mean_squared_error'.\",\n",
       " nan,\n",
       " 'Fit the model. Remember that the first argument is the predictive features (predictors), and the data to be predicted (target) is the second argument.',\n",
       " nan,\n",
       " \"Convert df.survived to a categorical variable using the to_categorical() function. Specify a Sequential model called model. Add a Dense layer with 32 nodes. Use 'relu' as the activationand (n_cols,) as the input_shape. Add the Dense output layer. Because there are two outcomes, it should have 2 units, and because it is a classification model, the activation should be 'softmax'. Compile the model, using 'sgd' as the optimizer, 'categorical_crossentropy' as the loss function, and metrics=['accuracy'] to see the accuracy (what fraction of predictions were correct) at the end of each epoch. Fit the model using the predictors and the target.\",\n",
       " nan,\n",
       " \"Create your predictions using the model's .predict() method on pred_data. Use NumPy indexing to find the column corresponding to predicted probabilities of survival being True. This is the second column (index 1) of predictions. Store the result in predicted_prob_true and print it.\",\n",
       " nan,\n",
       " \"Import SGD from keras.optimizers. Create a list of learning rates to try optimizing with called lr_to_test. The learning rates in it should be .000001, 0.01, and 1. Using a for loop to iterate over lr_to_test: Use the get_new_model()function to build a new, unoptimized model. Create an optimizer called my_optimizer using the SGD() constructor with keyword argument lr=lr. Compile your model. Set the optimizer parameter to be the SGD object you created above, and because this is a classification problem, use 'categorical_crossentropy'for the loss parameter. Fit your model using the predictors and target.\",\n",
       " nan,\n",
       " \"Compile your model using 'adam' as the optimizer and 'categorical_crossentropy' for the loss. To see what fraction of predictions are correct (the accuracy) in each epoch, specify the additional keyword argument metrics=['accuracy'] in model.compile(). Fit the model using the predictorsand target. Create a validation split of 30% (or 0.3). This will be reported in each epoch.\",\n",
       " nan,\n",
       " \"Import EarlyStopping from keras.callbacks. Compile the model, once again using 'adam' as the optimizer, 'categorical_crossentropy' as the loss function, and metrics=['accuracy'] to see the accuracy at each epoch. Create an EarlyStopping object called early_stopping_monitor. Stop optimization when the validation loss hasn't improved for 2 epochs by specifying the patience parameter of EarlyStopping() to be 2. Fit the model using the predictorsand target. Specify the number of epochs to be 30 and use a validation split of 0.3. In addition, pass [early_stopping_monitor] to the callbacks parameter.\",\n",
       " nan,\n",
       " \"Create model_2 to replicate model_1, but use 100 nodes instead of 10 for the first two Dense layers you add with the 'relu' activation. Use 2 nodes for the Dense output layer with 'softmax' as the activation. Compile model_2 as you have done with previous models: Using 'adam'as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy']. Hit 'Submit Answer' to fit both the models and visualize which one gives better results! Notice the keyword argument verbose=False in model.fit(): This prints out fewer updates, since you'll be evaluating the models graphically instead of through text.\",\n",
       " nan,\n",
       " \"Specify a model called model_2 that is like model_1, but which has 3 hidden layers of 50 units instead of only 1 hidden layer. Use input_shape to specify the input shape in the first hidden layer. Use 'relu' activation for the 3 hidden layers and 'softmax'for the output layer, which should have 2 units. Compile model_2 as you have done with previous models: Using 'adam'as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy']. Hit 'Submit Answer' to fit both the models and visualize which one gives better results! For both models, you should look for the best val_loss and val_acc, which won't be the last epoch for that model.\",\n",
       " nan,\n",
       " \"Create a Sequential object to start your model. Call this model. Add the first Dense hidden layer of 50 units to your model with 'relu'activation. For this data, the input_shape is (784,). Add a second Dense hidden layer with 50 units and a 'relu' activation function. Add the output layer. Your activation function should be 'softmax', and the number of nodes in this layer should be the same as the number of possible outputs in this case: 10. Compile model as you have done with previous models: Using 'adam' as the optimizer, 'categorical_crossentropy' for the loss, and metrics=['accuracy']. Fit the model using X and y using a validation_split of 0.3.\",\n",
       " nan,\n",
       " \"Open the file moby_dick.txt as read-only and store it in the variable file. Make sure to pass the filename enclosed in quotation marks ''. Print the contents of the file to the shell using the print()function. As Hugo showed in the video, you'll need to apply the method read() to the object file. Check whether the file is closed by executing print(file.closed). Close the file using the close() method. Check again that the file is closed as you did above.\",\n",
       " nan,\n",
       " \"While still within this construct, the variable file will be bound to open('huck_finn.txt'); thus, to print the file to the shell, all the code you need to execute is: with open('huck_finn.txt') as file: print(file.read())\",\n",
       " \"You'll now use these tools to print the first few lines of moby_dick.txt!\",\n",
       " 'Open moby_dick.txt using the with context manager and the variable file. Print the first three lines of the file to the shell by using readline() three times within the context manager.',\n",
       " nan,\n",
       " \"Fill in the arguments of np.loadtxt() by passing file and a comma ',' for the delimiter. Fill in the argument of print() to print the type of the object digits. Use the function type(). Execute the rest of the code to visualize one of the rows of the data.\",\n",
       " nan,\n",
       " \"Complete the arguments of np.loadtxt(): the file you're importing is tab-delimited, you want to skip the first row and you only want to import the first and third columns. Complete the argument of the print() call in order to print the entire array that you just imported.\",\n",
       " nan,\n",
       " \"Complete the first call to np.loadtxt() by passing file as the first argument. Execute print(data[0]) to print the first element of data. Complete the second call to np.loadtxt(). The file you're importing is tab-delimited, the datatype is float, and you want to skip the first row. Print the 10th element of data_float by completing the print() command. Be guided by the previous print()call. Execute the rest of the code to visualize the data.\",\n",
       " \"## Working with mixed datatypes (1) 50xp Much of the time you will need to import datasets which have different datatypes in different columns; one column may contain strings and another floats, for example. The functionnp.loadtxt() will freak at this. There is another function, np.genfromtxt(), which can handle such structures. If we pass dtype=None to it, it will figure out what types each column should be. Import 'titanic.csv' using the function np.genfromtxt() as follows: data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\",\n",
       " \"Here, the first argument is the filename, the second specifies the delimiter , and the third argument names tells us there is a header. Because the data are of different types, data is an object called a structured array. Because numpy arrays have to contain elements that are all the same type, the structured array solves this by being a 1D array, where each element of the array is a row of the flat file imported. You can test this by checking out the array's shape in the shell by executing np.shape(data). Acccessing rows and columns of structured arrays is super-intuitive: to get the ith row, merely execute data[i] and to get the column with name 'Fare', execute data['Fare']. Print the entire column with name Survived to the shell. What are the last 4 values of this column?\",\n",
       " nan,\n",
       " \"Import titanic.csv using the function np.recfromcsv()and assign it to the variable, d. You'll only need to pass file to it because it has the defaults delimiter=',' and names=True in addition to dtype=None! Run the remaining code to print the first three entries of the resulting array d.\",\n",
       " nan,\n",
       " 'Import the pandas package using the alias pd. Read titanic.csv into a DataFrame called df. The file name is already stored in the file object. In a print() call, view the head of the DataFrame.',\n",
       " \"##Using pandas to import flat files as DataFrames (2) 0xp In the last exercise, you were able to import flat files into a pandasDataFrame. As a bonus, it is then straightforward to retrieve the corresponding numpy array using the attribute values. You'll now have a chance to do this using the MNIST dataset, which is available as digits.csv.\",\n",
       " \"Import the first 5 rows of the file into a DataFrame using the function pd.read_csv() and assign the result to data. You'll need to use the arguments nrows and header (there is no header in this file). Build a numpy array from the resulting DataFrame in dataand assign to data_array. Execute print(type(data_array)) to print the datatype of data_array\",\n",
       " nan,\n",
       " \"Complete the sep (the pandas version of delim), comment and na_values arguments of pd.read_csv(). comment takes characters that comments occur after in the file, which in this case is '#'. na_values takes a list of strings to recognize as NA/NaN, in this case the string 'Nothing'. Execute the rest of the code to print the head of the resulting DataFrame and plot the histogram of the 'Age' of passengers aboard the Titanic.\",\n",
       " nan,\n",
       " \"Import the pickle package. Complete the second argument of open() so that it is read only for a binary file. This argument will be a string of two letters, one signifying 'read only', the other 'binary'. Pass the correct argument to pickle.load(); it should use the variable that is bound to open. Print the data, d. Print the datatype of d; take your mind back to your previous use of the function type().\",\n",
       " nan,\n",
       " 'Assign the filename to the variable file. Pass the correct argument to pd.ExcelFile() to load the file using pandas. Print the sheetnames of the Excel spreadsheet by passing the necessary argument to the print() function.',\n",
       " nan,\n",
       " \"Load the sheet '2004' into the DataFrame df1 using its name as a string. Print the head of df1 to the shell. Load the sheet 2002 into the DataFrame df2 using its index. Print the head of df2 to the shell.\",\n",
       " nan,\n",
       " \"Parse the first sheet by index. In doing so, skip the first row of data and name the columns 'Country' and 'AAM due to War (2002)' using the argument names. The values passed to skiprows and names all need to be of type list. Parse the second sheet by index. In doing so, parse only the first column with the parse_cols parameter, skip the first row and rename the column 'Country'. The argument passed to parse_cols also needs to be of type list.\",\n",
       " nan,\n",
       " 'The data are adapted from the website of the undergraduate text bookPrinciples of Economics by Hill, Griffiths and Lim.',\n",
       " \"Import the module SAS7BDAT from the library sas7bdat. In the context of the file 'sales.sas7bdat', load its contents to a DataFrame df_sas, using the method to_data_frame() on the object file. Print the head of the DataFrame df_sas. Execute your entire script to produce a histogram plot!\",\n",
       " nan,\n",
       " \"Use pd.read_stata() to load the file 'disarea.dta' into the DataFrame df. Print the head of the DataFrame df. Visualize your results by plotting a histogram of the column disa10. Weâ€™ve already provided this code for you, so just run it!\",\n",
       " nan,\n",
       " \"Import the package h5py. Assign the name of the file to the variable file. Load the file as read only into the variable data. Print the datatype of data. Print the names of the groups in the HDF5 file 'LIGO_data.hdf5'.\",\n",
       " nan,\n",
       " \"Assign the HDF5 group data['strain'] to group. In the for loop, print out the keys of the HDF5 group in group. Assign to the variable strain the values of the time series data data['strain']['Strain'] using the attribute .value. Set num_samples equal to 10000, the number of time points we wish to sample. Execute the rest of the code to produce a plot of the time series data in LIGO_data.hdf5.\",\n",
       " nan,\n",
       " \"Import the package scipy.io. Load the file 'albeck_gene_expression.mat' into the variable mat\",\n",
       " nan,\n",
       " 'Once again, this file contains gene expression data from the Albeck Lab at UCDavis. You can find the data and some great documentation here.',\n",
       " \"Use the method .keys() on the dictionary mat to print the keys. Most of these keys (in fact the ones that do NOT begin and end with '__') are variables from the corresponding MATLAB environment. Print the type of the value corresponding to the key 'CYratioCyt' in mat. Recall that mat['CYratioCyt']accesses the value. Print the shape of the value corresponding to the key 'CYratioCyt' using the numpy function shape(). Execute the entire script to see some oscillatory gene expression data!\",\n",
       " nan,\n",
       " \"Here, 'sqlite:///Northwind.sqlite' is called the connection string to the SQLite database Northwind.sqlite. A little bit of background on the Chinook database: the Chinook database contains information about a semi-fictional digital media store in which media data is real and customer, employee and sales data has been manually created. Why the name Chinook, you ask? According to their website, The name of this sample database was based on the Northwind database. Chinooks are winds in the interior West of North America, where the Canadian Prairies and Great Plains meet various mountain ranges. Chinooks are most prevalent over southern Alberta in Canada. Chinook is a good name choice for a database that intends to be an alternative to Northwind.\",\n",
       " \"Import the function create_engine from the module sqlalchemy. Create an engine to connect to the SQLite database 'Chinook.sqlite' and assign it to engine. Take Hint (-30xp)\",\n",
       " nan,\n",
       " \"Import the function create_engine from the module sqlalchemy. Create an engine to connect to the SQLite database 'Chinook.sqlite'and assign it to engine. Using the method table_names() on the engine engine, assign the table names of 'Chinook.sqlite' to the variable table_names. Print the object table_names to the shell.\",\n",
       " nan,\n",
       " 'Open the engine connection as con using the method connect() on the engine. Execute the query that selects ALL columns from the Album table. Store the results in rs. Store all of your query results in the DataFrame df by applying the fetchall() method to the results rs. Close the connection!',\n",
       " nan,\n",
       " 'with engine.connect() as con: rs = con.execute(\"SELECT OrderID, OrderDate, ShipName FROM Orders\") df = pd.DataFrame(rs.fetchmany(size=5)) df.columns = rs.keys()',\n",
       " 'Packages have already been imported as follows: from sqlalchemy import create_engine import pandas as pd',\n",
       " \"The engine has also already been created: engine = create_engine('sqlite:///Chinook.sqlite')\",\n",
       " 'The engine connection is already open with the statement with engine.connect() as con:',\n",
       " 'All the code you need to complete is within this context.',\n",
       " \"Execute the SQL query that selects the columns LastName and Title from the Employee table. Store the results in the variable rs. Apply the method fetchmany() to rs in order to retrieve 3 of the records. Store them in the DataFrame df. Using the rs object, set the DataFrame's column names to the corresponding names of the table columns.\",\n",
       " nan,\n",
       " \"In fact, you can filter any SELECT statement by any condition using a WHEREclause. This is called filtering your records. In this interactive exercise, you'll select all records of the Employee table for which 'EmployeeId' is greater than or equal to 6. Packages are already imported as follows: import pandas as pd from sqlalchemy import create_engine\",\n",
       " 'Query away!',\n",
       " \"Complete the argument of create_engine() so that the engine for the SQLite database 'Chinook.sqlite' is created. Execute the query that selects all records from the Employee table where 'EmployeeId' is greater than or equal to 6. Use the >=operator and assign the results to rs. Apply the method fetchall() to rs in order to fetch all records in rs. Store them in the DataFrame df. Using the rs object, set the DataFrame's column names to the corresponding names of the table columns.\",\n",
       " nan,\n",
       " \"In fact, you can order any SELECT statement by any column. In this interactive exercise, you'll select all records of the Employee table and order them in increasing order by the column BirthDate. Packages are already imported as follows: import pandas as pd from sqlalchemy import create_engine\",\n",
       " 'Get querying!',\n",
       " \"Using the function create_engine(), create an engine for the SQLite database Chinook.sqlite and assign it to the variable engine. In the context manager, execute the query that selects all records from the Employee table and orders them in increasing order by the column BirthDate. Assign the result to rs. In a call to pd.DataFrame(), apply the method fetchall() to rs in order to fetch all records in rs. Store them in the DataFrame df. Set the DataFrame's column names to the corresponding names of the table columns.\",\n",
       " nan,\n",
       " 'Using the function create_engine(), create an engine for the SQLite database Chinook.sqlite and assign it to the variable engine. Use the pandas function read_sql_query() to assign to the variable df the DataFrame of results from the following query: select all records from the Employee table where the EmployeeId is greater than or equal to 6 and ordered by BirthDate (make sure to use WHERE and ORDER BY in this precise order).',\n",
       " nan,\n",
       " \"The following code has already been executed to import the necessary packages and to create the engine: import pandas as pd from sqlalchemy import create_engine engine = create_engine('sqlite:///Chinook.sqlite')\",\n",
       " \"Assign to rs the results from the following query: select all the records, extracting the Title of the record and Name of the artist of each record from the Album table and the Artist table, respectively. To do so, INNER JOIN these two tables on the ArtistID column of both. In a call to pd.DataFrame(), apply the method fetchall() to rs in order to fetch all records in rs. Store them in the DataFrame df. Set the DataFrame's column names to the corresponding names of the table columns.\",\n",
       " nan,\n",
       " \"The following code has already been executed to import the neccesary packages and to create the engine: import pandas as pd from sqlalchemy import create_engine engine = create_engine('sqlite:///Chinook.sqlite')\",\n",
       " 'Use the pandas function read_sql_query() to assign to the variable df the DataFrame of results from the following query: select allrecords from PlaylistTrack INNER JOIN Track on PlaylistTrack.TrackId = Track.TrackId that satisfy the condition Milliseconds < 250000.',\n",
       " nan,\n",
       " \"Open the file moby_dick.txt as read-only and store it in the variable file. Make sure to pass the filename enclosed in quotation marks ''. Print the contents of the file to the shell using the print()function. As Hugo showed in the video, you'll need to apply the method read() to the object file. Check whether the file is closed by executing print(file.closed). Close the file using the close() method. Check again that the file is closed as you did above.\",\n",
       " nan,\n",
       " \"While still within this construct, the variable file will be bound to open('huck_finn.txt'); thus, to print the file to the shell, all the code you need to execute is: with open('huck_finn.txt') as file: print(file.read())\",\n",
       " \"You'll now use these tools to print the first few lines of moby_dick.txt!\",\n",
       " 'Open moby_dick.txt using the with context manager and the variable file. Print the first three lines of the file to the shell by using readline() three times within the context manager.',\n",
       " nan,\n",
       " \"Fill in the arguments of np.loadtxt() by passing file and a comma ',' for the delimiter. Fill in the argument of print() to print the type of the object digits. Use the function type(). Execute the rest of the code to visualize one of the rows of the data.\",\n",
       " nan,\n",
       " \"Complete the arguments of np.loadtxt(): the file you're importing is tab-delimited, you want to skip the first row and you only want to import the first and third columns. Complete the argument of the print() call in order to print the entire array that you just imported.\",\n",
       " nan,\n",
       " \"Complete the first call to np.loadtxt() by passing file as the first argument. Execute print(data[0]) to print the first element of data. Complete the second call to np.loadtxt(). The file you're importing is tab-delimited, the datatype is float, and you want to skip the first row. Print the 10th element of data_float by completing the print() command. Be guided by the previous print()call. Execute the rest of the code to visualize the data.\",\n",
       " \"## Working with mixed datatypes (1) 50xp Much of the time you will need to import datasets which have different datatypes in different columns; one column may contain strings and another floats, for example. The functionnp.loadtxt() will freak at this. There is another function, np.genfromtxt(), which can handle such structures. If we pass dtype=None to it, it will figure out what types each column should be. Import 'titanic.csv' using the function np.genfromtxt() as follows: data = np.genfromtxt('titanic.csv', delimiter=',', names=True, dtype=None)\",\n",
       " \"Here, the first argument is the filename, the second specifies the delimiter , and the third argument names tells us there is a header. Because the data are of different types, data is an object called a structured array. Because numpy arrays have to contain elements that are all the same type, the structured array solves this by being a 1D array, where each element of the array is a row of the flat file imported. You can test this by checking out the array's shape in the shell by executing np.shape(data). Acccessing rows and columns of structured arrays is super-intuitive: to get the ith row, merely execute data[i] and to get the column with name 'Fare', execute data['Fare']. Print the entire column with name Survived to the shell. What are the last 4 values of this column?\",\n",
       " nan,\n",
       " \"Import titanic.csv using the function np.recfromcsv()and assign it to the variable, d. You'll only need to pass file to it because it has the defaults delimiter=',' and names=True in addition to dtype=None! Run the remaining code to print the first three entries of the resulting array d.\",\n",
       " nan,\n",
       " 'Import the pandas package using the alias pd. Read titanic.csv into a DataFrame called df. The file name is already stored in the file object. In a print() call, view the head of the DataFrame.',\n",
       " \"##Using pandas to import flat files as DataFrames (2) 0xp In the last exercise, you were able to import flat files into a pandasDataFrame. As a bonus, it is then straightforward to retrieve the corresponding numpy array using the attribute values. You'll now have a chance to do this using the MNIST dataset, which is available as digits.csv.\",\n",
       " \"Import the first 5 rows of the file into a DataFrame using the function pd.read_csv() and assign the result to data. You'll need to use the arguments nrows and header (there is no header in this file). Build a numpy array from the resulting DataFrame in dataand assign to data_array. Execute print(type(data_array)) to print the datatype of data_array\",\n",
       " nan,\n",
       " \"Complete the sep (the pandas version of delim), comment and na_values arguments of pd.read_csv(). comment takes characters that comments occur after in the file, which in this case is '#'. na_values takes a list of strings to recognize as NA/NaN, in this case the string 'Nothing'. Execute the rest of the code to print the head of the resulting DataFrame and plot the histogram of the 'Age' of passengers aboard the Titanic.\",\n",
       " nan,\n",
       " \"Import the pickle package. Complete the second argument of open() so that it is read only for a binary file. This argument will be a string of two letters, one signifying 'read only', the other 'binary'. Pass the correct argument to pickle.load(); it should use the variable that is bound to open. Print the data, d. Print the datatype of d; take your mind back to your previous use of the function type().\",\n",
       " nan,\n",
       " 'Assign the filename to the variable file. Pass the correct argument to pd.ExcelFile() to load the file using pandas. Print the sheetnames of the Excel spreadsheet by passing the necessary argument to the print() function.',\n",
       " nan,\n",
       " \"Load the sheet '2004' into the DataFrame df1 using its name as a string. Print the head of df1 to the shell. Load the sheet 2002 into the DataFrame df2 using its index. Print the head of df2 to the shell.\",\n",
       " nan,\n",
       " \"Parse the first sheet by index. In doing so, skip the first row of data and name the columns 'Country' and 'AAM due to War (2002)' using the argument names. The values passed to skiprows and names all need to be of type list. Parse the second sheet by index. In doing so, parse only the first column with the parse_cols parameter, skip the first row and rename the column 'Country'. The argument passed to parse_cols also needs to be of type list.\",\n",
       " nan,\n",
       " 'The data are adapted from the website of the undergraduate text bookPrinciples of Economics by Hill, Griffiths and Lim.',\n",
       " \"Import the module SAS7BDAT from the library sas7bdat. In the context of the file 'sales.sas7bdat', load its contents to a DataFrame df_sas, using the method to_data_frame() on the object file. Print the head of the DataFrame df_sas. Execute your entire script to produce a histogram plot!\",\n",
       " nan,\n",
       " \"Use pd.read_stata() to load the file 'disarea.dta' into the DataFrame df. Print the head of the DataFrame df. Visualize your results by plotting a histogram of the column disa10. Weâ€™ve already provided this code for you, so just run it!\",\n",
       " nan,\n",
       " \"Import the package h5py. Assign the name of the file to the variable file. Load the file as read only into the variable data. Print the datatype of data. Print the names of the groups in the HDF5 file 'LIGO_data.hdf5'.\",\n",
       " nan,\n",
       " \"Assign the HDF5 group data['strain'] to group. In the for loop, print out the keys of the HDF5 group in group. Assign to the variable strain the values of the time series data data['strain']['Strain'] using the attribute .value. Set num_samples equal to 10000, the number of time points we wish to sample. Execute the rest of the code to produce a plot of the time series data in LIGO_data.hdf5.\",\n",
       " nan,\n",
       " \"Import the package scipy.io. Load the file 'albeck_gene_expression.mat' into the variable mat\",\n",
       " nan,\n",
       " 'Once again, this file contains gene expression data from the Albeck Lab at UCDavis. You can find the data and some great documentation here.',\n",
       " \"Use the method .keys() on the dictionary mat to print the keys. Most of these keys (in fact the ones that do NOT begin and end with '__') are variables from the corresponding MATLAB environment. Print the type of the value corresponding to the key 'CYratioCyt' in mat. Recall that mat['CYratioCyt']accesses the value. Print the shape of the value corresponding to the key 'CYratioCyt' using the numpy function shape(). Execute the entire script to see some oscillatory gene expression data!\",\n",
       " nan,\n",
       " \"Here, 'sqlite:///Northwind.sqlite' is called the connection string to the SQLite database Northwind.sqlite. A little bit of background on the Chinook database: the Chinook database contains information about a semi-fictional digital media store in which media data is real and customer, employee and sales data has been manually created. Why the name Chinook, you ask? According to their website, The name of this sample database was based on the Northwind database. Chinooks are winds in the interior West of North America, where the Canadian Prairies and Great Plains meet various mountain ranges. Chinooks are most prevalent over southern Alberta in Canada. Chinook is a good name choice for a database that intends to be an alternative to Northwind.\",\n",
       " \"Import the function create_engine from the module sqlalchemy. Create an engine to connect to the SQLite database 'Chinook.sqlite' and assign it to engine. Take Hint (-30xp)\",\n",
       " nan,\n",
       " \"Import the function create_engine from the module sqlalchemy. Create an engine to connect to the SQLite database 'Chinook.sqlite'and assign it to engine. Using the method table_names() on the engine engine, assign the table names of 'Chinook.sqlite' to the variable table_names. Print the object table_names to the shell.\",\n",
       " nan,\n",
       " 'Open the engine connection as con using the method connect() on the engine. Execute the query that selects ALL columns from the Album table. Store the results in rs. Store all of your query results in the DataFrame df by applying the fetchall() method to the results rs. Close the connection!',\n",
       " nan,\n",
       " 'with engine.connect() as con: rs = con.execute(\"SELECT OrderID, OrderDate, ShipName FROM Orders\") df = pd.DataFrame(rs.fetchmany(size=5)) df.columns = rs.keys()',\n",
       " 'Packages have already been imported as follows: from sqlalchemy import create_engine import pandas as pd',\n",
       " \"The engine has also already been created: engine = create_engine('sqlite:///Chinook.sqlite')\",\n",
       " 'The engine connection is already open with the statement with engine.connect() as con:',\n",
       " 'All the code you need to complete is within this context.',\n",
       " \"Execute the SQL query that selects the columns LastName and Title from the Employee table. Store the results in the variable rs. Apply the method fetchmany() to rs in order to retrieve 3 of the records. Store them in the DataFrame df. Using the rs object, set the DataFrame's column names to the corresponding names of the table columns.\",\n",
       " nan,\n",
       " \"In fact, you can filter any SELECT statement by any condition using a WHEREclause. This is called filtering your records. In this interactive exercise, you'll select all records of the Employee table for which 'EmployeeId' is greater than or equal to 6. Packages are already imported as follows: import pandas as pd from sqlalchemy import create_engine\",\n",
       " 'Query away!',\n",
       " \"Complete the argument of create_engine() so that the engine for the SQLite database 'Chinook.sqlite' is created. Execute the query that selects all records from the Employee table where 'EmployeeId' is greater than or equal to 6. Use the >=operator and assign the results to rs. Apply the method fetchall() to rs in order to fetch all records in rs. Store them in the DataFrame df. Using the rs object, set the DataFrame's column names to the corresponding names of the table columns.\",\n",
       " nan,\n",
       " \"In fact, you can order any SELECT statement by any column. In this interactive exercise, you'll select all records of the Employee table and order them in increasing order by the column BirthDate. Packages are already imported as follows: import pandas as pd from sqlalchemy import create_engine\",\n",
       " 'Get querying!',\n",
       " \"Using the function create_engine(), create an engine for the SQLite database Chinook.sqlite and assign it to the variable engine. In the context manager, execute the query that selects all records from the Employee table and orders them in increasing order by the column BirthDate. Assign the result to rs. In a call to pd.DataFrame(), apply the method fetchall() to rs in order to fetch all records in rs. Store them in the DataFrame df. Set the DataFrame's column names to the corresponding names of the table columns.\",\n",
       " nan,\n",
       " 'Using the function create_engine(), create an engine for the SQLite database Chinook.sqlite and assign it to the variable engine. Use the pandas function read_sql_query() to assign to the variable df the DataFrame of results from the following query: select all records from the Employee table where the EmployeeId is greater than or equal to 6 and ordered by BirthDate (make sure to use WHERE and ORDER BY in this precise order).',\n",
       " nan,\n",
       " \"The following code has already been executed to import the necessary packages and to create the engine: import pandas as pd from sqlalchemy import create_engine engine = create_engine('sqlite:///Chinook.sqlite')\",\n",
       " \"Assign to rs the results from the following query: select all the records, extracting the Title of the record and Name of the artist of each record from the Album table and the Artist table, respectively. To do so, INNER JOIN these two tables on the ArtistID column of both. In a call to pd.DataFrame(), apply the method fetchall() to rs in order to fetch all records in rs. Store them in the DataFrame df. Set the DataFrame's column names to the corresponding names of the table columns.\",\n",
       " nan,\n",
       " \"The following code has already been executed to import the neccesary packages and to create the engine: import pandas as pd from sqlalchemy import create_engine engine = create_engine('sqlite:///Chinook.sqlite')\",\n",
       " 'Use the pandas function read_sql_query() to assign to the variable df the DataFrame of results from the following query: select allrecords from PlaylistTrack INNER JOIN Track on PlaylistTrack.TrackId = Track.TrackId that satisfy the condition Milliseconds < 250000.',\n",
       " nan,\n",
       " \"After you import it, you'll check your working directory to confirm that it is there and then you'll load it into a pandas DataFrame.\",\n",
       " \"Import the function urlretrieve from the subpackage urllib.request. Assign the URL of the file to the variable url. Use the function urlretrieve() to save the file locally as 'winequality-red.csv'. Execute the remaining code to load 'winequality-red.csv'in a pandas DataFrame and to print its head to the shell.\",\n",
       " nan,\n",
       " \"Assign the URL of the file to the variable url. Read file into a DataFrame df using pd.read_csv(), recalling that the separator in the file is ';'. Print the head of the DataFrame df. Execute the rest of the code to plot histogram of the first feature in the DataFrame df.\",\n",
       " nan,\n",
       " 'Your job is to use pd.read_excel() to read in all of its sheets, print the sheet names and then print the head of the first sheet using its name, not its index. Note that the output of pd.read_excel() is a Python dictionary with sheet names as keys and corresponding DataFrames as corresponding values.',\n",
       " \"Assign the URL of the file to the variable url. Read the file in url into a dictionary xl using pd.read_excel() recalling that, in order to import all sheets you need to pass None to the argument sheetname. Print the names of the sheets in the Excel spreadsheet; these will be the keys of the dictionary xl. Print the head of the first sheet using the sheet name, not the index of the sheet! The sheet name is '1700'\",\n",
       " nan,\n",
       " 'Import the functions urlopen and Request from the subpackage urllib.request. Package the request to the url \"http://www.datacamp.com/teach/documentation\"using the function Request() and assign it to request. Send the request and catch the response in the variable response with the function urlopen(). Run the rest of the code to see the datatype of response and to close the connection!',\n",
       " nan,\n",
       " 'Send the request and catch the response in the variable response with the function urlopen(), as in the previous exercise. Extract the response using the read()method and store the result in the variable html. Print the string html. Hit submit to perform all of the above and to close the response: be tidy!',\n",
       " nan,\n",
       " 'Import the package requests. Assign the URL of interest to the variable url. Package the request to the URL, send the request and catch the response with a single function requests.get(), assigning the response to the variable r. Use the text attribute of the object r to return the HTML of the webpage as a string; store the result in a variable text. Hit submit to print the HTML of the webpage.',\n",
       " nan,\n",
       " 'Import the function BeautifulSoupfrom the package bs4. Assign the URL of interest to the variable url. Package the request to the URL, send the request and catch the response with a single function requests.get(), assigning the response to the variable r. Use the text attribute of the object r to return the HTML of the webpage as a string; store the result in a variable html_doc. Create a BeautifulSoup object soupfrom the resulting HTML using the function BeautifulSoup(). Use the method prettify() on soup and assign the result to pretty_soup. Hit submit to print to prettified HTML to your shell!',\n",
       " nan,\n",
       " \"In the sample code, the HTML response object html_doc has already been created: your first task is to Soupify it using the function BeatifulSoup()and to assign the resulting soup to the variable soup. Extract the title from the HTML soup soup using the attribute title and assign the result to guido_title. Print the title of Guido's webpage to the shell using the print() function. Extract the text from the HTML soup soup using the method get_text() and assign to guido_text. Hit submit to print the text from Guido's webpage to the shell.\",\n",
       " nan,\n",
       " \"Use the method find_all() to find all hyperlinks in soup, remembering that hyperlinks are defined by the HTML tag ; store the result in the variable a_tags. The variable a_tags is a results set: your job now is to enumerate over it, using a for loop and to print the actual URLs of the hyperlinks; to do this, for every element link in a_tags, you want to print()link.get('href').\",\n",
       " nan,\n",
       " \"Load the JSON 'a_movie.json' into the variable json_data within the context provided by the withstatement. To do so, use the function json.load() within the context manager. Use a for loop to print all key-value pairs in the dictionary json_data. Recall that you can access a value in a dictionary using the syntax: dictionary[key].\",\n",
       " nan,\n",
       " \"Import the requests package. Assign to the variable url the URL of interest in order to query 'http://www.omdbapi.com' for the data corresponding to the movie The Social Network. The query string should have two arguments: apikey=ff21610b and t=social+network. You can combine them as follows: apikey=ff21610b&t=social+network. Print the text of the reponse object r by using its textattribute and passing the result to the print() function.\",\n",
       " nan,\n",
       " 'Pass the variable url to the requests.get() function in order to send the relevant request and catch the response, assigning the resultant response message to the variable r. Apply the json() method to the response object r and store the resulting dictionary in the variable json_data. Hit Submit Answer to print the key-value pairs of the dictionary json_data to the shell.',\n",
       " nan,\n",
       " \"Assign the relevant URL to the variable url. Apply the json() method to the response object r and store the resulting dictionary in the variable json_data. The variable pizza_extract holds the HTML of an extract from Wikipedia's Pizza page as a string\",\n",
       " nan,\n",
       " 'Import the package tweepy. Pass the parameters consumer_keyand consumer_secret to the function tweepy.OAuthHandler(). Complete the passing of OAuth credentials to the OAuth handler authby applying to it the method set_access_token(), along with arguments access_token and access_token_secret.',\n",
       " nan,\n",
       " \"Create your Stream object with authentication by passing tweepy.Stream() the authentication handler auth and the Stream listener l; To filter Twitter streams, pass to the track argument in stream.filter() a list containing the desired keywords 'clinton', 'trump', 'sanders', and 'cruz'.\",\n",
       " nan,\n",
       " \"Assign the filename 'tweets.txt' to the variable tweets_data_path. Initialize tweets_data as an empty list to store the tweets in. Within the for loop initiated by for line in tweets_file:, load each tweet into a variable, tweet, using json.loads(), then append tweet to tweets_data using the append() method. Hit submit and check out the keys of the first tweet dictionary printed to the shell\",\n",
       " nan,\n",
       " 'Use pd.DataFrame() to construct a DataFrame of tweet texts and languages; to do so, the first argument should be tweets_data, a list of dictionaries. The second argument to pd.DataFrame() is a list of the keys you wish to have as columns. Assign the result of the pd.DataFrame() call to df. Print the head of the DataFrame.',\n",
       " nan,\n",
       " 'def word_in_text(word, tweet): word = word.lower() text = tweet.lower() match = re.search(word, tweet)',\n",
       " \"You're going to iterate over the rows of the DataFrame and calculate how many tweets contain each of our keywords! The list of objects for each candidate has been initialized to 0.\",\n",
       " \"Within the for loop for index, row in df.iterrows():, the code currently increases the value of clinton by 1 each time a tweet mentioning 'Clinton' is encountered; complete the code so that the same happens for trump, sanders and cruz.\",\n",
       " nan,\n",
       " 'Import both matplotlib.pyplot and seaborn using the aliases plt and sns, respectively. Complete the arguments of sns.barplot: the first argument should be the labels to appear on the x-axis; the second argument should be the list of the variables you wish to plot, as produced in the previous exercise.',\n",
       " 'In this example, you\\'re going to make a scatter plot of female literacy vs fertility using data from the European Environmental Agency. This dataset highlights that countries with low female literacy have high birthrates. The x-axis data has been loaded for you as fertility and the y-axis data has been loaded as female_literacy. Your job is to create a figure, assign x-axis and y-axis labels, and plot female_literacy vs fertility using the circle glyph. After you have created the figure, in this exercise and the ones to follow, play around with it! Explore the different options available to you on the tab to the right, such as \"Pan\", \"Box Zoom\", and \"Wheel Zoom\". You can click on the question mark sign for more details on any of these tools. Note: You may have to scroll down to view the lower portion of the figure.',\n",
       " nan,\n",
       " 'By calling multiple glyph functions on the same figure object, we can overlay multiple data sets in the same figure. In this exercise, you will plot female literacy vs fertility for two different regions, Africa and Latin America. Each set of x and y data has been loaded separately for you as fertility_africa, female_literacy_africa, fertility_latinamerica, and female_literacy_latinamerica. Your job is to plot the Latin America data with the circle()glyph, and the Africa data with the x() glyph. figure has already been imported for you from bokeh.plotting.',\n",
       " nan,\n",
       " \"The three most important arguments to customize scatter glyphs are color, size, and alpha. Bokeh accepts colors as hexadecimal strings, tuples of RGB values between 0 and 255, and any of the 147 CSS color names. Size values are supplied in screen space units with 100 meaning the size of the entire figure. The alpha parameter controls transparency. It takes in floating point numbers between 0.0, meaning completely transparent, and 1.0, meaning completely opaque. In this exercise, you'll plot female literacy vs fertility for Africa and Latin America as red and blue circle glyphs, respectively.\",\n",
       " nan,\n",
       " \"We can draw lines on Bokeh plots with the line() glyph function. In this exercise, you'll plot the daily adjusted closing price of Apple Inc.'s stock (AAPL) from 2000 to 2013. The data points are provided for you as lists. date is a list ofdatetime objects to plot on the x-axis and price is a list of prices to plot on the y-axis. Since we are plotting dates on the x-axis, you must add x_axis_type='datetime' when creating the figure object.\",\n",
       " nan,\n",
       " \"Lines and markers can be combined by plotting them separately using the same data points. In this exercise, you'll plot a line and circle glyph for the AAPL stock prices. Further, you'll adjust the fill_color keyword argument of the circle() glyph function while leaving the line_color at the default value. The date and price lists are provided. The Bokeh figure object p that you created in the previous exercise has also been provided.\",\n",
       " nan,\n",
       " 'In Bokeh, extended geometrical shapes can be plotted by using the patches() glyph function. The patches glyph takes as input a list-of-lists collection of numeric values specifying the vertices in x and y directions of each distinct patch to plot. In this exercise, you will plot the state borders of Arizona, Colorado, New Mexico and Utah. The latitude and longitude vertices for each state have been prepared as lists. Your job is to plot longitude on the x-axis and latitude on the y-axis. The figure object has been created for you as p.',\n",
       " nan,\n",
       " \"In the previous exercises, you made plots using data stored in lists. You learned that Bokeh can plot both numbers and datetime objects. In this exercise, you'll generate NumPy arrays using np.linspace() and np.cos() and plot them using the circle glyph. np.linspace() is a function that returns an array of evenly spaced numbers over a specified interval. For example, np.linspace(0, 10, 5) returns an array of 5 evenly spaced samples calculated over the interval [0, 10]. np.cos(x)calculates the element-wise cosine of some array x. For more information on NumPy functions, you can refer to the NumPy User Guide and NumPy Reference. The figure p has been provided for you.\",\n",
       " nan,\n",
       " \"You can create Bokeh plots from Pandas DataFrames by passing column selections to the glyph functions. Bokeh can plot floating point numbers, integers, and datetime data types. In this example, you will read a CSV file containing information on 392 automobiles manufactured in the US, Europe and Asia from 1970 to 1982. The CSV file is provided for you as 'auto.csv'. Your job is to plot miles-per-gallon (mpg) vs horsepower (hp) by passing Pandas column selections into the p.circle()function. Additionally, each glyph will be colored according to values in the color column.\",\n",
       " nan,\n",
       " \"You can create a ColumnDataSource object directly from a Pandas DataFrame by passing the DataFrame to the class initializer. In this exercise, we have imported pandas as pd and read in a data set containing all Olympic medals awarded in the 100 meter sprint from 1896 to 2012. A color column has been added indicating the CSS colorname we wish to use in the plot for every data point. Your job is to import the ColumnDataSource class, create a new ColumnDataSource object from the DataFrame df, and plot circle glyphs with 'Year' on the x-axis and 'Time' on the y-axis. Color each glyph by the color column. The figure object p has already been created for you.\",\n",
       " nan,\n",
       " \"In this exercise, you're going to add the box_select tool to a figure and change the selected and non-selected circle glyph properties so that selected glyphs are red and non-selected glyphs are transparent blue. You'll use the ColumnDataSource object of the Olympic Sprint dataset you made in the last exercise. It is provided to you with the name source. After you have created the figure, be sure to experiment with the Box Select tool you added! As in previous exercises, you may have to scroll down to view the lower portion of the figure.\",\n",
       " nan,\n",
       " \"Now let's practice using and customizing the hover tool. In this exercise, you're going to plot the blood glucose levels for an unknown patient. The blood glucose levels were recorded every 5 minutes on October 7th starting at 3 minutes past midnight. The date and time of each measurement are provided to you as x and the blood glucose levels in mg/dL are provided as y. A bokeh figure is also provided in the workspace as p. Your job is to add a circle glyph that will appear red when the mouse is hovered near the data points. You will also add a customized hover tool object to the plot. When you're done, play around with the hover tool you just created! Notice how the points where your mouse hovers over turn red.\",\n",
       " nan,\n",
       " \"The final glyph customization we'll practice is using the CategoricalColorMapper to color each glyph by a categorical property. Here, you're going to use the automobile dataset to plot miles-per-gallon vs weight and color each circle glyph by the region where the automobile was manufactured. The origin column will be used in the ColorMapper to color automobiles manufactured in the US as blue, Europe as red and Asia as green. The automobile data set is provided to you as a Pandas DataFrame called df. The figure is provided for you as p.\",\n",
       " nan,\n",
       " 'Layouts are collections of Bokeh figure objects. In this exercise, you\\'re going to create two plots from the Literacy and Birth Rate data set to plot fertility vs female literacy and population vs female literacy. By using the row() method, you\\'ll create a single layout of the two figures. Remember, as in the previous chapter, once you have created your figures, you can interact with them in various ways. In this exercise, you may have to scroll sideways to view both figures in the row layout. Alternatively, you can view the figures in a new window by clicking on the expand icon to the right of the \"Bokeh plot\" tab.',\n",
       " nan,\n",
       " \"In this exercise, you're going to use the column() function to create a single column layout of the two plots you created in the previous exercise. Figure p1 has been created for you. In this exercise and the ones to follow, you may have to scroll down to view the lower portion of the figure.\",\n",
       " nan,\n",
       " \"You can create nested layouts of plots by combining row and column layouts. In this exercise, you'll make a 3-plot layout in two rows using the auto-mpg data set. Three plots have been created for you of average mpg vs year, mpg vs hp, and mpg vs weight. Your job is to use the column() and row() functions to make a two-row layout where the first row will have only the average mpg vs year plot and the second row will have mpg vs hp and mpg vs weight plots as columns. By using the sizing_mode argument, you can scale the widths to fill the whole figure.\",\n",
       " nan,\n",
       " \"Regular grids of Bokeh plots can be generated with gridplot. In this example, you're going to display four plots of fertility vs female literacy for four regions: Latin America, Africa, Asia and Europe. Your job is to create a list-of-lists for the four Bokeh plots that have been provided to you as p1, p2, p3 and p4. The list-of-lists defines the row and column placement of each plot.\",\n",
       " nan,\n",
       " \"Tabbed layouts can be created in Pandas by placing plots or layouts in Panels. In this exercise, you'll take the four fertility vs female literacy plots from the last exercise and make a Panel() for each. No figure will be generated in this exercise. Instead, you will use these panels in the next exercise to build and display a tabbed layout.\",\n",
       " nan,\n",
       " 'Tabbed layouts are collections of Panel objects. Using the figures and Panels from the previous two exercises, you\\'ll create a tabbed layout to change the region in the fertility vs female literacy plots. Your job is to create the layout using Tabs() and assign the tabskeyword argument to your list of Panels. The Panels have been created for you as tab1, tab2, tab3 and tab4. After you\\'ve displayed the figure, explore the tabs you just added! The \"Pan\", \"Box Zoom\" and \"Wheel Zoom\" tools are also all available as before.',\n",
       " nan,\n",
       " \"Linking axes between plots is achieved by sharing range objects. In this exercise, you'll link four plots of female literacy vs fertility so that when one plot is zoomed or dragged, one or more of the other plots will respond. The four plots p1, p2, p3 and p4 along with the layout that you created in the last section have been provided for you. Your job is link p1 with the three other plots by assignment of the .x_range and .y_range attributes. After you have linked the axes, explore the plots by clicking and dragging along the x or y axes of any of the plots, and notice how the linked plots change together.\",\n",
       " nan,\n",
       " \"By sharing the same ColumnDataSource object between multiple plots, selection tools like BoxSelect and LassoSelect will highlight points in both plots that share a row in the ColumnDataSource. In this exercise, you'll plot female literacy vs fertility and population vs fertility in two plots using the same ColumnDataSource. After you have built the figure, experiment with the Lasso Select and Box Select tools. Use your mouse to drag a box or lasso around points in one figure, and notice how points in the other figure that share a row in the ColumnDataSource also get highlighted. Before experimenting with the Lasso Select, however, click the Bokeh plot pop-out icon to pop out the figure so that you can definitely see everything that you're doing.\",\n",
       " nan,\n",
       " 'Legends can be added to any glyph by using the legend keyword argument. In this exercise, you will plot two circle glyphs for female literacy vs fertility in Africa and Latin America. Two ColumnDataSources called latin_america and africa have been provided. Your job is to plot two circle glyphs for these two objects with fertility on the x axis and female_literacy on the y axis and add the legend values. The figure p has been provided for you.',\n",
       " nan,\n",
       " \"Properties of the legend can be changed by using the legend member attribute of a Bokeh figure after the glyphs have been plotted. In this exercise, you'll adjust the background color and legend location of the female literacy vs fertility plot from the previous exercise. The figure object p has been created for you along with the circle glyphs.\",\n",
       " nan,\n",
       " 'Working with the HoverTool is easy for data stored in a ColumnDataSource. In this exercise, you will create a HoverTool object and display the country for each circle glyph in the figure that you created in the last exercise. This is done by assigning the tooltips keyword argument to a list-of-tuples specifying the label and the column of values from the ColumnDataSource using the @ operator. The figure object has been prepared for you as p. After you have added the hover tooltip to the figure, be sure to interact with it by hovering your mouse over each point to see which country it represents.',\n",
       " nan,\n",
       " 'Let\\'s get started with building an interactive Bokeh app. This typically begins with importing the curdoc, or \"current document\", function from bokeh.io. This current document will eventually hold all the plots, controls, and layouts that you create. Your job in this exercise is to use this function to add a single plot to your application. In the video, Bryan described the process for running a Bokeh app using the bokeh serve command line tool. In this chapter and the one that follows, the DataCamp environment does this for you behind the scenes. Notice that your code is part of a script.py file. When you hit \\'Submit Answer\\', you\\'ll see in the IPython Shell that we call bokeh serve script.py for you. Remember, as in the previous chapters, that there are different options available for you to interact with your plots, and as before, you may have to scroll down to view the lower portion of the plots.',\n",
       " nan,\n",
       " 'In the previous exercise, you added a single plot to the \"current document\" of your application. In this exercise, you\\'ll practice adding a layout to your current document. Your job here is to create a single slider, use it to create a widgetbox layout, and then add this layout to the current document. The slider you create here cannot be used for much, but in the later exercises, you\\'ll use it to update your plots!',\n",
       " nan,\n",
       " \"Having added a single slider in a widgetbox layout to your current document, you'll now add multiple sliders into the current document. Your job in this exercise is to create two sliders, add them to a widgetbox layout, and then add the layout into the current document.\",\n",
       " nan,\n",
       " \"Let's begin making a Bokeh application that has a simple slider and plot, that also updates the plot based on the slider. In this exercise, your job is to first explicitly create a ColumnDataSource. You'll then combine a plot and a slider into a single column layout, and add it to the current document. After you are done, notice how in the figure you generate, the slider will not actually update the plot, because a widget callback has not been defined. You'll learn how to update the plot using widget callbacks in the next exercise. All the necessary modules have been imported for you. The plot is available in the workspace as plot, and the slider is available as slider.\",\n",
       " nan,\n",
       " \"You'll now learn how to use widget callbacks to update the state of a Bokeh application, and in turn, the data that is presented to the user. Your job in this exercise is to use the slider's on_change() function to update the plot's data from the previous example. NumPy's sin() function will be used to update the y-axis data of the plot. Now that you have added a widget callback, notice how as you move the slider of your app, the figure also updates!\",\n",
       " nan,\n",
       " \"You'll now learn to update the plot's data using a drop down menu instead of a slider. This would allow users to do things like select between different data sources to view. The ColumnDataSource source has been created for you along with the plot. Your job in this exercise is to add a drop down menu to update the plot's data. All necessary modules have been imported for you.\",\n",
       " nan,\n",
       " \"Here, you'll practice using a dropdown callback to update another dropdown's options. This will allow you to customize your applications even further and is a powerful addition to your toolbox. Your job in this exercise is to create two dropdown select widgets and then define a callback such that one dropdown is used to update the other dropdown. All modules necessary have been imported.\",\n",
       " nan,\n",
       " \"It's time to practice adding buttons to your interactive visualizations. Your job in this exercise is to create a button and use its on_click() method to update a plot. All necessary modules have been imported for you. In addition, the ColumnDataSource with data x and y as well as the figure have been created for you and are available in the workspace as source and plot. When you're done, be sure to interact with the button you just added to your plot, and notice how it updates the data!\",\n",
       " nan,\n",
       " \"You can also get really creative with your Button widgets. In this exercise, you'll practice using CheckboxGroup, RadioGroup, and Toggle to add multiple Button widgets with different styles. curdoc and widgetbox have already been imported for you.\",\n",
       " nan,\n",
       " \"Here, you'll continue your Exploratory Data Analysis by making a simple plot of Life Expectancy vs Fertility for the year 1970. Your job is to import the relevant Bokeh modules and then prepare a ColumnDataSource object with the fertility, life and Country columns, where you only select the rows with the index value 1970. Remember, as with the figures you generated in previous chapters, you can interact with your figures here with a variety of tools.\",\n",
       " nan,\n",
       " \"Let's get started on the Gapminder app. Your job is to make the ColumnDataSourceobject, prepare the plot, and add circles for Life expectancy vs Fertility. You'll also set x and y ranges for the axes. As in the previous chapter, the DataCamp environment executes the bokeh servecommand to run the app for you. When you hit 'Submit Answer', you'll see in the IPython Shell that bokeh serve script.py gets called to run the app. This is something to keep in mind when you are creating your own interactive visualizations outside of the DataCamp environment.\",\n",
       " nan,\n",
       " 'Now that you have the base plot ready, you can enhance it by coloring each circle glyph by continent. Your job is to make a list of the unique regions from the data frame, prepare a ColorMapper, and add it to the circle glyph.',\n",
       " nan,\n",
       " \"Until now, we've been plotting data only for 1970. In this exercise, you'll add a slider to your plot to change the year being plotted. To do this, you'll create an update_plot() function and associate it with a slider to select values between 1970 and 2010. After you are done, you may have to scroll to the right to view the entire plot. As you play around with the slider, notice that the title of the plot is not updated along with the year. This is something you'll fix in the next exercise!\",\n",
       " nan,\n",
       " \"Remember how in the plot from the previous exercise, the title did not update along with the slider? In this exercise, you'll fix this. In Python, you can format strings by specifying placeholders with the % keyword. For example, if you have a string company = 'DataCamp', you can use print('%s' % company) to print DataCamp. Placeholders are useful when you are printing values that are not static, such as the value of the year slider. You can specify a placeholder for a number with %d. Here, when you're updating the plot title inside your callback function, you should make use of a placeholder so that the year displayed is in accordance with the value of the year slider. In addition to updating the plot title, you'll also create the callback function and slider as you did in the previous exercise, so you get a chance to practice these concepts further. All necessary modules have been imported for you, and as in the previous exercise, you may have to scroll to the right to view the entire figure.\",\n",
       " nan,\n",
       " \"#Adding a hover tool In this exercise, you'll practice adding a hover tool to drill down into data column values and display more detailed information about each scatter point. After you're done, experiment with the hover tool and see how it displays the name of the country when your mouse hovers over a point! The figure and slider have been created for you and are available in the workspace as plot and slider.\",\n",
       " nan,\n",
       " \"As a final step in enhancing your application, in this exercise you'll add dropdowns for interactively selecting different data features. In combination with the hover tool you added in the previous exercise, as well as the slider to change the year, you'll have a powerful app that allows you to interactively and quickly extract some great insights from the dataset! All necessary modules have been imported, and the previous code you wrote is taken care off. In the provided sample code, the dropdown for selecting features on the x-axis has been added for you. Using this as a reference, your job in this final exercise is to add a dropdown menu for selecting features on the y-axis. Take a moment, after you are done, to enjoy exploring the visualization by experimenting with the hover tools, sliders, and dropdown menus that you have learned how to implement in this course.\",\n",
       " nan,\n",
       " nan,\n",
       " 'In the video, you already saw how much the world population has grown over the past years. Will it continue to do so? The world bank has estimates of the world population for the years 1950 up to 2100. The years are loaded in your workspace as a list called year, and the corresponding populations as a list called pop.',\n",
       " \"print() the last item from both the year and the pop list to see what the predicted population for the year 2100 is. Before you can start, you should import matplotlib.pyplot as plt. pyplot is a sub-package of matplotlib, hence the dot. Use plt.plot() to build a line plot. year should be mapped on the horizontal axis, pop on the vertical axis. Don't forget to finish off with the show() function to actually display the plot.\",\n",
       " nan,\n",
       " \"Print the last item from both the list gdp_cap, and the list life_exp; it is information about Zimbabwe. Build a line chart, with gdp_cap on the x-axis, and life_exp on the y-axis. Does it make sense to plot this data on a line plot? Don't forget to finish off with a plt.show() command, to actually display the plot.\",\n",
       " nan,\n",
       " \"Let's continue with the gdp_cap versus life_exp plot, the GDP and life expectancy data for different countries in 2007. Maybe a scatter plot will be a better alternative? Again, the matploblib.pyplot package is available as plt.\",\n",
       " \"Change the line plot that's coded in the script to a scatter plot. A correlation will become clear when you display the GDP per capita on a logarithmic scale. Add the line plt.xscale('log'). Finish off your script with plt.show() to display the plot.\",\n",
       " nan,\n",
       " 'Start from scratch: import matplotlib.pyplot as plt. Build a scatter plot, where pop is mapped on the horizontal axis, and life_exp is mapped on the vertical axis. Finish the script with plt.show() to actually display the plot. Do you see a correlation?',\n",
       " nan,\n",
       " 'Use plt.hist() to create a histogram of the values in life_exp. Do not specify the number of bins',\n",
       " nan,\n",
       " \"Build a histogram of life_exp, with 5 bins. Can you tell which bin contains the most observations? Build another histogram of life_exp, this time with 20 bins. Is this better? ##Build a histogram (3): compare 100xp In the video, you saw population pyramids for the present day and for the future. Because we were using a histogram, it was very easy to make a comparison. Let's do a similar comparison. life_exp contains life expectancy data for different countries in 2007. You also have access to a second list now, life_exp1950, containing similar data for 1950. Can you make a histogram for both datasets? You'll again be making two plots. The plt.show() and plt.clf() commands to render everything nicely are already included. Also matplotlib.pyplot is imported for you, as plt.\",\n",
       " 'Build a histogram of life_exp with 15 bins. Build a histogram of life_exp1950, also with 15 bins. Is there a big difference with the histogram for the 2007 data?',\n",
       " nan,\n",
       " 'The strings xlab and ylab are already set for you. Use these variables to set the label of the x- and y-axis. The string title is also coded for you. Use it to add a title to the plot. After these customizations, finish the script with plt.show()to actually display the plot.',\n",
       " nan,\n",
       " \"In this example, the ticks corresponding to the numbers 0, 1 and 2 will be replaced by one, two and three, respectively. Let's do a similar thing for the x-axis of your world development chart, with the xticks() function. The tick values 1000, 10000 and 100000should be replaced by 1k, 10k and 100k. To this end, two lists have already been created for you: tick_val and tick_lab.\",\n",
       " \"Use tick_val and tick_lab as inputs to the xticks()function to make the the plot more readable. As usual, display the plot with plt.show() after you've added the customizations.\",\n",
       " nan,\n",
       " 'Run the script to see how the plot changes. Looks good, but increasing the size of the bubbles will make things stand out more. Import the numpy package as np. Use np.array() to create a numpy array from the list pop. Call this Numpy array np_pop. Double the values in np_pop by assigning np_pop * 2 to np_pop again. Because np_pop is a Numpy array, each array element will be doubled. Change the s argument inside plt.scatter() to be np_pop instead of pop.',\n",
       " nan,\n",
       " 'Nothing to worry about now',\n",
       " 'Add c = col to the arguments of the plt.scatter()function. Change the opacity of the bubbles by setting the alphaargument to 0.8 inside plt.scatter(). Alpha can be set from zero to one, where zero is totally transparent, and one is not at all transparent.',\n",
       " nan,\n",
       " 'Add plt.grid(True) after the plt.text() calls so that gridlines are drawn on the plot.',\n",
       " nan,\n",
       " \"Use the index() method on countries to find the index of 'germany'. Store this index as ind_ger. Use ind_ger to access the capital of Germany from the capitals list. Print it out.\",\n",
       " nan,\n",
       " 'In this recipe, both the keys and the values are strings. This will also be the case for this exercise.',\n",
       " nan,\n",
       " \"Here, 'france' is the key and 'paris' the value is returned.\",\n",
       " \"Check out which keys are in europe by calling the keys()method on europe. Print out the result. Print out the value that belongs to the key 'norway'.\",\n",
       " nan,\n",
       " \"Add the key 'italy' with the value 'rome' to europe. To assert that 'italy' is now a key in europe, print out 'italy' in europe. Add another key:value pair to europe: 'poland' is the key, 'warsaw' is the corresponding value. Print out europe.\",\n",
       " nan,\n",
       " \"The capital of Germany is not 'bonn'; it's 'berlin'. Update its value. Australia is not in Europe, Austria is! Remove they key 'australia' from europe. Print out europe to see if your cleaning work paid off.\",\n",
       " nan,\n",
       " \"Use chained square brackets to select and print out the capital of France. Create a dictionary, named data, with the keys 'capital'and 'population'. Set them to 'rome' and 59.83, respectively. Add a new key-value pair to europe; the key is 'italy'and the value is data, the dictionary you just built.\",\n",
       " nan,\n",
       " \"Import pandas as pd. Use the pre-defined lists to create a dictionary called my_dict. There should be three key value pairs: key 'country' and value names. key 'drives_right' and value dr. key 'cars_per_cap' and value cpc. Use pd.DataFrame() to turn your dict into a DataFrame called cars. Print out cars and see how beautiful it is.\",\n",
       " nan,\n",
       " 'Hit Submit Answer to see that, indeed, the row labels are not correctly set. Specify the row labels by setting cars.index equal to row_labels. Print out cars again and check if the row labels are correct this time.',\n",
       " nan,\n",
       " nan,\n",
       " 'Run the code with Submit Answer and assert that the first column should actually be used as row labels. Specify the index_col argument inside pd.read_csv(): set it to 0, so that the first column is used as row labels. Has the printout of cars improved now?',\n",
       " nan,\n",
       " 'The single bracket version gives a Pandas Series, the double bracket version gives a Pandas DataFrame.',\n",
       " 'Use single square brackets to print out the country column of cars as a Pandas Series. Use double square brackets to print out the country column of cars as a Pandas DataFrame. Use double square brackets to print out a DataFrame with both the country and drives_right columns of cars, in this order.',\n",
       " nan,\n",
       " \"The result is another DataFrame containing only the rows you specified. Pay attention: You can only select rows using square brackets if you specify a slice, like 0:4. Also, you're using the integer indexes of the rows here, not the row labels!\",\n",
       " 'Select the first 3 observations from cars and print them out. Select the fourth, fifth and sixth observation, corresponding to row indexes 3, 4 and 5, and print them out.',\n",
       " nan,\n",
       " \"cars.loc[['RU']] cars.iloc[[4]]\",\n",
       " \"cars.loc[['RU', 'AUS']] cars.iloc[[4, 1]]\",\n",
       " 'As before, code is included that imports the cars data as a Pandas DataFrame.',\n",
       " 'Use loc or iloc to select the observation corresponding to Japan as a Series. The label of this row is JAP, the index is 2. Make sure to print the resulting Series. Use loc or iloc to select the observations for Australia and Egypt as a DataFrame. You can find out about the labels/indexes of these rows by inspecting cars in the IPython Shell. Make sure to print the resulting DataFrame.',\n",
       " nan,\n",
       " \"cars.loc[['IN', 'RU'], 'cars_per_cap'] cars.iloc[[3, 4], 0]\",\n",
       " \"cars.loc[['IN', 'RU'], ['cars_per_cap', 'country']] cars.iloc[[3, 4], [0, 1]]\",\n",
       " 'Print out the drives_right value of the row corresponding to Morocco (its row label is MOR) Print out a sub-DataFrame, containing the observations for Russia and Morocco and the columns country and drives_right.',\n",
       " nan,\n",
       " \"cars.loc[:, ['country','drives_right']] cars.iloc[:, [1, 2]]\",\n",
       " 'Print out the drives_right column as a Series using locor iloc. Print out the drives_right column as a DataFrame using loc or iloc. Print out both the cars_per_cap and drives_rightcolumn as a DataFrame using loc or iloc.',\n",
       " nan,\n",
       " 'When you write these comparisons in a script, you will need to wrap a print() function around them to see the output.',\n",
       " 'In the editor on the right, write code to see if True equals False. Write Python code to check if -5 * 15 is not equal to 75. Ask Python whether the strings \"pyscript\" and \"PyScript\" are equal. What happens if you compare booleans and integers? Write code to see if True and 1 are equal.',\n",
       " nan,\n",
       " 'Remember that for string comparison, Python determines the relationship based on alphabetical order.',\n",
       " 'Write Python expressions, wrapped in a print() function, to check whether: x is greater than or equal to -10. x has already been defined for you. \"test\" is less than or equal to y. y has already been defined for you. True is greater than False.',\n",
       " nan,\n",
       " 'Using comparison operators, generate boolean arrays that answer the following questions: Which areas in my_house are greater than or equal to 18? You can also compare two Numpy arrays element-wise. Which areas in my_house are smaller than the ones in your_house? Make sure to wrap both commands in a print() statement, so that you can inspect the output.',\n",
       " nan,\n",
       " 'Write Python expressions, wrapped in a print() function, to check whether: my_kitchen is bigger than 10 and smaller than 18. my_kitchen is smaller than 14 or bigger than 17. double the area of my_kitchen is smaller than triple the area of your_kitchen.',\n",
       " \"Before, the operational operators like < and >= worked with Numpy arrays out of the box. Unfortunately, this is not true for the boolean operators and, or, and not. To use these operators with Numpy, you will need np.logical_and(), np.logical_or() and np.logical_not(). Here's an example on the my_house and your_house arrays from before to give you an idea: logical_and(your_house > 13, your_house < 15)\",\n",
       " 'Generate boolean arrays that answer the following questions: Which areas in my_house are greater than 18.5 or smaller than 10? Which areas are smaller than 11 in both my_houseand your_house? Make sure to wrap both commands in print() statement, so that you can inspect the output.',\n",
       " nan,\n",
       " 'Examine the if statement that prints out \"Looking around in the kitchen.\" if room equals \"kit\". Write another if statement that prints out \"big place!\" if areais greater than 15.',\n",
       " nan,\n",
       " 'Add an else statement to the second control structure so that \"pretty small.\" is printed out if area > 15 evaluates to False.',\n",
       " nan,\n",
       " 'Add an elif to the second control structure such that \"medium size, nice!\" is printed out if area is greater than 10.',\n",
       " nan,\n",
       " 'Extract the drives_right column as a Pandas Series and store it as dr. Use dr, a boolean Series, to subset the cars DataFrame. Store the resulting selection in sel. Print sel, and assert that drives_right is True for all observations.',\n",
       " nan,\n",
       " 'Convert the code on the right to a one-liner that calculates the variable sel as before.',\n",
       " nan,\n",
       " \"Select the cars_per_cap column from cars as a Pandas Series and store it as cpc. Use cpc in combination with a comparison operator and 500. You want to end up with a boolean Series that's True if the corresponding country has a cars_per_cap of more than 500 and False otherwise. Store this boolean Series as many_cars. Use many_cars to subset cars, similar to what you did before. Store the result as car_maniac. Print out car_maniac to see if you got it right.\",\n",
       " nan,\n",
       " 'Use the code sample above to create a DataFrame medium, that includes all the observations of cars that have a cars_per_cap between 100 and 500. Print out medium.',\n",
       " nan,\n",
       " \"This example will come in handy, because it's time to build a while loop yourself! We're going to code a while loop that implements a very basic control system for a inverted pendulum. If there's an offset from standing perfectly straight, the while loop will incrementally fix this offset.\",\n",
       " nan,\n",
       " nan,\n",
       " 'As usual, you simply have to indent the code with 4 spaces to tell Python which code should be executed in the for loop. The areas variable, containing the area of different rooms in your house, is already defined.',\n",
       " 'Write a for loop that iterates over all elements of the areas list and prints out every element separately.',\n",
       " nan,\n",
       " 'Adapt the for loop in the sample code to use enumerate(). On each run, a line of the form \"room x: y\" should be printed, where x is the index of the list element and y is the actual list element, i.e. the area. Make sure to print out this exact string, with the correct spacing.',\n",
       " nan,\n",
       " 'Adapt the print() function in the for loop on the right so that the first printout becomes \"room 1: 11.25\", the second one \"room 2: 18.0\" and so on.',\n",
       " nan,\n",
       " 'Write a for loop that goes through each sublist of house and prints out the x is y sqm, where x is the name of the room and y is the area of the room.',\n",
       " nan,\n",
       " 'for key, value in world.items() : print(key + \" -- \" + str(value))',\n",
       " 'Remember the europe dictionary that contained the names of some European countries as key and their capitals as corresponding value? Go ahead and write a loop to iterate over it!',\n",
       " 'Write a for loop that goes through each key:value pair of europe. On each iteration, \"the capital of x is y\" should be printed out, where x is the key and y is the value of the pair.',\n",
       " nan,\n",
       " \"If you're dealing with a 2D Numpy array, it's more complicated. A 2D array is built up of multiple 1D arrays. To explicitly iterate over all separate elements of a multi-dimensional array, you'll need this syntax: for x in np.nditer(my_array) : ...\",\n",
       " 'Two Numpy arrays that you might recognize from the intro course are available in your Python session: np_height, a Numpy array containing the heights of Major League Baseball players, and np_baseball, a 2D Numpy array that contains both the heights (first column) and weights (second column) of those players.',\n",
       " 'Import the numpy package under the local alias np. Write a for loop that iterates over all elements in np_height and prints out \"x inches\" for each element, where x is the value in the array. Write a for loop that visits every element of the np_baseball array and prints it out.',\n",
       " nan,\n",
       " 'In this and the following exercises you will be working on the carsDataFrame. It contains information on the cars per capita and whether people drive right or left for seven countries in the world.',\n",
       " 'Write a for loop that iterates over the rows of cars and on each iteration perform two print() calls: one to print out the row label and one to print out all of the rows contents.',\n",
       " nan,\n",
       " 'Adapt the code in the for loop such that the first iteration prints out \"US: 809\", the second iteration \"AUS: 731\", and so on. The output should be in the form \"country: cars_per_cap\". Make sure to print out this exact string, with the correct spacing.',\n",
       " nan,\n",
       " 'You can do similar things on the cars DataFrame.',\n",
       " 'Use a for loop to add a new column, named COUNTRY, that contains a uppercase version of the country names in the \"country\" column. You can use the string method upper() for this. To see if your code worked, print out cars. Don\\'t indent this code, so that it\\'s not part of the for loop.',\n",
       " nan,\n",
       " 'brics[\"name_length\"] = brics[\"country\"].apply(len)',\n",
       " \"We can do a similar thing to call the upper() method on every name in the country column. However, upper() is a method, so we'll need a slightly different approach:\",\n",
       " 'Replace the for loop with a one-liner that uses .apply(str.upper). The call should give the same result: a column COUNTRY should be added to cars, containing an uppercase version of the country names. As usual, print out cars to see the fruits of your hard labor',\n",
       " nan,\n",
       " \"This example will come in handy, because it's time to build a while loop yourself! We're going to code a while loop that implements a very basic control system for a inverted pendulum. If there's an offset from standing perfectly straight, the while loop will incrementally fix this offset.\",\n",
       " 'Create the variable offset with an initial value of 8. Code a while loop that keeps running as long as offset is not equal to 0. Inside the while loop: Print out the sentence \"correcting...\". Next, decrease the value of offset by 1. You can do this with offset = offset - 1. Finally, print out offset so you can see how it changes',\n",
       " nan,\n",
       " \"Inside the while loop, replace offset = offset - 1 by an if-else statement: If offset > 0, you should decrease offset by 1. Else, you should increase offset by 1. If you've coded things correctly, hitting Submit Answer should work this time.\",\n",
       " nan,\n",
       " 'As usual, you simply have to indent the code with 4 spaces to tell Python which code should be executed in the for loop. The areas variable, containing the area of different rooms in your house, is already defined.',\n",
       " 'Write a for loop that iterates over all elements of the areas list and prints out every element separately.',\n",
       " nan,\n",
       " 'Adapt the for loop in the sample code to use enumerate(). On each run, a line of the form \"room x: y\" should be printed, where x is the index of the list element and y is the actual list element, i.e. the area. Make sure to print out this exact string, with the correct spacing.',\n",
       " nan,\n",
       " 'Adapt the print() function in the for loop on the right so that the first printout becomes \"room 1: 11.25\", the second one \"room 2: 18.0\" and so on.',\n",
       " nan,\n",
       " 'Write a for loop that goes through each sublist of house and prints out the x is y sqm, where x is the name of the room and y is the area of the room.',\n",
       " nan,\n",
       " 'for key, value in world.items() : print(key + \" -- \" + str(value))',\n",
       " 'Remember the europe dictionary that contained the names of some European countries as key and their capitals as corresponding value? Go ahead and write a loop to iterate over it!',\n",
       " 'Write a for loop that goes through each key:value pair of europe. On each iteration, \"the capital of x is y\" should be printed out, where x is the key and y is the value of the pair.',\n",
       " nan,\n",
       " \"If you're dealing with a 2D Numpy array, it's more complicated. A 2D array is built up of multiple 1D arrays. To explicitly iterate over all separate elements of a multi-dimensional array, you'll need this syntax: for x in np.nditer(my_array) : ...\",\n",
       " 'Two Numpy arrays that you might recognize from the intro course are available in your Python session: np_height, a Numpy array containing the heights of Major League Baseball players, and np_baseball, a 2D Numpy array that contains both the heights (first column) and weights (second column) of those players.',\n",
       " 'Import the numpy package under the local alias np. Write a for loop that iterates over all elements in np_height and prints out \"x inches\" for each element, where x is the value in the array. Write a for loop that visits every element of the np_baseball array and prints it out.',\n",
       " nan,\n",
       " 'In this and the following exercises you will be working on the carsDataFrame. It contains information on the cars per capita and whether people drive right or left for seven countries in the world.',\n",
       " 'Write a for loop that iterates over the rows of cars and on each iteration perform two print() calls: one to print out the row label and one to print out all of the rows contents.',\n",
       " nan,\n",
       " 'Adapt the code in the for loop such that the first iteration prints out \"US: 809\", the second iteration \"AUS: 731\", and so on. The output should be in the form \"country: cars_per_cap\". Make sure to print out this exact string, with the correct spacing.',\n",
       " nan,\n",
       " 'You can do similar things on the cars DataFrame.',\n",
       " 'Use a for loop to add a new column, named COUNTRY, that contains a uppercase version of the country names in the \"country\" column. You can use the string method upper() for this. To see if your code worked, print out cars. Don\\'t indent this code, so that it\\'s not part of the for loop.',\n",
       " nan,\n",
       " 'brics[\"name_length\"] = brics[\"country\"].apply(len)',\n",
       " \"We can do a similar thing to call the upper() method on every name in the country column. However, upper() is a method, so we'll need a slightly different approach:\",\n",
       " 'Replace the for loop with a one-liner that uses .apply(str.upper). The call should give the same result: a column COUNTRY should be added to cars, containing an uppercase version of the country names. As usual, print out cars to see the fruits of your hard labor',\n",
       " nan,\n",
       " 'Import numpy as np. Use seed() to set the seed; as an argument, pass 123. Generate your first random float with rand() and print it out.',\n",
       " nan,\n",
       " 'Numpy has already been imported as np and a seed has been set. Can you roll some dice?',\n",
       " 'Use randint() with the appropriate arguments to randomly generate the integer 1, 2, 3, 4, 5 or 6. This simulates a dice. Print it out. Repeat the outcome to see if the second throw is different. Again, print out the result.',\n",
       " nan,\n",
       " 'Roll the dice. Use randint() to create the variable dice. Finish the if-elif-else construct by replacing ___: If dice is 1 or 2, you go one step down. if dice is 3, 4 or 5, you go one step up. Else, you throw the dice again. The number of eyes is the number of steps you go up. Print out dice and step. Given the value of dice, was step updated correctly?',\n",
       " nan,\n",
       " 'Make a list random_walk that contains the first step, which is the integer 0. Finish the for loop: The loop should run 100 times. On each iteration, set step equal to the last element in the random_walk list. You can use the index -1 for this. Next, let the if-elif-else construct update step for you. The code that appends step to random_walk is already coded. Print out random_walk.',\n",
       " nan,\n",
       " \"Use max() in a similar way to make sure that step doesn't go below zero if dice <= 2. Hit Submit Answer and check the contents of random_walk.\",\n",
       " nan,\n",
       " 'The first list you pass is mapped onto the x axis and the second list is mapped onto the y axis. If you pass only one argument, Python will know what to do and will use the index of the list to map onto the x axis, and the values in the list onto the y axis.',\n",
       " 'Add some lines of code after the for loop: Import matplotlib.pyplot as plt. Use plt.plot() to plot random_walk. Finish off with plt.show() to actually display the plot.',\n",
       " nan,\n",
       " 'Initialize all_walks to an empty list. Fill in the specification of the for loop so that the random walk is simulated 10 times. At the end of the top-level for loop, append random_walkto the all_walks list. Finally, after the top-level for loop, print out all_walks.',\n",
       " nan,\n",
       " 'Use np.array() to convert all_walks to a Numpy array, np_aw. Try to use plt.plot() on np_aw. Also include plt.show(). Does it work out of the box? Transpose np_aw by calling np.transpose() on np_aw. Call the result np_aw_t. Now every row in np_all_walksrepresents the position after 1 throw for the 10 random walks. Use plt.plot() to plot np_aw_t; also include a plt.show(). Does it look better this time?',\n",
       " \"Things are shaping up nicely! You already have code that calculates your location in the Empire State Building after 100 dice throws. However, there's something we haven't thought about - you can't go below 0! A typical way to solve problems like this is by using max(). If you pass max() two arguments, the biggest one gets returned. For example, to make sure that a variable x never goes below 10 when you decrease it, you can use: x = max(10, x - 1)\",\n",
       " \"Use max() in a similar way to make sure that step doesn't go below zero if dice <= 2. Hit Submit Answer and check the contents of random_walk.\",\n",
       " nan,\n",
       " 'Change the range() function so that the simulation is performed 250 times. Finish the if condition so that step is set to 0 if a random float is less or equal to 0.001. Use np.random.rand().',\n",
       " nan,\n",
       " \"To make sure we've got enough simulations, go crazy. Simulate the random walk 500 times. From np_aw_t, select the last row. This contains the endpoint of all 500 random walks you've simulated. Store this Numpy array as ends. Use plt.hist() to build a histogram of ends. Don't forget plt.show() to display the plot.\",\n",
       " 'Remember how you calculated the money you ended up with after 7 years of investing $100? You did something like this: 100 * 1.10 ** 7',\n",
       " \"Instead of calculating with the actual values, you can use variables instead. The savings variable you've created in the previous exercise represents the $100 you started with. It's up to you to create a new variable to represent 1.10 and then redo the calculations!\",\n",
       " 'In the previous exercise, you worked with two Python data types:',\n",
       " 'int, or integer: a number without a fractional part. savings, with the value 100, is an example of an integer. float, or floating point: a number that has both an integer and fractional part, separated by a point. factor, with the value 1.10, is an example of a float.',\n",
       " 'Next to numerical data types, there are two other very common data types: str, or string: a type to represent text. You can use single or double quotes to build a string. bool, or boolean: a type to represent logical values. Can only be True or False.',\n",
       " 'Create a new string, desc, with the value \"compound interest\". Create a new boolean, profitable, with the value True.',\n",
       " \"To find out the type of a value or a variable that refers to that value, you can use the type()function. Suppose you've defined a variable a, but you forgot the type of this variable. To determine the type of a, simply execute: type(a)\",\n",
       " 'We already went ahead and created three variables: a, b and c. You can use the IPython shell on the right to discover their type. Which of the following options is correct? Answer: 3',\n",
       " 'Filip mentioned that different types behave differently in Python.',\n",
       " \"When you sum two strings, for example, you'll get different behavior than when you sum two integers or two booleans. In the script some variables with different types have already been created. It's up to you to use them.\",\n",
       " 'Using the + operator to paste together two strings can be very useful in building custom messages. Suppose for example that you\\'ve calculated the return of your investment, and want to summarize the results in a string. Assuming the floats savings and result are defined, you can try something like this: print(\"I started with\\n\"\\n+\\ns\\na\\nv\\ni\\nn\\ng\\ns\\n+\\n\"\\na\\nn\\nd\\nn\\no\\nw\\nh\\na\\nv\\ne\\n\" + result + \". Awesome!\")',\n",
       " 'This will not work, though, as you cannot simply sum strings and floats.',\n",
       " \"To fix the error, you'll need to explicitly convert the types of your variables. More specifically, you'll need str(), to convert a value into a string. str(savings), for example, will convert the float savings to a string. Similar functions such as int(), float() and bool() will help you convert Python values into any type.\",\n",
       " 'Now that you know something more about combining different sources of information, have a look at the 4 Python expressions below. Which one of these will throw an error? You can always copy and paste this code in the IPython Shell to find out! Answer Three',\n",
       " 'As opposed to int, bool etc, a list is a compound data type: you can group values together: a = \"is\" b = \"nice\" my_list = [\"my\", \"list\", a, b]',\n",
       " \"After measuring the height of your family, you decide to collect some information on the house you're living in. The areas of the different parts of your house are stored in separate variables for now, as shown in the script.\",\n",
       " '-Create a list, areas, that contains the area of the hallway (hall), kitchen (kit), living room (liv), bedroom (bed) and bathroom (bath), in this order. Use the predefined variables. -Print areas with the print() function.',\n",
       " 'A list can contain any Python type. Although it\\'s not really common, a list can also contain a mix of Python types including strings, floats, booleans, etc. The printout of the previous exercise wasn\\'t really satisfying. It\\'s just a list of numbers representing the areas, but you can\\'t tell which area corresponds to which part of your house. The code on the right is the start of a solution. For some of the areas, the name of the corresponding room is already placed in front. Pay attention here! \"bathroom\" is a string, while bath is a variable that represents the float 9.50 you specified earlier.',\n",
       " 'A list can contain any Python type. But a list itself is also a Python type. That means that a list can also contain a list! Python is getting funkier by the minute, but fear not, just remember the list syntax: my_list = [el1, el2, el3]',\n",
       " 'Can you tell which ones of the following lines of Python code are valid ways to build a list? A. [1, 3, 4, 2] B. [[1, 2, 3], [4, 5, 7]] C. [1 + 2, \"a\" * 5, 3] Answer 1',\n",
       " 'As a data scientist, you\\'ll often be dealing with a lot of data, and it will make sense to group some of this data. Instead of creating a flat list containing strings and floats, representing the names and areas of the rooms in your house, you can create a list of lists. The script on the right can already give you an idea. Don\\'t get confused here: \"hallway\" is a string, while hall is a variable that represents the float 11.25 you specified earlier.',\n",
       " 'Finish the list of lists so that it also contains the bedroom and bathroom data. Make sure you enter these in order! Print out house',\n",
       " nan,\n",
       " 'Remember the areas list from before, containing both strings and floats? Its definition is already in the script. Can you add the correct code to do some Python subsetting?',\n",
       " 'After you\\'ve extracted values from a list, you can use them to perform additional calculations. Take this example, where the second and fourth element of a list x are extracted. The strings that result are pasted together using the +operator: x = [\"a\", \"b\", \"c\", \"d\"] print(x[1] + x[3])',\n",
       " \"Selecting single values from a list is just one part of the story. It's also possible to slice your list, which means selecting multiple elements from your list. Use the following syntax: my_list[start:end]\",\n",
       " 'The start index will be included, while the end index is not. The code sample below shows an example. A list with \"b\" and \"c\", corresponding to indexes 1 and 2, are selected from a list x: x = [\"a\", \"b\", \"c\", \"d\"] x[1:3]',\n",
       " 'The elements with index 1 and 2 are included, while the element with index 3 is not.',\n",
       " 'In the video, Filip only discussed the syntax where you specify both where to begin and end the slice of your list: my_list[begin:end]',\n",
       " 'However, it\\'s also possible not to specify these indexes. If you don\\'t specify the begin index, Python figures out that you want to start your slice at the beginning of your list. If you don\\'t specify the end index, the slice will go all the way to the last element of your list. To experiment with this, try the following commands in the IPython Shell: x = [\"a\", \"b\", \"c\", \"d\"] x[:2] x[2:] x[:]',\n",
       " \"Use slicing to create the lists downstairs and upstairsagain, but this time without using indexes if it's not necessary. Remember downstairs is the first 6 elements of areasand upstairs is the last 4 elements of areas.\",\n",
       " nan,\n",
       " 'x[2] results in a list, that you can subset again by adding additional square brackets. What will house[-1][1] return? house, the list of lists that you created before, is already defined for you in the workspace. You can experiment with it in the IPython Shell.',\n",
       " 'aSNWE THERRRE',\n",
       " nan,\n",
       " \"For this and the following exercises, you'll continue working on the areaslist that contains the names and areas of different rooms in a house.\",\n",
       " '#NAME?',\n",
       " nan,\n",
       " 'You just won the lottery, awesome! You decide to build a poolhouse and a garage. Can you add the information to the areas list?',\n",
       " 'Finally, you can also remove elements from your list. You can do this with the del statement: x = [\"a\", \"b\", \"c\", \"d\"] del(x[1])',\n",
       " 'Pay attention here: as soon as you remove an element from a list, the indexes of the elements that come after the deleted element all change! The updated and extended version of areas that you\\'ve built in the previous exercises is coded below. You can copy and paste this into the IPython Shell to play around with the result. areas = [\"hallway\", 11.25, \"kitchen\", 18.0, \"chill zone\", 20.0, \"bedroom\", 10.75, \"bathroom\", 10.50, \"poolhouse\", 24.5, \"garage\", 15.45]',\n",
       " \"There was a mistake! The amount you won with the lottery is not that big after all and it looks like the poolhouse isn't going to happen. You decide to remove the corresponding string and float from the areas list. The \",\n",
       " 'Separate lines command1 command2',\n",
       " 'Which of the code chunks will do the job for us? Answer Three',\n",
       " \"At the end of the video, Filip explained how Python lists work behind the scenes. In this exercise you'll get some hands-on experience with this. The Python code in the script already creates a list with the name areasand a copy named areas_copy. Next, the first element in the areas_copy list is changed and the areas list is printed out. If you hit Submit Answer you'll see that, although you've changed areas_copy, the change also takes effect in the areas list. That's because areas and areas_copy point to the same list. If you want to prevent changes in areas_copy to also take effect in areas, you'll have to do a more explicit copy of the areas list. You can do this with list() or by using [:].\",\n",
       " nan,\n",
       " 'The general recipe for calling functions is thus: output = function_name(input)',\n",
       " nan,\n",
       " 'Use the Shell on the right to open up the documentation on complex(). Which of the following statements is true?',\n",
       " 'Answer three',\n",
       " nan,\n",
       " 'Two lists have been created for you on the right. Can you paste them together and sort them in descending order?',\n",
       " nan,\n",
       " nan,\n",
       " 'Use the index() method to get the index of the element in areas that is equal to 20.0. Print out this index. Call count() on areas to find out how many times 14.5 appears in the list. Again, simply print out this number.',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " \"Let's say the Moon's orbit around planet Earth is a perfect circle, with a radius r (in km) that is defined in the script.\",\n",
       " nan,\n",
       " 'Which import statement will you need in order to run the above code without an error? Answer Four',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'For Numpy specifically, you can also use boolean Numpy arrays: high = y > 5 y[high]',\n",
       " 'The code that calculates the BMI of all baseball players is already included. Follow the instructions and reveal interesting things from the data!',\n",
       " nan,\n",
       " 'np_x = np.array(x) np_x[1]',\n",
       " 'The script on the right already contains code that imports numpy as np, and stores both the height and weight of the MLB players as Numpy arrays.',\n",
       " nan,\n",
       " nan,\n",
       " nan,\n",
       " 'x = [[\"a\", \"b\"], [\"c\", \"d\"]] [x[0][0], x[1][0]]',\n",
       " 'import numpy as np np_x = np.array(x) np_x[:,0]',\n",
       " \"For regular Python lists, this is a real pain. For 2D Numpy arrays, however, it's pretty intuitive! The indexes before the comma refer to the rows, while those after the comma refer to the columns. The : is for slicing; in this example, it tells Python to include all rows. The code that converts the pre-loaded baseball list to a 2D Numpy array is already in the script. Add some lines to make the correct selections. Remember that in Python, the first element is at index 0!\",\n",
       " nan,\n",
       " \"np_baseball is coded for you; it's again a 2D Numpy array with 3 columns representing height, weight and age.\",\n",
       " nan,\n",
       " \"The baseball data is available as a 2D Numpy array with 3 columns (height, weight, age) and 1015 rows. The name of this Numpy array is np_baseball. After restructuring the data, however, you notice that some height values are abnormally high. Follow the instructions and discover which summary statistic is best suited if you're dealing with so-called outliers.\",\n",
       " nan,\n",
       " nan,\n",
       " \"Alright, it's time to create your first engine! An engine is just a common interface to a database, and the information it requires to connect to one is contained in a connection string, such as sqlite:///census_nyc.sqlite. Here, sqlite is the database driver, while census_nyc.sqlite is a SQLite file contained in the local directory. You can learn a lot more about connection strings in theSQLAlchemy documentation. Your job in this exercise is to create an engine that connects to a local SQLite file named census.sqlite. Then, print the names of the tables it contains using the .table_names() method. Note that when you just want to print the table names, you do not need to use engine.connect() after creating the engine.\",\n",
       " nan,\n",
       " \"SQLAlchemy can be used to automatically load tables from a database using something called reflection. Reflection is the process of reading the database and building the metadata based on that information. It's the opposite of creating a Table by hand and is very useful for working with existing databases. To perform reflection, you need to import the Table object from the SQLAlchemy package. Then, you use this Table object to read your table from the engine and autoload the columns. Using the Table object in this manner is a lot like passing arguments to a function. For example, to autoload the columns with the engine, you have to specify the keyword arguments autoload=True and autoload_with=engine to Table(). In this exercise, your job is to reflect the census table available on your engine into a variable called census. The metadata has already been loaded for you using MetaData() and is available in the variable metadata.\",\n",
       " nan,\n",
       " \"Great job reflecting the census table! Now you can begin to learn more about the columns and structure of your table. It is important to get an understanding of your database by examining the column names. This can be done by using the .columnsattribute and accessing the .keys() method. For example, census.columns.keys() would return a list of column names of the census table. Following this, we can use the metadata container to find out more details about the reflected table such as the columns and their types. For example, table objects are stored in the metadata.tables dictionary, so you can get the metadata of your census table with metadata.tables['census']. This is similar to your use of the repr() function on the census table from the previous exercise.\",\n",
       " nan,\n",
       " \"Using what we just learned about SQL and applying the .execute() method on our connection, we can leverage a raw SQL query to query all the records in our census table. The object returned by the .execute() method is a ResultProxy. On this ResultProxy, we can then use the .fetchall() method to get our results - that is, the ResultSet. In this exercise, you'll use a traditional SQL query. In the next exercise, you'll move to SQLAlchemy and begin to understand its advantages. Go for it!\",\n",
       " nan,\n",
       " 'Excellent work so far! It\\'s now time to build your first select statement using SQLAlchemy. SQLAlchemy provides a nice \"Pythonic\" way of interacting with databases. So rather than dealing with the differences between specific dialects of traditional SQL such as MySQL or PostgreSQL, you can leverage the Pythonic framework of SQLAlchemy to streamline your workflow and more efficiently query your data. For this reason, it is worth learning even if you may already be familiar with traditional SQL. In this exercise, you\\'ll once again build a statement to query all records from the census table. This time, however, you\\'ll make use of the select() function of the sqlalchemy module. This function requires a list of tables or columns as the only required argument. Table and MetaData have already been imported. The metadata is available as metadata and the connection to the database as connection.',\n",
       " nan,\n",
       " \"Recall the differences between a ResultProxy and a ResultSet: ResultProxy: The object returned by the .execute()method. It can be used in a variety of ways to get the data returned by the query. ResultSet: The actual data asked for in the query when using a fetch method such as .fetchall() on a ResultProxy. This separation between the ResultSet and ResultProxy allows us to fetch as much or as little data as we desire. Once we have a ResultSet, we can use Python to access all the data within it by column name and by list style indexes. For example, you can get the first row of the results by using results[0]. With that first row then assigned to a variable first_row, you can get data from the first column by either using first_row[0] or by column name such as first_row['column_name']. You'll now practice exactly this using the ResultSet you obtained from the census table in the previous exercise. It is stored in the variable results. Enjoy!\",\n",
       " nan,\n",
       " \"In these exercises, you will be working with real databases hosted on the cloud via Amazon Web Services (AWS)! Let's begin by connecting to a PostgreSQL database. When connecting to a PostgreSQL database, many prefer to use the psycopg2 database driver as it supports practically all of PostgreSQL's features efficiently and is the standard dialect for PostgreSQL in SQLAlchemy. You might recall from Chapter 1 that we use the create_engine() function and a connection string to connect to a database. There are three components to the connection string in this exercise: the dialect and driver ('postgresql+psycopg2://'), followed by the username and password ('student:datacamp'), followed by the host and port ('@postgresql.csrrinzqubik.us-east-1.rds.amazonaws.com:5432/'), and finally, the database name ('census'). You will have to pass this string as an argument to create_engine() in order to connect to the database.\",\n",
       " nan,\n",
       " \"Having connected to the database, it's now time to practice filtering your queries! As mentioned in the video, a where() clause is used to filter the data that a statement returns. For example, to select all the records from the census table where the sex is Female (or 'F') we would do the following: select([census]).where(census.columns.sex == 'F') In addition to == we can use basically any python comparison operator (such as <=, !=, etc) in the where() clause.\",\n",
       " nan,\n",
       " \"In addition to standard Python comparators, we can also use methods such as in_() to create more powerful where()clauses. You can see a full list of expressions in the SQLAlchemy Documentation. We've already created a list of some of the most densely populated states.\",\n",
       " nan,\n",
       " \"You're really getting the hang of this! SQLAlchemy also allows users to use conjunctions such as and_(), or_(), and not_() to build more complex filtering. For example, we can get a set of records for people in New York who are 21 or 37 years old with the following code: stmt([census]).where( and_(census.columns.state == 'New York', or_(census.columns.age == 21, census.columns.age == 37 ) ) )\",\n",
       " nan,\n",
       " 'To sort the result output by a field, we use the .order_by()method. By default, the .order_by() method sorts from lowest to highest on the supplied column. You just have to pass in the name of the column you want sorted to .order_by(). In the video, for example, Jason used stmt.order_by(census.columns.state) to sort the result output by the state column.',\n",
       " nan,\n",
       " \"You can also use .order_by() to sort from highest to lowest by wrapping a column in the desc() function. Although you haven't seen this function in action, it generalizes what you have already learned. All you have to just pass in desc() inside an .order_by() with the name of the column you want to sort by. For instance, stmt.order_by(desc(table.columns.column_name)) sorts column_name in descending order.\",\n",
       " nan,\n",
       " \"We can pass multiple arguments to the .order_by() method to order by multiple columns. In fact, we can also sort in ascending or descending order for each individual column. Each column in the .order_by() method is fully sorted from left to right. This means that the first column is completely sorted, and then within each matching group of values in the first column, it's sorted by the next column in the .order_by() method. This process is repeated until all the columns in the .order_by() are sorted.\",\n",
       " nan,\n",
       " \"As mentioned in the video, SQLAlchemy's func module provides access to built-in SQL functions that can make operations like counting and summing faster and more efficient. In the video, Jason used func.sum() to get a sum of the pop2008 column of census as shown below: select([func.sum(census.columns.pop2008)])\",\n",
       " 'If instead you want to count the number of values in pop2008, you could use func.count() like this: select([func.count(census.columns.pop2008)])',\n",
       " 'Furthermore, if you only want to count the distinct values of pop2008, you can use the .distinct() method: select([func.count(census.columns.pop2008.distinct())])',\n",
       " \"In this exercise, you will practice using func.count() and .distinct() to get a count of the distinct number of states in census. So far, you've seen .fetchall() and .first() used on a ResultProxy to get the results. The ResultProxy also has a method called .scalar() for getting just the value of a query that returns only one row and column. This can be very useful when you are querying for just a count or sum.\",\n",
       " nan,\n",
       " 'Often, we want to get a count for each record with a particular value in another column. The .group_by() method helps answer this type of query. You can pass a column to the .group_by() method and use in a aggregate function like sum() or count(). Much like the .order_by() method, .group_by() can take multiple columns as arguments.',\n",
       " 'INSTRUCTIONS 100XP Import func from sqlalchemy. Build a select statement to get the value of the state field and a count of the values in the age field, and store it as stmt. Use the .group_by() method to group the statement by the state column. Execute stmt using the connection to get the count and store the results as results. Print the keys/column names of the results returned using results[0].keys().',\n",
       " 'To avoid confusion with query result column names like count_1, we can use the .label() method to provide a name for the resulting column. This gets appended to the function method we are using, and its argument is the name we want to use. We can pair func.sum() with .group_by() to get a sum of the population by State and use the label() method to name the output. We can also create the func.sum() expression before using it in the select statement. We do it the same way we would inside the select statement and store it in a variable. Then we use that variable in the select statement where the func.sum() would normally be.',\n",
       " nan,\n",
       " \"We can feed a ResultProxy directly into a pandas DataFrame, which is the workhorse of many Data Scientists in PythonLand. Jason demonstrated this in the video. In this exercise, you'll follow exactly the same approach to convert a ResultProxy into a DataFrame.\",\n",
       " nan,\n",
       " 'We can also take advantage of pandas and Matplotlib to build figures of our data. Remember that data visualization is essential for both exploratory data analysis and communication of your data!',\n",
       " nan,\n",
       " \"Before you jump into the calculation exercises, let's begin by connecting to our database. Recall that in the last chapter you connected to a PostgreSQL database. Now, you'll connect to a MySQL database, for which many prefer to use the pymysqldatabase driver, which, like psycopg2 for PostgreSQL, you have to install prior to use. This connection string is going to start with 'mysql+pymysql://', indicating which dialect and driver you're using to establish the connection. The dialect block is followed by the 'username:password' combo. Next, you specify the host and port with the following '@host:port/'. Finally, you wrap up the connection string with the 'database_name'. Now you'll practice connecting to a MySQL database: it will be the same census database that you have already been working with. One of the great things about SQLAlchemy is that, after connecting, it abstracts over the type of database it has connected to and you can write the same SQLAlchemy code, regardless!\",\n",
       " nan,\n",
       " \"Often, you'll need to perform math operations as part of a query, such as if you wanted to calculate the change in population from 2000 to 2008. For math operations on numbers, the operators in SQLAlchemy work the same way as they do in Python. You can use these operators to perform addition (+), subtraction (-), multiplication (*), division (/), and modulus (%) operations. Note: They behave differently when used with non-numeric column types. Let's now find the top 5 states by population growth between 2000 and 2008.\",\n",
       " nan,\n",
       " \"It's possible to combine functions and operators in a single select statement as well. These combinations can be exceptionally handy when we want to calculate percentages or averages, and we can also use the case() expression to operate on data that meets specific criteria while not affecting the query as a whole. The case() expression accepts a list of conditions to match and the column to return if the condition matches, followed by an else_ if none of the conditions match. We can wrap this entire expression in any function or math operation we like. Often when performing integer division, we want to get a float back. While some databases will do this automatically, you can use the cast() function to convert an expression to a particular type.\",\n",
       " nan,\n",
       " \"Import case, cast, and Float from sqlalchemy. Build an expression female_pop2000to calculate female population in 2000. To achieve this: Use case() inside func.sum(). The first argument of case() is a list containing a tuple of i) A boolean checking that census.columns.sex is equal to 'F'. ii) The column census.columns.pop2000. The second argument is the else_ condition, which should be set to 0. Calculate the total population in 2000 and use cast() to convert it to Float. Build a query to calculate the percentage of females in 2000. To do this, divide female_pop2000 by total_pop2000 and multiply by 100. Execute the query and print percent_female.\",\n",
       " 'If you have two tables that already have an established relationship, you can automatically use that relationship by just adding the columns we want from each table to the select statement. Recall that Jason constructed the following query: stmt = select([census.columns.pop2008, state_fact.columns.abbreviation])',\n",
       " \"in order to join the census and state_fact tables and select the pop2008 column from the first and the abbreviationcolumn from the second. In this case, the census and state_fact tables had a pre-defined relationship: the statecolumn of the former corresponded to the name column of the latter. In this exercise, you'll use the same predefined relationship to select the pop2000 and abbreviation columns!\",\n",
       " nan,\n",
       " \"If you aren't selecting columns from both tables or the two tables don't have a defined relationship, you can still use the .join()method on a table to join it with another table and get extra data related to our query. The join() takes the table object you want to join in as the first argument and a condition that indicates how the tables are related to the second argument. Finally, you use the .select_from() method on the select statement to wrap the join clause. For example, in the video, Jason executed the following code to join the census table to the state_facttable such that the state column of the census table corresponded to the name column of the state_fact table. stmt = stmt.select_from( census.join( state_fact, census.columns.state == state_fact.columns.name)\",\n",
       " nan,\n",
       " \"You can use the same select statement you built in the last exercise, however, let's add a twist and only return a few columns and use the other table in a group_by() clause.\",\n",
       " nan,\n",
       " \"Often, you'll have tables that contain hierarchical data, such as employees and managers who are also employees. For this reason, you may wish to join a table to itself on different columns. The .alias() method, which creates a copy of a table, helps accomplish this task. Because it's the same table, you only need a where clause to specify the join condition. Here, you'll use the .alias() method to build a query to join the employees table against itself to determine to whom everyone reports.\",\n",
       " \"###INSTRUCTIONS 100XP Save an alias of the employees table as managers. To do so, apply the method .alias() to employees. Build a query to select the employee name and their manager's name. The manager's name has already been selected for you. Use label to label the name column of employees as 'employee'. Append a where clause to stmt to match where the idcolumn of the managers table corresponds to the mgrcolumn of the employees table. Order the statement by the name column of the managerstable. Execute the statement and store all the results. This code is already written. Hit 'Submit Answer' to print the names of the managers and all their employees.\",\n",
       " \"It's also common to want to roll up data which is in a hierarchical table. Rolling up data requires making sure you're careful which alias you use to perform the group_bys and which table you use for the function. Here, your job is to get a count of employees for each manager.\",\n",
       " nan,\n",
       " \"Fantastic work so far! As Jason discussed in the video, sometimes you may have the need to work on a large ResultProxy, and you may not have the memory to load all the results at once. To work around that issue, you can get blocks of rows from the ResultProxy by using the .fetchmany() method inside a loop. With .fetchmany(), give it an argument of the number of records you want. When you reach an empty list, there are no more rows left to fetch, and you have processed all the results of the query. Then you need to use the .close() method to close out the connection to the database. You'll now have the chance to practice this on a large ResultProxy called results_proxy that has been pre-loaded for you to work with.\",\n",
       " nan,\n",
       " \"Previously, you used the Table object to reflect a table from an existing database, but what if you wanted to create a new table? You'd still use the Table object; however, you'd need to replace the autoload and autoload_with parameters with Column objects. The Column object takes a name, a SQLAlchemy type with an optional format, and optional keyword arguments for different constraints. When defining the table, recall how in the video Jason passed in 255 as the maximum length of a String by using Column('name', String(255)). Checking out the slides from the video may help: you can dowload them by clicking on 'Slides' next to the IPython Shell. After defining the table, you can create the table in the database by using the .create_all() method on metadata and supplying the engine as the only parameter. Go for it!\",\n",
       " nan,\n",
       " \"You're now going to practice creating a table with some constraints! Often, you'll need to make sure that a column is unique, nullable, a positive value, or related to a column in another table. This is where constraints come in. As Jason showed you in the video, in addition to constraints, you can also set a default value for the column if no data is passed to it via the default keyword on the column.\",\n",
       " nan,\n",
       " 'There are several ways to perform an insert with SQLAlchemy; however, we are going to focus on the one that follows the same pattern as the select statement. It uses an insert statement where you specify the table as an argument, and supply the data you wish to insert into the value via the .values() method as keyword arguments. Here, the name of the table is data.',\n",
       " nan,\n",
       " \"It's time to practice inserting multiple records at once! As Jason showed you in the video, you'll want to first build a list of dictionaries that represents the data you want to insert. Then, in the .execute() method, you can pair this list of dictionaries with an insert statement, which will insert all the records in your list of dictionaries.\",\n",
       " nan,\n",
       " \"You've done a great job so far at inserting data into tables! You're now going to learn how to load the contents of a CSV file into a table. We have used the csv module to set up a csv_reader, which is just a reader object that can iterate over the lines in a given CSV file - in this case, a census CSV file. Using the enumerate()function, you can loop over the csv_reader to handle the results one at a time. Here, for example, the first line it would return is: 0 ['Illinois', 'M', '0', '89600', '95012'] 0 is the idx - or line number - while ['Illinois', 'M', '0', '89600', '95012'] is the row, corresponding to the column names 'state' , 'sex', 'age', 'pop2000 'and 'pop2008'. 'Illinois' can be accessed with row[0], 'M' with row[1], and so on. You can create a dictionary containing this information where the keys are the column names and the values are the entries in each line. Then, by appending this dictionary to a list, you can combine it with an insert statement to load it all into a table!\",\n",
       " nan,\n",
       " \"The update statement is very similar to an insert statement, except that it also typically uses a where clause to help us determine what data to update. You'll be using the FIPS state code using here, which is appropriated by the U.S. government to identify U.S. states and certain other associated areas. Recall that you can update all wages in the employees table as follows: stmt = update(employees).values(wage=100.00)\",\n",
       " 'For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), name(Column), and fips_state (Column).',\n",
       " nan,\n",
       " \"As Jason discussed in the video, by using a where clause that selects more records, you can update multiple records at once. It's time now to practice this! For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), notes(Column), and census_region_name (Column).\",\n",
       " nan,\n",
       " \"You can also update records with data from a select statement. This is called a correlated update. It works by defining a selectstatement that returns the value you want to update the record with and assigning that as the value in an update statement. You'll be using a flat_census in this exercise as the target of your correlated update. The flat_census table is a summarized copy of your census table.\",\n",
       " nan,\n",
       " \"Often, you'll need to empty a table of all of its records so you can reload the data. You can do this with a delete statement with just the table as an argument. For example, in the video, Jason deleted the table extra_employees by executing as follows: delete_stmt = delete(census) result_proxy = connection.execute(delete_stmt)\",\n",
       " 'Do be careful, though, as deleting cannot be undone!',\n",
       " nan,\n",
       " 'By using a where() clause, you can target the deletestatement to remove only certain records. For example, Jason deleted all columns from the employees table that had id 3 with the following delete statement: delete(employees).where(employees.columns.id == 3)',\n",
       " \"Here you'll delete ALL rows which have 'M' in the sexcolumn and 36 in the age column. We have included code at the start which computes the total number of these rows. It is important to make sure that this is the number of rows that you actually delete.\",\n",
       " nan,\n",
       " \"You're now going to practice dropping individual tables from a database with the .drop() method, as well as all tables in a database with the .drop_all() method! As Spider-Man's Uncle Ben (as well as Jason, in the video!) said: With great power, comes great responsibility. Do be careful when deleting tables, as it's not simple or fast to restore large databases! Remember, you can check to see if a table exists with the .exists() method. This is the final exercise in this chapter: After this, you'll be ready to apply everything you've learned to a case study in the final chapter of this course!\",\n",
       " nan,\n",
       " 'In this exercise, your job is to create an engine to the database that will be used in this chapter. Then, you need to initialize its metadata. Recall how you did this in Chapter 1 by leveraging create_engine() and MetaData.',\n",
       " nan,\n",
       " 'Having setup the engine and initialized the metadata, you will now define the census table object and then create it in the database using using the metadata and engine from the previous exercise. To create it in the database, you will have to use the .create_all() method on the metadata with engine as the argument. It may help to refer back to the Chapter 4 exercise in which you learned how to create a table.',\n",
       " nan,\n",
       " 'Leverage the Python CSV module from the standard library and load the data into a list of dictionaries. It may help to refer back to the Chapter 4 exercise in which you did something similar.',\n",
       " nan,\n",
       " 'Using the multiple insert pattern, in this exercise, you will load the data from values_list into the table.',\n",
       " nan,\n",
       " \"In this exercise, you will use the func.sum() and group_by()methods to first determine the average age weighted by the population in 2008, and then group by sex. As Jason discussed in the video, a weighted average is calculated as the sum of the product of the weights and averages divided by the sum of all the weights. For example, the following statement determines the average age weighted by the population in 2000: stmt = select([census.columns.sex, (func.sum(census.columns.pop2000 * census.columns.age) / func.sum(census.columns.pop2000)).label('average_age') ])\",\n",
       " nan,\n",
       " 'In this exercise, you will write a query to determine the percentage of the population in 2000 that comprised of women. You will group this query by state.',\n",
       " nan,\n",
       " 'In this final exercise, you will write a query to calculate the states that changed the most in population. You will limit your query to display only the top 10 states.',\n",
       " nan,\n",
       " 'It is time now to put together some of what you have learned and combine line plots on a common set of axes. The data set here comes from records of undergraduate degrees awarded to women in a variety of fields from 1970 to 2011. You can compare trends in degrees most easily by viewing two curves on the same set of axes. Here, three NumPy arrays have been pre-loaded for you: year(enumerating years from 1970 to 2011 inclusive), physical_sciences (representing the percentage of Physical Sciences degrees awarded to women each in corresponding year), and computer_science (representing the percentage of Computer Science degrees awarded to women in each corresponding year). You will issue two plt.plot() commands to draw line plots of different colors on the same set of axes. Here, year represents the x-axis, while physical_sciences and computer_scienceare the y-axes.',\n",
       " nan,\n",
       " 'Rather than overlaying line plots on common axes, you may prefer to plot different line plots on distinct axes. The command plt.axes() is one way to do this (but it requires specifying coordinates relative to the size of the figure). Here, you have the same three arrays year, physical_sciences, and computer_science representing percentages of degrees awarded to women over a range of years. You will use plt.axes() to create separate sets of axes in which you will draw each line plot. In calling plt.axes([xlo, ylo, width, height]), a set of axes is created and made active with lower corner at coordinates (xlo, ylo) of the specified width and height. Note that these coordinates can be passed to plt.axes() in the form of a list or a tuple. The coordinates and lengths are values between 0 and 1 representing lengths relative to the dimensions of the figure. After issuing a plt.axes() command, plots generated are put in that set of axes.',\n",
       " nan,\n",
       " 'The command plt.axes() requires a lot of effort to use well because the coordinates of the axes need to be set manually. A better alternative is to use plt.subplot() to determine the layout automatically. In this exercise, you will continue working with the same arrays from the previous exercises: year, physical_sciences, and computer_science. Rather than using plt.axes() to explicitly lay out the axes, you will use plt.subplot(m, n, k) to make the subplot grid of dimensions m by n and to make the kth subplot active (subplots are numbered starting from 1 row-wise from the top left corner of the subplot grid).',\n",
       " nan,\n",
       " 'Now you have some familiarity with plt.subplot(), you can use it to plot more plots in larger grids of subplots of the same figure. Here, you will make a 2Ã—22Ã—2 grid of subplots and plot the percentage of degrees awarded to women in Physical Sciences (using physical_sciences), in Computer Science (using computer_science), in Health Professions (using health), and in Education (using education).',\n",
       " nan,\n",
       " 'In this exercise, you will work with the matplotlib.pyplotinterface to quickly set the x- and y-limits of your plots. You will now create the same figure as in the previous exercise using plt.plot(), this time setting the axis extents using plt.xlim() and plt.ylim(). These commands allow you to either zoom or expand the plot or to set the axis ranges to include important values (such as the origin). In this exercise, as before, the percentage of women graduates in Computer Science and in the Physical Sciences are held in the variables computer_science and physical_sciencesrespectively over year. After creating the plot, you will use plt.savefig() to export the image produced to a file.',\n",
       " nan,\n",
       " 'Using plt.xlim() and plt.ylim() are useful for setting the axis limits individually. In this exercise, you will see how you can pass a 4-tuple to plt.axis() to set limits for both axes at once. For example, plt.axis((1980,1990,0,75)) would set the extent of the x-axis to the period between 1980 and 1990, and would set the y-axis extent from 0 to 75% degrees award. Once again, the percentage of women graduates in Computer Science and in the Physical Sciences are held in the variables computer_science and physical_sciences where each value was measured at the corresponding year held in the yearvariable.',\n",
       " nan,\n",
       " 'Legends are useful for distinguishing between multiple datasets displayed on common axes. The relevant data are created using specific line colors or markers in various plot commands. Using the keyword argument label in the plotting function associates a string to use in a legend. For example, here, you will plot enrollment of women in the Physical Sciences and in Computer Science over time. You can label each curve by passing a label argument to the plotting call, and request a legend using plt.legend(). Specifying the keyword argument loc determines where the legend will be placed.',\n",
       " nan,\n",
       " \"It is often useful to annotate a simple plot to provide context. This makes the plot more readable and can highlight specific aspects of the data. Annotations like text and arrows can be used to emphasize specific observations. Here, you will once again plot enrollment of women in the Physical Sciences and Computer science over time. The legend is set up as before. Additionally, you will mark the inflection point when enrollment of women in Computer Science reached a peak and started declining using plt.annotate(). To enable an arrow, set arrowprops=dict(facecolor='black'). The arrow will point to the location given by xy and the text will appear at the location given by xytext.\",\n",
       " nan,\n",
       " 'Matplotlib comes with a number of different stylesheets to customize the overall look of different plots. To activate a particular stylesheet you can simply call plt.style.use() with the name of the style sheet you want. To list all the available style sheets you can execute: print(plt.style.available).',\n",
       " nan,\n",
       " 'In order to visualize two-dimensional arrays of data, it is necessary to understand how to generate and manipulate 2-D arrays. Many Matplotlib plots support arrays as input and in particular, they support NumPy arrays. The NumPy library is the most widely-supported means for supporting numeric arrays in Python. In this exercise, you will use the meshgrid function in NumPy to generate 2-D arrays which you will then visualize using plt.imshow(). The simplest way to generate a meshgrid is as follows: import numpy as np Y,X = np.meshgrid(range(10),range(20))',\n",
       " 'This will create two arrays with a shape of (20,10), which corresponds to 20 rows along the Y-axis and 10 columns along the X-axis. In this exercise, you will use np.meshgrid() to generate a regular 2-D sampling of a mathematical function.',\n",
       " nan,\n",
       " 'Although plt.imshow() or plt.pcolor() are often used to visualize a 2-D array in entirety, there are other ways of visualizing such data without displaying all the available sample values. One option is to use the array to compute contours that are visualized instead. Two types of contour plot supported by Matplotlib are plt.contour() and plt.contourf() where the former displays the contours as lines and the latter displayed filled areas between contours. Both these plotting commands accept a two dimensional array from which the appropriate contours are computed. In this exercise, you will visualize a 2-D array repeatedly using both plt.contour() and plt.contourf(). You will use plt.subplot() to display several contour plots in a common figure, using the meshgrid X, Y as the axes. For example, plt.contour(X, Y, Z) generates a default contour map of the array Z.',\n",
       " nan,\n",
       " \"When displaying a 2-D array with plt.imshow() or plt.pcolor(), the values of the array are mapped to a corresponding color. The set of colors used is determined by a colormap which smoothly maps values to colors, making it easy to understand the structure of the data at a glance. It is often useful to change the colormap from the default 'jet'colormap used by matplotlib. A good colormap is visually pleasing and conveys the structure of the data faithfully and in a way that makes sense for the application. Some matplotlib colormaps have unique names such as 'jet', 'coolwarm', 'magma' and 'viridis'. Others have a naming scheme based on overall color such as 'Greens', 'Blues', 'Reds', and 'Purples'. Another four colormaps are based on the seasons, namely 'summer', 'autumn', 'winter' and 'spring'. You can insert the option cmap= into most matplotlib functions to change the color map of the resulting plot. In this exercise, you will explore four different colormaps together using plt.subplot(). You will use a pregenerated array Z and a meshgrid X, Y to generate the same filled contour plot with four different color maps. Be sure to also add a color bar to each filled contour plot with plt.colorbar().\",\n",
       " nan,\n",
       " \"Given a set of ordered pairs describing data points, you can count the number of points with similar values to construct a two-dimensional histogram. This is similar to a one-dimensional histogram, but it describes the joint variation of two random variables rather than just one. In matplotlib, one function to visualize 2-D histograms is plt.hist2d(). You specify the coordinates of the points using plt.hist2d(x,y) assuming x and y are two vectors of the same length. You can specify the number of bins with the argument bins=(nx, ny) where nx is the number of bins to use in the horizontal direction and ny is the number of bins to use in the vertical direction. You can specify the rectangular region in which the samples are counted in constructing the 2D histogram. The optional parameter required is range=((xmin, xmax), (ymin, ymax)) where xmin and xmax are the respective lower and upper limits for the variables on the x-axis and ymin and ymax are the respective lower and upper limits for the variables on the y-axis. Notice that the optional range argument can use nested tuples or lists. In this exercise, you'll use some data from the auto-mpg data set. There are two arrays mpg and hp that respectively contain miles per gallon and horse power ratings from over three hundred automobiles built.\",\n",
       " nan,\n",
       " \"The function plt.hist2d() uses rectangular bins to construct a two dimensional histogram. As an alternative, the function plt.hexbin() uses hexagonal bins. The underlying algorithm (based on this article from 1987) constructs a hexagonal tesselation of a planar region and aggregates points insidehexagonal bins. The optional gridsize argument (default 100) gives the number of hexagons across the x-direction used in the hexagonal tiling. If specified as a list or a tuple of length two, gridsize fixes the number of hexagon in the x- and y-directions respectively in the tiling. The optional parameter extent=(xmin, xmax, ymin, ymax) specifies rectangular region covered by the hexagonal tiling. In that case, xminand xmax are the respective lower and upper limits for the variables on the x-axis and ymin and ymax are the respective lower and upper limits for the variables on the y-axis. In this exercise, you'll use the same auto-mpg data as in the last exercise (again using arrays mpg and hp). This time, you'll use plt.hexbin() to visualize the two-dimensional histogram.\",\n",
       " nan,\n",
       " 'Color images such as photographs contain the intensity of the red, green and blue color channels. To read an image from file, use plt.imread() by passing the path to a file, such as a PNG or JPG file. The color image can be plotted as usual using plt.imshow(). The resulting image loaded is a NumPy array of three dimensions. The array typically has dimensions MÃ—NÃ—3MÃ—NÃ—3, where MÃ—NMÃ—N is the dimensions of the image. The third dimensions are referred to as color channels (typically red, green, and blue). The color channels can be extracted by Numpy array slicing. In this exercise, you will load & display an image of an astronaut(by NASA (Public domain), via Wikimedia Commons). You will also examine its attributes to understand how color images are represented.',\n",
       " nan,\n",
       " \"Image data comes in many forms and it is not always appropriate to display the available channels in RGB space. In many situations, an image may be processed and analysed in some way before it is visualized in pseudocolor, also known as 'false' color. In this exercise, you will perform a simple analysis using the image showing an astronaut as viewed from space. Instead of simply displaying the image, you will compute the total intensity across the red, green and blue channels. The result is a single two dimensional array which you will display using plt.imshow()with the 'gray' colormap.\",\n",
       " nan,\n",
       " \"When using plt.imshow() to display an array, the default behavior is to keep pixels square so that the height to width ratio of the output matches the ratio determined by the shape of the array. In addition, by default, the x- and y-axes are labeled by the number of samples in each direction. The ratio of the displayed width to height is known as the image aspect and the range used to label the x- and y-axes is known as the image extent. The default aspect value of 'auto'keeps the pixels square and the extents are automatically computed from the shape of the array if not specified otherwise. In this exercise, you will investigate how to set these options explicitly by plotting the same image in a 2 by 2 grid of subplots with distinct aspect and extent options.\",\n",
       " nan,\n",
       " 'Sometimes, low contrast images can be improved by rescalingtheir intensities. For instance, this image of Hawkes Bay, New Zealand (originally by Phillip Capper, modified by User:Konstable, via Wikimedia Commons, CC BY 2.0) has no pixel values near 0 or near 255 (the limits of valid intensities). For this exercise, you will do a simple rescaling (remember, an image is NumPy array) to translate and stretch the pixel intensities so that the intensities of the new image fill the range from 0 to 255.',\n",
       " nan,\n",
       " \"As you have seen, seaborn provides a convenient interface to generate complex and great-looking statistical plots. One of the simplest things you can do using seaborn is to fit and visualize a simple linear regression between two variables using sns.lmplot(). One difference between seaborn and regular matplotlib plotting is that you can pass pandas DataFrames directly to the plot and refer to each column by name. For example, if you were to plot the column 'price' vs the column 'area' from a DataFrame df, you could call sns.lmplot(x='area', y='price', data=df). In this exercise, you will once again use the DataFrame autocontaining the auto-mpg dataset. You will plot a linear regression illustrating the relationship between automobile weight and horse power.\",\n",
       " nan,\n",
       " \"Often, you don't just want to see the regression itself but also see the residuals to get a better idea how well the regression captured the data. Seaborn provides sns.residplot() for that purpose, visualizing how far datapoints diverge from the regression line. In this exercise, you will visualize the residuals of a regression between the 'hp' column (horse power) and the 'mpg'column (miles per gallon) of the auto DataFrame used previously.\",\n",
       " nan,\n",
       " \"When there are more complex relationships between two variables, a simple first order regression is often not sufficient to accurately capture the relationship between the variables. Seaborn makes it simple to compute and visualize regressions of varying orders. Here, you will plot a second order regression between the horse power ('hp') and miles per gallon ('mpg') using sns.regplot() (the function sns.lmplot() is a higher-level interface to sns.regplot()). However, before plotting this relationship, compare how the residual changes depending on the order of the regression. Does a second order regression perform significantly better than a simple linear regression? A principal difference between sns.lmplot() and sns.regplot() is the way in which matplotlib options are passed (sns.regplot() is more permissive). For both sns.lmplot() and sns.regplot(), the keyword order is used to control the order of polynomial regression. The function sns.regplot() uses the argument scatter=None to prevent plotting the scatter plot points again.\",\n",
       " nan,\n",
       " \"Often it is useful to compare and contrast trends between different groups. Seaborn makes it possible to apply linear regressions separately for subsets of the data by applying a groupby operation. Using the hue argument, you can specify a categorical variable by which to group data observations. The distinct groups of points are used to produce distinct regressions with different hues in the plot. In the automobile dataset - which has been pre-loaded here as auto - you can view the relationship between weight ('weight') and horsepower ('hp') of the cars and group them by their origin ('origin'), giving you a quick visual indication how the relationship differs by continent.\",\n",
       " nan,\n",
       " \"Rather than overlaying linear regressions of grouped data in the same plot, we may want to use a grid of subplots. The sns.lmplot() accepts the arguments row and/or col to arrangements of subplots for regressions. You'll use the automobile dataset again and, this time, you'll use the keyword argument row to display the subplots organized in rows. That is, you'll produce horsepower vs. weight regressions grouped by continent of origin in separate subplots stacked vertically.\",\n",
       " nan,\n",
       " \"Regressions are useful to understand relationships between two continuous variables. Often we want to explore how the distribution of a single continuous variable is affected by a second categorical variable. Seaborn provides a variety of plot types to perform these types of comparisons between univariate distributions. The strip plot is one way of visualizing this kind of data. It plots the distribution of variables for each category as individual datapoints. For vertical strip plots (the default), distributions of continuous values are laid out parallel to the y-axis and the distinct categories are spaced out along the x-axis. For example, sns.stripplot(x='type', y='length', data=df)produces a sequence of vertical strip plots of lengthdistributions grouped by type (assuming length is a continuous column and type is a categorical column of the DataFrame df). Overlapping points can be difficult to distinguish in strip plots. The argument jitter=True helps spread out overlapping points. Other matplotlib arguments can be passed to sns.stripplot(), e.g., marker, color, size, etc.\",\n",
       " nan,\n",
       " \"As you have seen, a strip plot can be visually crowded even with jitter applied and smaller point sizes. An alternative is provided by the swarm plot (sns.swarmplot()), which is very similar but spreads out the points to avoid overlap and provides a better visual overview of the data. The syntax for sns.swarmplot() is similar to that of sns.stripplot(), e.g., sns.swarmplot(x='type', y='length', data=df). The orientation for the continuous variable in the strip/swarm plot can be inferred from the choice of the columns x and y from the DataFrame data. The orientation can be set explicitly using orient='h'(horizontal) or orient='v' (vertical). Another grouping can be added in using the hue keyword. For instance, using sns.swarmplot(x='type', y='length', data=df, hue='build year')makes a swarm plot from the DataFrame df with the 'length' column values spread out vertically, horizontally grouped by the column 'type' and each point colored by the categorical column 'build year'. In this exercise, you'll use the auto DataFrame again to illustrate the use of sns.swarmplot() with grouping by hueand with explicit specification of the orientation using the keyword orient.\",\n",
       " nan,\n",
       " \"Both strip and swarm plots visualize all the datapoints. For large datasets, this can result in significant overplotting. Therefore, it is often useful to use plot types which reduce a dataset to more descriptive statistics and provide a good summary of the data. Box and whisker plots are a classic way of summarizing univariate distributions but seaborn provides a more sophisticated extension of the standard box plot, called a violin plot. Here, you will produce violin plots of the distribution of horse power ('hp') by the number of cylinders ('cyl'). Additionally, you will combine two different plot types by overlaying a strip plot on the violin plot. As before, the DataFrame has been pre-loaded for you as auto.\",\n",
       " nan,\n",
       " \"There are numerous strategies to visualize how pairs of continuous random variables vary jointly. Regression and residual plots are one strategy. Another is to visualize a bivariate distribution. Seaborn's sns.jointplot() provides means of visualizing bivariate distributions. The basic calling syntax is similar to that of sns.lmplot(). By default, calling sns.jointplot(x, y, data) renders a few things: A scatter plot using the specified columns x and y from the DataFrame data. A (univariate) histogram along the top of the scatter plot showing distribution of the column x. A (univariate) histogram along the right of the scatter plot showing distribution of the column y.\",\n",
       " nan,\n",
       " \"The seaborn function sns.jointplot() has a parameter kindto specify how to visualize the joint variation of two continuous random variables (i.e., two columns of a DataFrame) kind='scatter' uses a scatter plot of the data points kind='reg' uses a regression plot (default order 1) kind='resid' uses a residual plot kind='kde' uses a kernel density estimate of the joint distribution kind='hex' uses a hexbin plot of the joint distribution For this exercise, you will again use sns.jointplot() to display the joint distribution of the hp and mpg columns of the autoDataFrame. This time, you will use kind='hex' to generate a hexbin plot of the joint distribution.\",\n",
       " nan,\n",
       " 'Data sets often contain more than two continuous variables. The function sns.jointplot() is restricted to representing joint variation between only two quantities (i.e., two columns of a DataFrame). Visualizing multivariate relationships is trickier. The function sns.pairplot() constructs a grid of all joint plots pairwise from all pairs of (non-categorical) columns in a DataFrame. The syntax is very simple: sns.pairplot(df), where df is a DataFrame. The non-categorical columns are identified and the corresponding joint plots are plotted in a square grid of subplots. The diagonal of the subplot grid shows the univariate histograms of the individual columns. In this exercise, you will use a DataFrame auto comprising only three columns from the original auto-mpg data set.',\n",
       " nan,\n",
       " \"In this exercise, you will generate pairwise joint distributions again. This time, you will make two particular additions: You will display regressions as well as scatter plots in the off-diagonal subplots. You will do this with the argument kind='reg' (where 'reg' means 'regression'). Another option for kind is 'scatter' (the default) that plots scatter plots in the off-diagonal subplots. You will also visualize the joint distributions separated by continent of origin. You will do this with the keyword argument hue specifying the 'origin'.\",\n",
       " nan,\n",
       " 'Plotting relationships between many variables using a pair plot can quickly get visually overwhelming. It is therefore often useful to compute covariances between the variables instead. The covariance matrix can then easily be visualized as a heatmap. A heatmap is effectively a pseudocolor plot with labelled rows and columns (i.e., a pseudocolor plot based on a pandas DataFrame rather than a matrix). The DataFrame does not have to be square or symmetric (but, in the context of a covariance matrix, it is both). In this exercise, you will view the covariance matrix between the continuous variables in the auto-mpg dataset. You do not have to know here how the covariance matrix is computed; the important point is that its diagonal entries are all 1s, and the off-diagonal entries are between -1 and +1 (quantifying the degree to which variable pairs vary jointly). It is also, then, a symmetric matrix.',\n",
       " nan,\n",
       " 'How do they calculate the avaerages over the increasing number of days',\n",
       " \"For this exercise, you will construct a plot showing four time series stocks on the same axes. The time series in question are represented in the session using the identifiers aapl, ibm, csco, and msft. You'll generate a single plot showing all the time series on common axes with a legend.\",\n",
       " nan,\n",
       " \"You can easily slice subsets corresponding to different time intervals from a time series. In particular, you can use strings like '2001:2005', '2011-03:2011-12', or '2010-04-19:2010-04-30' to extract data from time intervals of length 5 years, 10 months, or 12 days respectively. Unlike slicing from standard Python lists, tuples, and strings, when slicing time series by labels (and other pandas Series & DataFrames by labels), the slice includes the right-most portion of the slice. That is, extracting my_time_series['1990':'1995'] extracts data from my_time_series corresponding to 1990, 1991, 1992, 1993, 1994, and 1995 inclusive. You can use partial strings or datetime objects for indexing and slicing from time series. For this exercise, you will use time series slicing to plot the time series aapl over its full 11-year range and also over a shorter 2-year range. You'll arrange these plots in a 2Ã—12Ã—1 grid of subplots\",\n",
       " nan,\n",
       " \"In this exercise, you will use the same time series aapl from the previous exercise and plot tighter views of the data. Partial string indexing works without slicing as well. For instance, using my_time_series['1995'], my_time_series['1999-05'], and my_time_series['2000-11-04'] respectively extracts views of the time series my_time_series corresponding to the entire year 1995, the entire month May 1999, and the entire day November 4, 2000.\",\n",
       " nan,\n",
       " \"Remember, rather than comparing plots with subplots or overlayed plots, you can generate an inset view directly using plt.axes(). In this exercise, you'll reproduce two of the time series plots from the preceding two exercises. Your figure will contain an inset plot to highlight the dramatic changes in AAPL stock price between November 2007 and April 2008 (as compared to the 11 years from 2001 to 2011).\",\n",
       " nan,\n",
       " 'In this exercise, you will plot pre-computed moving averages of AAPL stock prices in distinct subplots. The time series aapl is overlayed in black in each subplot for comparison. The time series mean_30, mean_75, mean_125, and mean_250 have been computed for you (containing the windowed averages of the series aapl computed over windows of width 30 days, 75 days, 125 days, and 250 days respectively).',\n",
       " nan,\n",
       " 'Having plotted pre-computed moving averages of AAPL stock prices on distinct subplots in the previous exercise, you will now plot pre-computed moving standard deviations of the same stock prices, this time together on common axes. The time series aapl is not plotted in this case; it is of a different length scale than the standard deviations. The time series std_30, std_75, stdn_125, & std_250 have been computed for you (containing the windowed standard deviations of the series aaplcomputed over windows of width 30 days, 75 days, 125 days, & 250 days respectively).',\n",
       " nan,\n",
       " 'For grayscale images, various image processing algorithms use an image histogram. Recall that an image is a two-dimensional array of numerical intensities. An image histogram, then, is computed by counting the occurences of distinct pixel intensities over all the pixels in the image. For this exercise, you will load an unequalized low contrast image of Hawkes Bay, New Zealand (originally by Phillip Capper, modified by User:Konstable, via Wikimedia Commons, CC BY 2.0). You will plot the image and use the pixel intensity values to plot a normalized histogram of pixel intensities.',\n",
       " nan,\n",
       " \"A histogram of a continuous random variable is sometimes called a Probability Distribution Function (or PDF). The area under a PDF (a definite integral) is called a Cumulative Distribution Function (or CDF). The CDF quantifies the probability of observing certain pixel intensities. Your task here is to plot the PDF and CDF of pixel intensities from a grayscale image. You will use the grayscale image of Hawkes Bay, New Zealand (originally by Phillip Capper, modified by User:Konstable, via Wikimedia Commons, CC BY 2.0). This time, the 2D array image will be pre-loaded and pre-flattened into the 1D array pixels for you. The histogram option cumulative=True permits viewing the CDF instead of the PDF. Notice that plt.grid('off') switches off distracting grid lines. The command plt.twinx() allows two plots to be overlayed sharing the x-axis but with different scales on the y-axis.\",\n",
       " nan,\n",
       " 'Histogram equalization is an image processing procedure that reassigns image pixel intensities. The basic idea is to use interpolation to map the original CDF of pixel intensities to a CDF that is almost a straight line. In essence, the pixel intensities are spread out and this has the practical effect of making a sharper, contrast-enhanced image. This is particularly useful in astronomy and medical imaging to help us see more features. For this exercise, you will again work with the grayscale image of Hawkes Bay, New Zealand (originally by Phillip Capper, modified by User:Konstable, via Wikimedia Commons, CC BY 2.0). Notice the sample code produces the same plot as the previous exercise. Your task is to modify the code from the previous exercise to plot the new equalized image as well as its PDF and CDF. The arrays image and pixels are extracted for you in advance. The CDF of the original image is computed using plt.hist(). Notice an array new_pixels is created for you that interpolates new pixel values using the original image CDF.',\n",
       " nan,\n",
       " 'This exercise resembles the last in that you will plot histograms from an image. This time, you will use a color image of the Helix Nebula as seen by the Hubble and the Cerro Toledo Inter-American Observatory. The separate RGB (red-green-blue) channels will be extracted for you as two-dimensional arrays red, green, and blue respectively. You will plot three overlaid color histograms on common axes (one for each channel) in a subplot as well as the original image in a separate subplot.',\n",
       " nan,\n",
       " 'Rather than overlaying univariate histograms of intensities in distinct channels, it is also possible to view the joint variation of pixel intensity in two different channels. For this final exercise, you will use the same color image of the Helix Nebula as seen by the Hubble and the Cerro Toledo Inter-American Observatory. The separate RGB (red-green-blue) channels will be extracted for you as one-dimensional arrays red_pixels, green_pixels, & blue_pixels respectively.',\n",
       " nan,\n",
       " 'Get product updates, company news, and more.',\n",
       " \"Before you jump into the calculation exercises, let's begin by connecting to our database. Recall that in the last chapter you connected to a PostgreSQL database. Now, you'll connect to a MySQL database, for which many prefer to use the pymysqldatabase driver, which, like psycopg2 for PostgreSQL, you have to install prior to use. This connection string is going to start with 'mysql+pymysql://', indicating which dialect and driver you're using to establish the connection. The dialect block is followed by the 'username:password' combo. Next, you specify the host and port with the following '@host:port/'. Finally, you wrap up the connection string with the 'database_name'. Now you'll practice connecting to a MySQL database: it will be the same census database that you have already been working with. One of the great things about SQLAlchemy is that, after connecting, it abstracts over the type of database it has connected to and you can write the same SQLAlchemy code, regardless!\",\n",
       " nan,\n",
       " \"Often, you'll need to perform math operations as part of a query, such as if you wanted to calculate the change in population from 2000 to 2008. For math operations on numbers, the operators in SQLAlchemy work the same way as they do in Python. You can use these operators to perform addition (+), subtraction (-), multiplication (*), division (/), and modulus (%) operations. Note: They behave differently when used with non-numeric column types. Let's now find the top 5 states by population growth between 2000 and 2008.\",\n",
       " nan,\n",
       " \"It's possible to combine functions and operators in a single select statement as well. These combinations can be exceptionally handy when we want to calculate percentages or averages, and we can also use the case() expression to operate on data that meets specific criteria while not affecting the query as a whole. The case() expression accepts a list of conditions to match and the column to return if the condition matches, followed by an else_ if none of the conditions match. We can wrap this entire expression in any function or math operation we like. Often when performing integer division, we want to get a float back. While some databases will do this automatically, you can use the cast() function to convert an expression to a particular type.\",\n",
       " nan,\n",
       " \"Import case, cast, and Float from sqlalchemy. Build an expression female_pop2000to calculate female population in 2000. To achieve this: Use case() inside func.sum(). The first argument of case() is a list containing a tuple of i) A boolean checking that census.columns.sex is equal to 'F'. ii) The column census.columns.pop2000. The second argument is the else_ condition, which should be set to 0. Calculate the total population in 2000 and use cast() to convert it to Float. Build a query to calculate the percentage of females in 2000. To do this, divide female_pop2000 by total_pop2000 and multiply by 100. Execute the query and print percent_female.\",\n",
       " 'If you have two tables that already have an established relationship, you can automatically use that relationship by just adding the columns we want from each table to the select statement. Recall that Jason constructed the following query: stmt = select([census.columns.pop2008, state_fact.columns.abbreviation])',\n",
       " \"in order to join the census and state_fact tables and select the pop2008 column from the first and the abbreviationcolumn from the second. In this case, the census and state_fact tables had a pre-defined relationship: the statecolumn of the former corresponded to the name column of the latter. In this exercise, you'll use the same predefined relationship to select the pop2000 and abbreviation columns!\",\n",
       " nan,\n",
       " \"If you aren't selecting columns from both tables or the two tables don't have a defined relationship, you can still use the .join()method on a table to join it with another table and get extra data related to our query. The join() takes the table object you want to join in as the first argument and a condition that indicates how the tables are related to the second argument. Finally, you use the .select_from() method on the select statement to wrap the join clause. For example, in the video, Jason executed the following code to join the census table to the state_facttable such that the state column of the census table corresponded to the name column of the state_fact table. stmt = stmt.select_from( census.join( state_fact, census.columns.state == state_fact.columns.name)\",\n",
       " nan,\n",
       " \"You can use the same select statement you built in the last exercise, however, let's add a twist and only return a few columns and use the other table in a group_by() clause.\",\n",
       " nan,\n",
       " \"Often, you'll have tables that contain hierarchical data, such as employees and managers who are also employees. For this reason, you may wish to join a table to itself on different columns. The .alias() method, which creates a copy of a table, helps accomplish this task. Because it's the same table, you only need a where clause to specify the join condition. Here, you'll use the .alias() method to build a query to join the employees table against itself to determine to whom everyone reports.\",\n",
       " \"###INSTRUCTIONS 100XP Save an alias of the employees table as managers. To do so, apply the method .alias() to employees. Build a query to select the employee name and their manager's name. The manager's name has already been selected for you. Use label to label the name column of employees as 'employee'. Append a where clause to stmt to match where the idcolumn of the managers table corresponds to the mgrcolumn of the employees table. Order the statement by the name column of the managerstable. Execute the statement and store all the results. This code is already written. Hit 'Submit Answer' to print the names of the managers and all their employees.\",\n",
       " \"It's also common to want to roll up data which is in a hierarchical table. Rolling up data requires making sure you're careful which alias you use to perform the group_bys and which table you use for the function. Here, your job is to get a count of employees for each manager.\",\n",
       " nan,\n",
       " \"Fantastic work so far! As Jason discussed in the video, sometimes you may have the need to work on a large ResultProxy, and you may not have the memory to load all the results at once. To work around that issue, you can get blocks of rows from the ResultProxy by using the .fetchmany() method inside a loop. With .fetchmany(), give it an argument of the number of records you want. When you reach an empty list, there are no more rows left to fetch, and you have processed all the results of the query. Then you need to use the .close() method to close out the connection to the database. You'll now have the chance to practice this on a large ResultProxy called results_proxy that has been pre-loaded for you to work with.\",\n",
       " nan,\n",
       " \"Previously, you used the Table object to reflect a table from an existing database, but what if you wanted to create a new table? You'd still use the Table object; however, you'd need to replace the autoload and autoload_with parameters with Column objects. The Column object takes a name, a SQLAlchemy type with an optional format, and optional keyword arguments for different constraints. When defining the table, recall how in the video Jason passed in 255 as the maximum length of a String by using Column('name', String(255)). Checking out the slides from the video may help: you can dowload them by clicking on 'Slides' next to the IPython Shell. After defining the table, you can create the table in the database by using the .create_all() method on metadata and supplying the engine as the only parameter. Go for it!\",\n",
       " nan,\n",
       " \"You're now going to practice creating a table with some constraints! Often, you'll need to make sure that a column is unique, nullable, a positive value, or related to a column in another table. This is where constraints come in. As Jason showed you in the video, in addition to constraints, you can also set a default value for the column if no data is passed to it via the default keyword on the column.\",\n",
       " nan,\n",
       " 'There are several ways to perform an insert with SQLAlchemy; however, we are going to focus on the one that follows the same pattern as the select statement. It uses an insert statement where you specify the table as an argument, and supply the data you wish to insert into the value via the .values() method as keyword arguments. Here, the name of the table is data.',\n",
       " nan,\n",
       " \"It's time to practice inserting multiple records at once! As Jason showed you in the video, you'll want to first build a list of dictionaries that represents the data you want to insert. Then, in the .execute() method, you can pair this list of dictionaries with an insert statement, which will insert all the records in your list of dictionaries.\",\n",
       " nan,\n",
       " \"You've done a great job so far at inserting data into tables! You're now going to learn how to load the contents of a CSV file into a table. We have used the csv module to set up a csv_reader, which is just a reader object that can iterate over the lines in a given CSV file - in this case, a census CSV file. Using the enumerate()function, you can loop over the csv_reader to handle the results one at a time. Here, for example, the first line it would return is: 0 ['Illinois', 'M', '0', '89600', '95012'] 0 is the idx - or line number - while ['Illinois', 'M', '0', '89600', '95012'] is the row, corresponding to the column names 'state' , 'sex', 'age', 'pop2000 'and 'pop2008'. 'Illinois' can be accessed with row[0], 'M' with row[1], and so on. You can create a dictionary containing this information where the keys are the column names and the values are the entries in each line. Then, by appending this dictionary to a list, you can combine it with an insert statement to load it all into a table!\",\n",
       " nan,\n",
       " \"The update statement is very similar to an insert statement, except that it also typically uses a where clause to help us determine what data to update. You'll be using the FIPS state code using here, which is appropriated by the U.S. government to identify U.S. states and certain other associated areas. Recall that you can update all wages in the employees table as follows: stmt = update(employees).values(wage=100.00)\",\n",
       " 'For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), name(Column), and fips_state (Column).',\n",
       " nan,\n",
       " \"As Jason discussed in the video, by using a where clause that selects more records, you can update multiple records at once. It's time now to practice this! For your convenience, the names of the tables and columns of interest in this exercise are: state_fact (Table), notes(Column), and census_region_name (Column).\",\n",
       " nan,\n",
       " \"You can also update records with data from a select statement. This is called a correlated update. It works by defining a selectstatement that returns the value you want to update the record with and assigning that as the value in an update statement. You'll be using a flat_census in this exercise as the target of your correlated update. The flat_census table is a summarized copy of your census table.\",\n",
       " nan,\n",
       " \"Often, you'll need to empty a table of all of its records so you can reload the data. You can do this with a delete statement with just the table as an argument. For example, in the video, Jason deleted the table extra_employees by executing as follows: delete_stmt = delete(census) result_proxy = connection.execute(delete_stmt)\",\n",
       " 'Do be careful, though, as deleting cannot be undone!',\n",
       " nan,\n",
       " 'By using a where() clause, you can target the deletestatement to remove only certain records. For example, Jason deleted all columns from the employees table that had id 3 with the following delete statement: delete(employees).where(employees.columns.id == 3)',\n",
       " \"Here you'll delete ALL rows which have 'M' in the sexcolumn and 36 in the age column. We have included code at the start which computes the total number of these rows. It is important to make sure that this is the number of rows that you actually delete.\",\n",
       " nan,\n",
       " \"You're now going to practice dropping individual tables from a database with the .drop() method, as well as all tables in a database with the .drop_all() method! As Spider-Man's Uncle Ben (as well as Jason, in the video!) said: With great power, comes great responsibility. Do be careful when deleting tables, as it's not simple or fast to restore large databases! Remember, you can check to see if a table exists with the .exists() method. This is the final exercise in this chapter: After this, you'll be ready to apply everything you've learned to a case study in the final chapter of this course!\",\n",
       " nan,\n",
       " 'In this exercise, your job is to create an engine to the database that will be used in this chapter. Then, you need to initialize its metadata. Recall how you did this in Chapter 1 by leveraging create_engine() and MetaData.',\n",
       " nan,\n",
       " 'Having setup the engine and initialized the metadata, you will now define the census table object and then create it in the database using using the metadata and engine from the previous exercise. To create it in the database, you will have to use the .create_all() method on the metadata with engine as the argument. It may help to refer back to the Chapter 4 exercise in which you learned how to create a table.',\n",
       " nan,\n",
       " 'Leverage the Python CSV module from the standard library and load the data into a list of dictionaries. It may help to refer back to the Chapter 4 exercise in which you did something similar.',\n",
       " nan,\n",
       " 'Using the multiple insert pattern, in this exercise, you will load the data from values_list into the table.',\n",
       " nan,\n",
       " \"In this exercise, you will use the func.sum() and group_by()methods to first determine the average age weighted by the population in 2008, and then group by sex. As Jason discussed in the video, a weighted average is calculated as the sum of the product of the weights and averages divided by the sum of all the weights. For example, the following statement determines the average age weighted by the population in 2000: stmt = select([census.columns.sex, (func.sum(census.columns.pop2000 * census.columns.age) / func.sum(census.columns.pop2000)).label('average_age') ])\",\n",
       " nan,\n",
       " 'In this exercise, you will write a query to determine the percentage of the population in 2000 that comprised of women. You will group this query by state.',\n",
       " nan,\n",
       " 'In this final exercise, you will write a query to calculate the states that changed the most in population. You will limit your query to display only the top 10 states.',\n",
       " nan,\n",
       " \"You're no novice to data science, but let's make sure we agree on the basics. As Peter from DrivenData explained in the video, you're going to be working with school district budget data. This data can be classified in many ways according to certain labels, e.g. Function: Career & Academic Counseling, or Position_Type: Librarian. Your goal is to develop a model that predicts the probability for each possible label by relying on some correctly labeled examples. What type of machine learning problem is this? ANSWER THE QUESTION 50XP\",\n",
       " 'Reinforcement Learning, because the model is learning from the data through a system of rewards and punishments.',\n",
       " 'As you know from previous courses, there are different types of supervised machine learning problems. In this exercise you will tell us what type of supervised machine learning problem this is, and why you think so. Remember, your goal is to correctly label budget line items by training a supervised model to predict the probability of each possible label, taking most probable label as the correct label.',\n",
       " 'Classification, because predicted probabilities will be used to select a label class.',\n",
       " \"Now it's time to check out the dataset! You'll use pandas (which has been pre-imported as pd) to load your data into a DataFrame and then do some Exploratory Data Analysis (EDA) of it. The training data is available as TrainingData.csv. Your first task is to load it into a DataFrame in the IPython Shell using pd.read_csv() along with the keyword argument index_col=0. Use methods such as .info(), .head(), and .tail() to explore the budget data and the properties of the features and labels. Some of the column names correspond to features - descriptions of the budget items - such as the Job_Title_Description column. The values in this column tell us if a budget item is for a teacher, custodian, or other employee. Some columns correspond to the budget item labels you will be trying to predict with your model. For example, the Object_Type column describes whether the budget item is related classroom supplies, salary, travel expenses, etc. Use df.info() in the IPython Shell to answer the following questions: How many rows are there in the training data? How many columns are there in the training data? How many non-null entries are in the Job_Title_Description column?\",\n",
       " '1560 rows, 25 columns, 1131 non-null entries in Job_Title_Description.',\n",
       " 'You\\'ll continue your EDA in this exercise by computing summary statistics for the numeric data in the dataset. The data has been pre-loaded into a DataFrame called df. You can use df.info() in the IPython Shell to determine which columns of the data are numeric, specifically type float64. You\\'ll notice that there are two numeric columns, called FTEand Total. FTE: Stands for \"full-time equivalent\". If the budget item is associated to an employee, this number tells us the percentage of full-time that the employee works. A value of 1 means the associated employee works for the schooll full-time. A value close to 0 means the item is associated to a part-time or contracted employee. Total: Stands for the total cost of the expenditure. This number tells us how much the budget item cost. After printing summary statistics for the numeric data, your job is to plot a histogram of the non-null FTE column to see the distribution of part-time and full-time employees in the dataset.',\n",
       " nan,\n",
       " \"It's always good to know what datatypes you're working with, especially when the inefficient pandas type object may be involved. Towards that end, let's explore what we have. The data has been loaded into the workspace as df. Your job is to look at the DataFrame attribute .dtypes in the IPython Shell, and call its .value_counts()method in order to answer the question below. Make sure to call df.dtypes.value_counts(), and not df.value_counts()! Check out the difference in the Shell. df.value_counts() will return an error, because it is a Series method, not a DataFrame method.\",\n",
       " \"Remember, your ultimate goal is to predict the probability that a certain label is attached to a budget line item. You just saw that many columns in your data are the inefficient object type. Does this include the labels you're trying to predict? Let's find out! There are 9 columns of labels in the dataset. Each of these columns is a category that has many possible values it can take). The 9 labels have been loaded into a list called LABELS. In the Shell, check out the type for these labels using df[LABELS].dtypes. You will notice that every label is encoded as an object datatype. Because category datatypes are much more efficient your task is to convert the labels to category types using the .astype()method. Note: .astype() only works on a pandas Series. Since you are working with a pandas DataFrame, you'll need to use the .apply() method and provide a lambda function called categorize_label that applies .astype() to each column, x.\",\n",
       " nan,\n",
       " 'As Peter mentioned in the video, there are over 100 unique labels. In this exercise, you will explore this fact by counting and plotting the number of unique values for each category of label. The dataframe df and the LABELS list have been loaded into the workspace; the LABELS columns of df have been converted to category types. pandas, which has been pre-imported as pd, provides a pd.Series.nunique method for counting the number of unique values in a Series.',\n",
       " nan,\n",
       " \"As Peter explained in the video, log loss provides a steep penalty for predictions that are both wrong and confident, i.e., a high probability is assigned to the incorrect class. Suppose you have the following 3 examples: A:y=1,p=0.85A:y=1,p=0.85 B:y=0,p=0.99B:y=0,p=0.99 C:y=0,p=0.51C:y=0,p=0.51 Select the ordering of the examples which corresponds to the lowest to highest log loss scores. y is an indicator of whether the example was classified correctly. You shouldn't need to crunch any numbers! Lowest: A, Middle: C, Highest: B.\",\n",
       " 'To see how the log loss metric handles the trade-off between accuracy and confidence, we will use some sample data generated with NumPy and compute the log loss using the provided function compute_log_loss(), which Peter showed you in the video. 5 one-dimensional numeric arrays simulating different types of predictions have been pre-loaded: actual_labels, correct_confident, correct_not_confident, wrong_not_confident, and wrong_confident. Your job is to compute the log loss for each sample set provided using the compute_log_loss(predicted_values, actual_values). It takes the predicted values as the first argument and the actual values as the second argument.',\n",
       " nan,\n",
       " \"Alright, you've been patient and awesome. It's finally time to start training models! The first step is to split the data into a training set and a test set. Some labels don't occur very often, but we want to make sure that they appear in both the training and the test sets. We provide a function that will make sure at least min_countexamples of each label appear in each split: multilabel_train_test_split. Feel free to check out the full code for multilabel_train_test_split here. You'll start with a simple model that uses just the numeric columns of your DataFrame when calling multilabel_train_test_split. The data has been read into a DataFrame df and a list consisting of just the numeric columns is available as NUMERIC_COLUMNS.\",\n",
       " nan,\n",
       " \"With split data in hand, you're only a few lines away from training a model. In this exercise, you will import the logistic regression and one versus rest classifiers in order to fit a multi-class logistic regression model to the NUMERIC_COLUMNS of your feature data. Then you'll test and print the accuracy with the .score()method to see the results of training. Before you train! Remember, we're ultimately going to be using logloss to score our model, so don't worry too much about the accuracy here. Keep in mind that you're throwing away all of the text data in the dataset - that's by far most of the data! So don't get your hopes up for a killer performance just yet. We're just interested in getting things up and running at the moment. All data necessary to call multilabel_train_test_split() has been loaded into the workspace.\",\n",
       " nan,\n",
       " 'You\\'re ready to make some predictions! Remember, the train-test-split you\\'ve carried out so far is for model development. The original competition provides an additional test set, for which you\\'ll never actually see the correct labels. This is called the \"holdout data.\" The point of the holdout data is to provide a fair test for machine learning competitions. If the labels aren\\'t known by anyone but DataCamp, DrivenData, or whoever is hosting the competition, you can be sure that no one submits a mere copy of labels to artificially pump up the performance on their model. Remember that the original goal is to predict the probability of each label. In this exercise you\\'ll do just that by using the .predict_proba() method on your trained model. First, however, you\\'ll need to load the holdout data, which is available in the workspace as the file HoldoutData.csv.',\n",
       " nan,\n",
       " \"At last, you're ready to submit some predictions for scoring. In this exercise, you'll write your predictions to a .csv using the .to_csv() method on a pandas DataFrame. Then you'll evaluate your performance according to the LogLoss metric discussed earlier! You'll need to make sure your submission obeys the correct format. To do this, you'll use your predictions values to create a new DataFrame, prediction_df. Interpreting LogLoss & Beating the Benchmark: When interpreting your log loss score, keep in mind that the score will change based on the number of samples tested. To get a sense of how this very basic model performs, compare your score to the DrivenData benchmark model performance: 2.0455, which merely submitted uniform probabilities for each class. Remember, the lower the log loss the better. Is your model's log loss lower than 2.0455?\",\n",
       " nan,\n",
       " 'In this exercise, you\\'ll study the effects of tokenizing in different ways by comparing the bag-of-words representations resulting from different token patterns. You will focus on one feature only, the Position_Extra column, which describes any additional information not captured by the Position_Type label. For example, in the Shell you can check out the budget item in row 8960 of the data using df.loc[8960]. Looking at the output reveals that this Object_Description is overtime pay. For who? The Position Type is merely \"other\", but the Position Extra elaborates: \"BUS DRIVER\". Explore the column further to see more instances. It has a lot of NaN values. Your task is to turn the raw text in this column into a bag-of-words representation by creating tokes that contain onlyalphanumeric characters. For comparison purposes, the first 15 tokens of vec_basic, which splits df.Position_Extra into tokens when it encounters only whitespace characters, have been printed along with the length of the representation.',\n",
       " nan,\n",
       " \"In order to get a bag-of-words representation for all of the text data in our DataFrame, you must first convert the text data in each row of the DataFrame into a single string. In the previous exercise, this wasn't necessary because you only looked at one column of data, so each row was already just a single string. CountVectorizer expects each row to just be a single string, so in order to use all of the text columns, you'll need a method to turn a list of strings into a single string. In this exercise, you'll complete the function definition combine_text_columns(). When completed, this function will convert all training text data in your DataFrame to a single string per row that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method. Note that the function uses NUMERIC_COLUMNS and LABELS to determine which columns to drop. These lists have been loaded into the workspace.\",\n",
       " nan,\n",
       " \"Now you will use combine_text_columns to convert all training text data in your DataFrame to a single vector that can be passed to the vectorizer object and made into a bag-of-words using the .fit_transform() method. You'll compare the effect of tokenizing using any non-whitespace characters as a token and using only alphanumeric characters as a token.\",\n",
       " nan,\n",
       " \"In order to make your life easier as you start to work with all of the data in your original DataFrame, df, it's time to turn to one of scikit-learn's most useful objects: the Pipeline. For the next few exercises, you'll reacquaint yourself with pipelines and train a classifier on some synthetic (sample) data of multiple datatypes before using the same techniques on the main dataset. The sample data is stored in the DataFrame, sample_df, which has three kinds of feature data: numeric, text, and numeric with missing values. It also has a label column with two classes, aand b. In this exercise, your job is to instantiate a pipeline that trains using the numeric column of the sample data.\",\n",
       " nan,\n",
       " \"Here, you'll perform a similar preprocessing pipeline step, only this time you'll use the text column from the sample data. To preprocess the text, you'll turn to CountVectorizer() to generate a bag-of-words representation of the data, as in Chapter 2. Using the default arguments, add a (step, transform) tuple to the steps list in your pipeline. Make sure you select only the text column for splitting your training and test sets. As usual, your sample_df is ready and waiting in the workspace.\",\n",
       " nan,\n",
       " \"The next two exercises will introduce new topics you'll need to make your pipeline truly excel. Any step in the pipeline must be an object that implements the fit and transform methods. The FunctionTransformercreates an object with these methods out of any Python function that you pass to it. We'll use it to help select subsets of data in a way that plays nicely with pipelines. You are working with numeric data that needs imputation, and text data that needs to be converted into a bag-of-words. You'll create functions that separate the text from the numeric variables and see how the .fit() and .transform() methods work.\",\n",
       " nan,\n",
       " \"Now that you can separate text and numeric data in your pipeline, you're ready to perform separate steps on each by nesting pipelines and using FeatureUnion(). These tools will allow you to streamline all preprocessing steps for your model, even when multiple datatypes are involved. Here, for example, you don't want to impute our text data, and you don't want to create a bag-of-words with our numeric data. Instead, you want to deal with these separately and then join the results together using FeatureUnion(). In the end, you'll still have only two high-level steps in your pipeline: preprocessing and model instantiation. The difference is that the first preprocessing step actually consists of a pipeline for numeric data and a pipeline for text data. The results of those pipelines are joined using FeatureUnion().\",\n",
       " nan,\n",
       " \"In this exercise you're going to use FunctionTransformer on the primary budget data, before instantiating a multiple-datatype pipeline in the next exercise. Recall from Chapter 2 that you used a custom function combine_text_columns to select and properly format text datafor tokenization; it is loaded into the workspace and ready to be put to work in a function transformer! Concerning the numeric data, you can use NUMERIC_COLUMNS, preloaded as usual, to help design a subset-selecting lambda function. You're all finished with sample data. The original df is back in the workspace, ready to use.\",\n",
       " nan,\n",
       " \"You're about to take everything you've learned so far and implement it in a Pipeline that works with the real, DrivenData budget line item data you've been exploring. Surprise! The structure of the pipeline is exactly the same as earlier in this chapter: the preprocessing step uses FeatureUnion to join the results of nested pipelines that each rely on FunctionTransformer to select multiple datatypes the model step stores the model object You can then call familiar methods like .fit() and .score()on the Pipeline object pl.\",\n",
       " nan,\n",
       " \"Now you're cruising. One of the great strengths of pipelines is how easy they make the process of testing different models. Until now, you've been using the model step ('clf', OneVsRestClassifier(LogisticRegression())) in your pipeline. But what if you want to try a different model? Do you need to build an entirely new pipeline? New nests? New FeatureUnions? Nope! You just have a simple one-line change, as you'll see in this exercise. In particular, you'll swap out the logistic-regression model and replace it with a random forest classifier, which uses the statistics of an ensemble of decision trees to generate predictions.\",\n",
       " nan,\n",
       " 'You just saw a substantial improvement in accuracy by swapping out the model. Pipelines are amazing! Can you make it better? Try changing the parameter n_estimators of RandomForestClassifier(), whose default value is 10, to 15.',\n",
       " nan,\n",
       " \"Recall from previous chapters that how you tokenize text affects the n-gram statistics used in your model. Going forward, you'll use alpha-numeric sequences, and only alpha-numeric sequences, as tokens. Alpha-numeric tokens contain only letters a-z and numbers 0-9 (no other characters). In other words, you'll tokenize on punctuation to generate n-gram statistics. In this exercise, you'll make sure you remember how to tokenize on punctuation. Assuming we tokenize on punctuation, accepting only alpha-numeric sequences as tokens, how many tokens are in the following string from the main dataset? 'PLANNING,RES,DEV,& EVAL '\",\n",
       " \"If you want, we've loaded this string into the workspace as SAMPLE_STRING, but you may not need it to answer the question.\",\n",
       " '4, because , and & are not tokens',\n",
       " \"Before you build up to the winning pipeline, it will be useful to look a little deeper into how the text features will be processed. In this exercise, you will use CountVectorizer on the training data X_train (preloaded into the workspace) to see the effect of tokenization on punctuation. Remember, since CountVectorizer expects a vector, you'll need to use the preloaded function, combine_text_columns before fitting to the training data.\",\n",
       " nan,\n",
       " 'In this exercise you\\'ll insert a CountVectorizer instance into your pipeline for the main dataset, and compute multiple n-gram features to be used in the model. In order to look for ngram relationships at multiple scales, you will use the ngram_range parameter as Peter discussed in the video. Special functions: You\\'ll notice a couple of new steps provided in the pipeline in this and many of the remaining exercises. Specifically, the dim_red step following the vectorizer step , and the scale step preceeding the clf (classification) step. These have been added in order to account for the fact that you\\'re using a reduced-size sample of the full dataset in this course. To make sure the models perform as the expert competition winner intended, we have to apply a dimensionality reduction technique, which is what the dim_red step does, and we have to scale the features to lie between -1 and 1, which is what the scale step does. The dim_red step uses a scikit-learn function called SelectKBest(), applying something called the chi-squared testto select the K \"best\" features. The scale step uses a scikit-learn function called MaxAbsScaler() in order to squash the relevant features into the interval -1 to 1. You won\\'t need to do anything extra with these functions here, just complete the vectorizing pipeline steps below. However, notice how easy it was to add more processing steps to our pipeline!',\n",
       " nan,\n",
       " 'Recall from the video that interaction terms involve products of features. Suppose we have two features x and y, and we use models that process the features as follows: Î²x + Î²y + Î²Î² Î²xy + Î²x + Î²y Î²x + Î²y + Î²x^2 + Î²y^2 where Î² is a coefficient in your model (not a feature). Which expression(s) include interaction terms?',\n",
       " 'The second expression',\n",
       " \"It's time to add interaction features to your model. The PolynomialFeatures object in scikit-learn does just that, but here you're going to a custom interaction object, SparseInteractions. Interaction terms are a statistical tool that lets your model express what happens if two features appear together in the same row. SparseInteractions does the same thing as PolynomialFeatures, but it uses sparse matrices to do so. You can get the code for SparseInteractions at this GitHub Gist. PolynomialFeatures and SparseInteractions both take the argument degree, which tells them what polynomia degree of interactions to compute. You're going to consider interaction terms of degree=2 in your pipeline. You will insert these steps after the preprocessing steps you've built out so far, but before the classifier steps. Pipelines with interaction terms take a while to train (since you're making n features into n-squared features!), so as long as you set it up right, we'll do the heavy lifting and tell you what your score is!\",\n",
       " nan,\n",
       " \"In the video, Peter explained that a hash function takes an input, in your case a token, and outputs a hash value. For example, the input may be a string and the hash value may be an integer. We've loaded a familiar python datatype, a dictionary called hash_dict, that makes this mapping concept a bit more explicit. In fact, python dictionaries ARE hash tables! Print hash_dict in the IPython Shell to get a sense of how strings can be mapped to integers. By explicitly stating how many possible outputs the hashing function may have, we limit the size of the objects that need to be processed. With these limits known, computation can be made more efficient and we can get results faster, even on large datasets. Using the above information, answer the following: Why is hashing a useful trick?\",\n",
       " 'Some problems are memory-bound and not easily parallelizable, and hashing enforces a fixed length computation instead of using a mutable datatype (like a dictionary).',\n",
       " 'In this exercise you will check out the scikit-learn implementation of HashingVectorizer before adding it to your pipeline later. As you saw in the video, HashingVectorizer acts just like CountVectorizer in that it can accept token_pattern and ngram_range parameters. The important difference is that it creates hash values from the text, so that we get all the computational advantages of hashing!',\n",
       " nan,\n",
       " \"You have arrived! This is where all of your hard work pays off. It's time to build the model that won DrivenData's competition. You've constructed a robust, powerful pipeline capable of processing training and testing data. Now that you understand the data and know all of the tools you need, you can essentially solve the whole problem in a relatively small number of lines of code. Wow! All you need to do is add the HashingVectorizer step to the pipeline to replace the CountVectorizer step. The parameters non_negative=True, norm=None, andbinary=False make the HashingVectorizer perform similarly to the default settings on the CountVectorizer so you can just replace one with the other.\",\n",
       " nan,\n",
       " nan,\n",
       " \"Create a list of file names called filenames with three strings 'Gold.csv', 'Silver.csv', & 'Bronze.csv'. This has been done for you. Use a for loop to create another list called dataframescontaining the three DataFrames loaded from filenames: Iterate over filenames. Read each CSV file in filenames into a DataFrame and append it to dataframes by using pd.read_csv()inside a call to .append(). Print the first 5 rows of the first DataFrame of the list dataframes. This has been done for you, so hit 'Submit Answer' to see the results.\",\n",
       " nan,\n",
       " \"Construct a copy of the DataFrame gold called medalsusing the .copy() method. Create a list called new_labels with entries 'NOC', 'Country', & 'Gold'. This is the same as the column labels from gold with the column label 'Total' replaced by 'Gold'. Rename the columns of medals by assigning new_labelsto medals.columns. Create new columns 'Silver' and 'Bronze' in medalsusing silver['Total'] & bronze['Total']. Print the top 5 rows of the final DataFrame medals. This has been done for you, so hit 'Submit Answer' to see the result!\",\n",
       " nan,\n",
       " \"Read 'monthly_max_temp.csv' into a DataFrame called weather1with 'Month' as the index. Sort the index of weather1 in alphabetical order using the .sort_index() method and store the result in weather2. Sort the index of weather1 in reverse alphabetical order by specifying the additional keyword argument ascending=False inside .sort_index(). Use the .sort_values() method to sort weather1 in increasing numerical order according to the values of the column 'Max TemperatureF'.\",\n",
       " nan,\n",
       " 'Reorder the rows of weather1 using the .reindex() method with the list year as the argument, which contains the abbreviations for each month. Reorder the rows of weather1 just as you did above, this time chaining the .ffill() method to replace the null values with the last preceding non-null value.',\n",
       " nan,\n",
       " 'As you can see by looking at their shapes, which have been printed in the IPython Shell, the DataFrame corresponding to 1981 births is much larger, reflecting the greater diversity of names in 1981 as compared to 1881. Your job here is to use the DataFrame .reindex() and .dropna() methods to make a DataFrame common_names counting names from 1881 that were still popular in 1981.',\n",
       " \"Create a new DataFrame common_names by reindexing names_1981using the Index of the DataFrame names_1881 of older names. Print the shape of the new common_names DataFrame. This has been done for you. It should be the same as that of names_1881. Drop the rows of common_names that have null counts using the .dropna() method. These rows correspond to names that fell out of fashion between 1881 & 1981. Print the shape of the reassigned common_names DataFrame. This has been done for you, so hit 'Submit Answer' to see the result!\",\n",
       " nan,\n",
       " \"Create a new DataFrame temps_f by extracting the columns 'Min TemperatureF', 'Mean TemperatureF', & 'Max TemperatureF' from weather as a new DataFrame temps_f. To do this, pass the relevant columns as a list to weather[]. Create a new DataFrame temps_c from temps_f using the formula (temps_f - 32) * 5/9. Rename the columns of temps_c to replace 'F' with 'C' using the .str.replace('F', 'C') method on temps_c.columns. Print the first 5 rows of DataFrame temps_c. This has been done for you, so hit 'Submit Answer' to see the result!\",\n",
       " nan,\n",
       " \"Read the file 'GDP.csv' into a DataFrame called gdp. Use parse_dates=True and index_col='DATE'. Create a DataFrame post2008 by slicing gdp such that it comprises all rows from 2008 onward. Print the last 8 rows of the slice post2008. This has been done for you. This data has quarterly frequency so the indices are separated by three-month intervals. Create the DataFrame yearly by resampling the slice post2008 by year. Remember, you need to chain .resample() (using the alias 'A' for annual frequency) with some kind of aggregation; you will use the aggregation method .last() to select the last element when resampling. Compute the percentage growth of the resampled DataFrame yearlywith .pct_change() * 100.\",\n",
       " 'In this exercise, stock prices in US Dollars for the S&P 500 in 2015 have been obtained from Yahoo Finance. The files sp500.csv for sp500 and exchange.csv for the exchange rates are both provided to you. Using the daily exchange rate to Pounds Sterling, your task is to convert both the Open and Close column prices.',\n",
       " \"Read the DataFrames sp500 & exchange from the files 'sp500.csv' & 'exchange.csv' respectively.. Use parse_dates=True and index_col='Date'. Extract the columns 'Open' & 'Close' from the DataFrame sp500as a new DataFrame dollars and print the first 5 rows. Construct a new DataFrame pounds by converting US dollars to British pounds. You'll use the .multiply() method of dollars with exchange['GBP/USD'] and axis='rows' Print the first 5 rows of the new DataFrame pounds. This has been done for you, so hit 'Submit Answer' to see the results!.\",\n",
       " \"In this exercise, you'll load sales data from the months January, February, and March into DataFrames. Then, you'll extract Series with the 'Units' column from each and append them together with method chaining using .append(). To check that the stacking worked, you'll print slices from these Series, and finally, you'll add the result to figure out the total units sold in the first quarter.\",\n",
       " \"Read the files 'sales-jan-2015.csv', 'sales-feb-2015.csv' and 'sales-mar-2015.csv' into the DataFrames jan, feb, and marrespectively. Use parse_dates=True and index_col='Date'. Extract the 'Units' column of jan, feb, and mar to create the Series jan_units, feb_units, and mar_units respectively. Construct the Series quarter1 by appending feb_units to jan_units and then appending mar_units to the result. Use chained calls to the .append() method to do this. Verify that quarter1 has the individual Series stacked vertically. To do this: Print the slice containing rows from jan 27, 2015 to feb 2, 2015. Print the slice containing rows from feb 26, 2015 to mar 7, 2015. Compute and print the total number of units sold from the Series quarter1. This has been done for you, so hit 'Submit Answer' to see the result!\",\n",
       " \"Having learned how to append Series, you'll now learn how to achieve the same result by concatenating Series instead. You'll continue to work with the sales data you've seen previously. This time, the DataFrames jan, feb, and mar have been pre-loaded. Your job is to use pd.concat() with a list of Series to achieve the same result that you would get by chaining calls to .append(). You may be wondering about the difference between pd.concat() and pandas' .append() method. One way to think of the difference is that .append() is a specific case of a concatenation, while pd.concat() gives you more flexibility, as you'll see in later exercises.\",\n",
       " nan,\n",
       " \"In this exercise, you'll use the Baby Names Dataset (from data.gov) again. This time, both DataFrames names_1981 and names_1881 are loaded without specifying an Index column (so the default Indexes for both are RangeIndexes). You'll use the DataFrame .append() method to make a DataFrame combined_names. To distinguish rows from the original two DataFrames, you'll add a 'year' column to each with the year (1881 or 1981 in this case). In addition, you'll specify ignore_index=True so that the index values are not used along the concatenation axis. The resulting axis will instead be labeled 0, 1, ..., n-1, which is useful if you are concatenating objects where the concatenation axis does not have meaningful indexing information. INSTRUCTIONS 100XP\",\n",
       " nan,\n",
       " \"The function pd.concat() can concatenate DataFrames horizontally as well as vertically (vertical is the default). To make the DataFrames stack horizontally, you have to specify the keyword argument axis=1 or axis='columns'. In this exercise, you'll use weather data with maximum and mean daily temperatures sampled at different rates (quarterly versus monthly). You'll concatenate the rows of both and see that, where rows are missing in the coarser DataFrame, null values are inserted in the concatenated DataFrame. This corresponds to an outer join (which you will explore in more detail in later exercises). The files 'quarterly_max_temp.csv' and 'monthly_mean_temp.csv' have been pre-loaded into the DataFrames weather_max and weather_mean respectively, and pandas has been imported as pd.\",\n",
       " nan,\n",
       " \"It is often convenient to build a large DataFrame by parsing many files as DataFrames and concatenating them all at once. You'll do this here with three files, but, in principle, this approach can be used to combine data from dozens or hundreds of files. Here, you'll work with DataFrames compiled from The Guardian's Olympic medal dataset. pandas has been imported as pd and two lists have been pre-loaded: An empty list called medals, and medal_types, which contains the strings 'bronze', 'silver', and 'gold'.\",\n",
       " nan,\n",
       " \"When stacking a sequence of DataFrames vertically, it is sometimes desirable to construct a MultiIndex to indicate the DataFrame from which each row originated. This can be done by specifying the keys parameter in the call to pd.concat(), which generates a hierarchical index with the labels from keysas the outermost index label. So you don't have to rename the columns of each DataFrame as you load it. Instead, only the Index column needs to be specified. Here, you'll continue working with DataFrames compiled from The Guardian's Olympic medal dataset. Once again, pandashas been imported as pd and two lists have been pre-loaded: An empty list called medals, and medal_types, which contains the strings 'bronze', 'silver', and 'gold'.\",\n",
       " nan,\n",
       " \"This exercise picks up where the last ended (again using The Guardian's Olympic medal dataset). You are provided with the MultiIndexed DataFrame as produced at the end of the preceding exercise. Your task is to sort the DataFrame and to use the pd.IndexSlice to extract specific slices. Check out this exercise from Manipulating DataFrames with pandas to refresh your memory on how to deal with MultiIndexed DataFrames. pandas has been imported for you as pd and the DataFrame medals is already in your namespace.\",\n",
       " nan,\n",
       " \"It is also possible to construct a DataFrame with hierarchically indexed columns. For this exercise, you'll start with pandas imported and a list of three DataFrames called dataframes. All three DataFrames contain 'Company', 'Product', and 'Units' columns with a 'Date' column as the index pertaining to sales transactions during the month of February, 2015. The first DataFrame describes Hardware transactions, the second describes Software transactions, and the third, Service transactions. Your task is to concatenate the DataFrames horizontally and to create a MultiIndex on the columns. From there, you can summarize the resulting DataFrame and slice some information from it.\",\n",
       " nan,\n",
       " \"Construct a new DataFrame february with MultiIndexed columns by concatenating the list dataframes. Use axis=1 to stack the DataFrames horizontally and the keyword argument keys=['Hardware', 'Software', 'Service'] to construct a hierarchical Index from each DataFrame. Print summary information from the new DataFrame february using the .info() method. This has been done for you. Create an alias called idx for pd.IndexSlice. Extract a slice called slice_2_8 from february (using .loc[] & idx) that comprises rows between Feb. 2, 2015 to Feb. 8, 2015 from columns under 'Company'. Print the slice_2_8. This has been done for you, so hit 'Submit Answer' to see the sliced data!\",\n",
       " \"You're now going to revisit the sales data you worked with earlier in the chapter. Three DataFrames jan, feb, and mar have been pre-loaded for you. Your task is to aggregate the sum of all sales over the 'Company' column into a single DataFrame. You'll do this by constructing a dictionary of these DataFrames and then concatenating them.\",\n",
       " nan,\n",
       " \"Here, you'll continue working with DataFrames compiled from The Guardian's Olympic medal dataset. The DataFrames bronze, silver, and gold have been pre-loaded for you. Your task is to compute an inner join.\",\n",
       " nan,\n",
       " \"In this exercise, you'll compare the historical 10-year GDP (Gross Domestic Product) growth in the US and in China. The data for the US starts in 1947 and is recorded quarterly; by contrast, the data for China starts in 1966 and is recorded annually. You'll need to use a combination of resampling and an inner join to align the index labels. You'll need an appropriate offset aliasfor resampling, and the method .resample() must be chained with some kind of aggregation method (.pct_change() and .last() in this case). pandas has been imported as pd, and the DataFrames china and us have been pre-loaded, with the output of china.head() and us.head() printed in the IPython Shell.\",\n",
       " nan,\n",
       " 'This exercise follows on the last one with the DataFrames revenue and managers for your company. You expect your company to grow and, eventually, to operate in cities with the same name on different states. As such, you decide that every branch should have a numerical branch identifier. Thus, you add a branch_id column to both DataFrames. Moreover, new cities have been added to both the revenue and managersDataFrames as well. pandas has been imported as pd and both DataFrames are available in your namespace. At present, there should be a 1-to-1 relationship between the city and branch_id fields. In that case, the result of a merge on the city columns ought to give you the same output as a merge on the branch_id columns. Do they? Can you spot an ambiguity in one of the DataFrames?',\n",
       " nan,\n",
       " \"You continue working with the revenue & managersDataFrames from before. This time, someone has changed the field name 'city' to 'branch' in the managers table. Now, when you attempt to merge DataFrames, an exception is thrown:\",\n",
       " \"pd.merge(revenue, managers, on='city') Traceback (most recent call last): ... ... pd.merge(revenue, managers, on='city') ... ... KeyError: 'city'\",\n",
       " 'Given this, it will take a bit more work for you to join or merge on the city/branch name. You have to specify the left_on and right_on parameters in the call to pd.merge(). As before, pandas has been pre-imported as pd and the revenue and managers DataFrames are in your namespace. They have been printed in the IPython Shell so you can examine the columns prior to merging. Are you able to merge better than in the last exercise? How should the rows with Springfield be handled?',\n",
       " nan,\n",
       " \"Another strategy to disambiguate cities with identical names is to add information on the states in which the cities are located. To this end, you add a column called state to both DataFrames from the preceding exercises. Again, pandas has been pre-imported as pd and the revenue and managers DataFrames are in your namespace. Your goal in this exercise is to use pd.merge() to merge DataFrames using multiple columns (using 'branch_id', 'city', and 'state' in this case). Are you able to match all your company's branches correctly?\",\n",
       " nan,\n",
       " 'return 5 rows with index labels [10, 20, 30, 31, 47]',\n",
       " \"revenue.join(managers, lsuffix='_rev', rsuffix='_mng', how='outer')\",\n",
       " \"Suppose you have two DataFrames: students (with columns 'StudentID', 'LastName', 'FirstName', and 'Major') and midterm_results (with columns 'StudentID', 'Q1', 'Q2', and 'Q3' for their scores on midterm questions). You want to combine the DataFrames into a single DataFrame grades, and be able to easily spot which students wrote the midterm and which didn't (their midterm question scores 'Q1', 'Q2', & 'Q3' should be filled with NaN values). You also want to drop rows from midterm_results in which the StudentID is not found in students. Which of the following strategies gives the desired result? A left join: grades = pd.merge(students, midterm_results, how='left').\",\n",
       " \"You now have, in addition to the revenue and managersDataFrames from prior exercises, a DataFrame sales that summarizes units sold from specific branches (identified by city and state but not branch_id). Once again, the managers DataFrame uses the label branch in place of city as in the other two DataFrames. Your task here is to employ left and right merges to preserve data and identify where data is missing. By merging revenue and sales with a right merge, you can identify the missing revenue values. Here, you don't need to specify left_on or right_on because the columns to merge on have matching labels. By merging sales and managers with a left merge, you can identify the missing manager. Here, the columns to merge on have conflicting labels, so you must specify left_on and right_on. In both cases, you're looking to figure out how to connect the fields in rows containing Springfield. pandas has been imported as pd and the three DataFrames revenue, managers, and sales have been pre-loaded. They have been printed for you to explore in the IPython Shell.\",\n",
       " nan,\n",
       " 'This exercise picks up where the previous one left off. The DataFrames revenue, managers, and sales are pre-loaded into your namespace (and, of course, pandas is imported as pd). Moreover, the merged DataFrames revenue_and_salesand sales_and_managers have been pre-computed exactly as you did in the previous exercise. The merged DataFrames contain enough information to construct a DataFrame with 5 rows with all known information correctly aligned and each branch listed only once. You will try to merge the merged DataFrames on all matching keys (which computes an inner join by default). You can compare the result to an outer join and also to an outer join with restricted subset of columns as keys.',\n",
       " nan,\n",
       " \"This exercise uses pre-loaded DataFrames austin and houston that contain weather data from the cities Austin and Houston respectively. They have been printed in the IPython Shell for you to examine. Weather conditions were recorded on separate days and you need to merge these two DataFrames together such that the dates are ordered. To do this, you'll use pd.merge_ordered(). After you're done, note the order of the rows before and after merging.\",\n",
       " nan,\n",
       " \"Similar to pd.merge_ordered(), the pd.merge_asof()function will also merge values in order using the on column, but for each row in the left DataFrame, only rows from the right DataFrame whose 'on' column values are less than the left value will be kept. This function can be use to align disparate datetime frequencies without having to first resample. Here, you'll merge monthly oil prices (US dollars) into a full automobile fuel efficiency dataset. The oil and automobile DataFrames have been pre-loaded as oil and auto. The first 5 rows of each have been printed in the IPython Shell for you to explore. These datasets will align such that the first price of the year will be broadcast into the rows of the automobiles DataFrame. This is considered correct since by the start of any given year, most automobiles for that year will have already been manufactured. You'll then inspect the merged DataFrame, resample by year and compute the mean 'Price' and 'mpg'. You should be able to see a trend in these two columns, that you can confirm by computing the Pearson correlation between resampled 'Price' and 'mpg'.\",\n",
       " nan,\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions = []\n",
    "for index, row in df[df_1].iterrows():\n",
    "    if True:\n",
    "        #print(row['Questions'])\n",
    "        instructions.append(row['Questions'])\n",
    "instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb09df0e-8151-4819-9a32-7927e5166e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = pd.DataFrame(instructions).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45fee6f2-0224-4cb4-b60a-d8ac33cc20d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Import pandas as pd. Read 'dob_job_application...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Print the info of df. Print the info of the su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Print the value counts for: The 'Borough' colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Import matplotlib.pyplot as plt. Create a hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Using the .boxplot() method of df, create a bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Using df, create a scatter plot (kind='scatter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Print the head of airquality. Use pd.melt() to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Print the head of airquality. Melt the Ozone, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Print the head of airquality_melt. Pivot airqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Print the index of airquality_pivot by accessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pivoting duplicate values 0xp So far, you've u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Melt tb keeping 'country' and 'year' fixed. Cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Melt ebola using 'Date' and 'Day' as the id_va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Concatenate uber1, uber2, and uber3 together u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Concatenate ebola_melt and status_country colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Import the glob module along with pandas (as i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Write a for loop to iterate though csv_files: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Merge the site and visited DataFrames on the '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Merge the site and visited DataFrames on the '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Merge the site and visited DataFrames on the '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Convert the sex column of the tips DataFrame t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Use pd.to_numeric() to convert the 'total_bill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Import re. Compile a pattern that matches a ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Import re. Write a pattern that will find all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Write patterns to match: A telephone number of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Define a function named recode_sex() that has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>df.apply(my_square)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>The equivalent code using a lambda function is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>The lambda function takes one parameter - the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Use the .replace() method inside a lambda func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Create a new DataFrame called tracks that cont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Calculate the mean of the Ozone column of airq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Write an assert statement to confirm that ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Each data point is a customer. The first input...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Calculate the value in node 0 by multiplying i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Fill in the definition of the relu() function:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Define a function called predict_with_network(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Calculate node_0_0_input using its weights wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Create a dictionary of weights called weights_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Import mean_squared_error from sklearn.metrics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Calculate the predictions, preds, by multiplyi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Set the learning rate to be 0.01 and calculate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Using a for loop to iteratively update weights...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Store the number of columns in the predictors ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Compile the model using model.compile(). Your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Fit the model. Remember that the first argumen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Convert df.survived to a categorical variable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Create your predictions using the model's .pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Import SGD from keras.optimizers. Create a lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Compile your model using 'adam' as the optimiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Import EarlyStopping from keras.callbacks. Com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Create model_2 to replicate model_1, but use 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Specify a model called model_2 that is like mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Create a Sequential object to start your model...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Open the file moby_dick.txt as read-only and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>While still within this construct, the variabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>You'll now use these tools to print the first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>Open moby_dick.txt using the with context mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>Fill in the arguments of np.loadtxt() by passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>Complete the arguments of np.loadtxt(): the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>Complete the first call to np.loadtxt() by pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>## Working with mixed datatypes (1) 50xp Much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Here, the first argument is the filename, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Import titanic.csv using the function np.recfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Import the pandas package using the alias pd. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>##Using pandas to import flat files as DataFra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Import the first 5 rows of the file into a Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Complete the sep (the pandas version of delim)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Import the pickle package. Complete the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Assign the filename to the variable file. Pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Load the sheet '2004' into the DataFrame df1 u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Parse the first sheet by index. In doing so, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>The data are adapted from the website of the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Import the module SAS7BDAT from the library sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Use pd.read_stata() to load the file 'disarea....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Import the package h5py. Assign the name of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Assign the HDF5 group data['strain'] to group....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Import the package scipy.io. Load the file 'al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Once again, this file contains gene expression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Use the method .keys() on the dictionary mat t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Here, 'sqlite:///Northwind.sqlite' is called t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Import the function create_engine from the mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Import the function create_engine from the mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>Open the engine connection as con using the me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>with engine.connect() as con: rs = con.execute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Packages have already been imported as follows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>The engine has also already been created: engi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>The engine connection is already open with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>All the code you need to complete is within th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Execute the SQL query that selects the columns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>In fact, you can filter any SELECT statement b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Query away!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Complete the argument of create_engine() so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>In fact, you can order any SELECT statement by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Get querying!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Using the function create_engine(), create an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Using the function create_engine(), create an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>The following code has already been executed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Assign to rs the results from the following qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>The following code has already been executed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Use the pandas function read_sql_query() to as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Open the file moby_dick.txt as read-only and s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>While still within this construct, the variabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>You'll now use these tools to print the first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Open moby_dick.txt using the with context mana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Fill in the arguments of np.loadtxt() by passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Complete the arguments of np.loadtxt(): the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Complete the first call to np.loadtxt() by pas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>## Working with mixed datatypes (1) 50xp Much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Here, the first argument is the filename, the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Import titanic.csv using the function np.recfr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Import the pandas package using the alias pd. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>##Using pandas to import flat files as DataFra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Import the first 5 rows of the file into a Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Complete the sep (the pandas version of delim)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Import the pickle package. Complete the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Assign the filename to the variable file. Pass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Load the sheet '2004' into the DataFrame df1 u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>Parse the first sheet by index. In doing so, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>The data are adapted from the website of the u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Import the module SAS7BDAT from the library sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>Use pd.read_stata() to load the file 'disarea....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>Import the package h5py. Assign the name of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Assign the HDF5 group data['strain'] to group....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Import the package scipy.io. Load the file 'al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Once again, this file contains gene expression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Use the method .keys() on the dictionary mat t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Here, 'sqlite:///Northwind.sqlite' is called t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Import the function create_engine from the mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Import the function create_engine from the mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Open the engine connection as con using the me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>with engine.connect() as con: rs = con.execute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Packages have already been imported as follows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>The engine has also already been created: engi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>The engine connection is already open with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>All the code you need to complete is within th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Execute the SQL query that selects the columns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>In fact, you can filter any SELECT statement b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Query away!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Complete the argument of create_engine() so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>In fact, you can order any SELECT statement by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Get querying!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Using the function create_engine(), create an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Using the function create_engine(), create an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>The following code has already been executed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Assign to rs the results from the following qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>The following code has already been executed t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Use the pandas function read_sql_query() to as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>After you import it, you'll check your working...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Import the function urlretrieve from the subpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>Assign the URL of the file to the variable url...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Your job is to use pd.read_excel() to read in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Assign the URL of the file to the variable url...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Import the functions urlopen and Request from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>Send the request and catch the response in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Import the package requests. Assign the URL of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Import the function BeautifulSoupfrom the pack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>In the sample code, the HTML response object h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Use the method find_all() to find all hyperlin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Load the JSON 'a_movie.json' into the variable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Import the requests package. Assign to the var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Pass the variable url to the requests.get() fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Assign the relevant URL to the variable url. A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>Import the package tweepy. Pass the parameters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>Create your Stream object with authentication ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>Assign the filename 'tweets.txt' to the variab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Use pd.DataFrame() to construct a DataFrame of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>def word_in_text(word, tweet): word = word.low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>You're going to iterate over the rows of the D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Within the for loop for index, row in df.iterr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Import both matplotlib.pyplot and seaborn usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>In this example, you're going to make a scatte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>By calling multiple glyph functions on the sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>The three most important arguments to customiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>We can draw lines on Bokeh plots with the line...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Lines and markers can be combined by plotting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>In Bokeh, extended geometrical shapes can be p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>In the previous exercises, you made plots usin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>You can create Bokeh plots from Pandas DataFra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>You can create a ColumnDataSource object direc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>In this exercise, you're going to add the box_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Now let's practice using and customizing the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>The final glyph customization we'll practice i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Layouts are collections of Bokeh figure object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>In this exercise, you're going to use the colu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>You can create nested layouts of plots by comb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Regular grids of Bokeh plots can be generated ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>Tabbed layouts can be created in Pandas by pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Tabbed layouts are collections of Panel object...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Linking axes between plots is achieved by shar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>By sharing the same ColumnDataSource object be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Legends can be added to any glyph by using the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Properties of the legend can be changed by usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>Working with the HoverTool is easy for data st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Let's get started with building an interactive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>In the previous exercise, you added a single p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Having added a single slider in a widgetbox la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Let's begin making a Bokeh application that ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>You'll now learn how to use widget callbacks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>You'll now learn to update the plot's data usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Here, you'll practice using a dropdown callbac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>It's time to practice adding buttons to your i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>You can also get really creative with your But...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Here, you'll continue your Exploratory Data An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>Let's get started on the Gapminder app. Your j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Now that you have the base plot ready, you can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Until now, we've been plotting data only for 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Remember how in the plot from the previous exe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>#Adding a hover tool In this exercise, you'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>As a final step in enhancing your application,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>In the video, you already saw how much the wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>print() the last item from both the year and t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>Print the last item from both the list gdp_cap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>Let's continue with the gdp_cap versus life_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Change the line plot that's coded in the scrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Start from scratch: import matplotlib.pyplot a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Use plt.hist() to create a histogram of the va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>Build a histogram of life_exp, with 5 bins. Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>Build a histogram of life_exp with 15 bins. Bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>The strings xlab and ylab are already set for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>In this example, the ticks corresponding to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>Use tick_val and tick_lab as inputs to the xti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>Run the script to see how the plot changes. Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>Nothing to worry about now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>Add c = col to the arguments of the plt.scatte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>Add plt.grid(True) after the plt.text() calls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>Use the index() method on countries to find th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>In this recipe, both the keys and the values a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>Here, 'france' is the key and 'paris' the valu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>Check out which keys are in europe by calling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>Add the key 'italy' with the value 'rome' to e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>The capital of Germany is not 'bonn'; it's 'be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Use chained square brackets to select and prin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>Import pandas as pd. Use the pre-defined lists...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Hit Submit Answer to see that, indeed, the row...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>Run the code with Submit Answer and assert tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>The single bracket version gives a Pandas Seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Use single square brackets to print out the co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>The result is another DataFrame containing onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>Select the first 3 observations from cars and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>cars.loc[['RU']] cars.iloc[[4]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>cars.loc[['RU', 'AUS']] cars.iloc[[4, 1]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>As before, code is included that imports the c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>Use loc or iloc to select the observation corr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>cars.loc[['IN', 'RU'], 'cars_per_cap'] cars.il...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>cars.loc[['IN', 'RU'], ['cars_per_cap', 'count...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>Print out the drives_right value of the row co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>cars.loc[:, ['country','drives_right']] cars.i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>Print out the drives_right column as a Series ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>When you write these comparisons in a script, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>In the editor on the right, write code to see ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>Remember that for string comparison, Python de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>Write Python expressions, wrapped in a print()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Using comparison operators, generate boolean a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Write Python expressions, wrapped in a print()...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Before, the operational operators like &lt; and &gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Generate boolean arrays that answer the follow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Examine the if statement that prints out \"Look...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>Add an else statement to the second control st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Add an elif to the second control structure su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>Extract the drives_right column as a Pandas Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Convert the code on the right to a one-liner t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>Select the cars_per_cap column from cars as a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>Use the code sample above to create a DataFram...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>This example will come in handy, because it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>As usual, you simply have to indent the code w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Write a for loop that iterates over all elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Adapt the for loop in the sample code to use e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>Adapt the print() function in the for loop on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>Write a for loop that goes through each sublis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>for key, value in world.items() : print(key + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Remember the europe dictionary that contained ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>Write a for loop that goes through each key:va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>If you're dealing with a 2D Numpy array, it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>Two Numpy arrays that you might recognize from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Import the numpy package under the local alias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>In this and the following exercises you will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Write a for loop that iterates over the rows o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>Adapt the code in the for loop such that the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>You can do similar things on the cars DataFrame.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>Use a for loop to add a new column, named COUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>brics[\"name_length\"] = brics[\"country\"].apply(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>We can do a similar thing to call the upper() ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>Replace the for loop with a one-liner that use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>This example will come in handy, because it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>Create the variable offset with an initial val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>Inside the while loop, replace offset = offset...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>As usual, you simply have to indent the code w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>Write a for loop that iterates over all elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Adapt the for loop in the sample code to use e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>Adapt the print() function in the for loop on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Write a for loop that goes through each sublis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>for key, value in world.items() : print(key + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>Remember the europe dictionary that contained ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>Write a for loop that goes through each key:va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>If you're dealing with a 2D Numpy array, it's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>Two Numpy arrays that you might recognize from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>Import the numpy package under the local alias...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>In this and the following exercises you will b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Write a for loop that iterates over the rows o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>Adapt the code in the for loop such that the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>You can do similar things on the cars DataFrame.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>Use a for loop to add a new column, named COUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>brics[\"name_length\"] = brics[\"country\"].apply(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>We can do a similar thing to call the upper() ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>Replace the for loop with a one-liner that use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Import numpy as np. Use seed() to set the seed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>Numpy has already been imported as np and a se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Use randint() with the appropriate arguments t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>Roll the dice. Use randint() to create the var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>Make a list random_walk that contains the firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>Use max() in a similar way to make sure that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>The first list you pass is mapped onto the x a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>Add some lines of code after the for loop: Imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>Initialize all_walks to an empty list. Fill in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Use np.array() to convert all_walks to a Numpy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>Things are shaping up nicely! You already have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Use max() in a similar way to make sure that s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Change the range() function so that the simula...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>To make sure we've got enough simulations, go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>552</th>\n",
       "      <td>Remember how you calculated the money you ende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>Instead of calculating with the actual values,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>In the previous exercise, you worked with two ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>int, or integer: a number without a fractional...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>Next to numerical data types, there are two ot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>Create a new string, desc, with the value \"com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>To find out the type of a value or a variable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>We already went ahead and created three variab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>Filip mentioned that different types behave di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>When you sum two strings, for example, you'll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>Using the + operator to paste together two str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>This will not work, though, as you cannot simp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>To fix the error, you'll need to explicitly co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>Now that you know something more about combini...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>As opposed to int, bool etc, a list is a compo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>After measuring the height of your family, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>-Create a list, areas, that contains the area ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>A list can contain any Python type. Although i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>A list can contain any Python type. But a list...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>Can you tell which ones of the following lines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>As a data scientist, you'll often be dealing w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>Finish the list of lists so that it also conta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Remember the areas list from before, containin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>After you've extracted values from a list, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Selecting single values from a list is just on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>The start index will be included, while the en...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>The elements with index 1 and 2 are included, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>In the video, Filip only discussed the syntax ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>However, it's also possible not to specify the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>Use slicing to create the lists downstairs and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>x[2] results in a list, that you can subset ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>aSNWE THERRRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>For this and the following exercises, you'll c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>#NAME?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>You just won the lottery, awesome! You decide ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Finally, you can also remove elements from you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Pay attention here: as soon as you remove an e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>There was a mistake! The amount you won with t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>Separate lines command1 command2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Which of the code chunks will do the job for u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>At the end of the video, Filip explained how P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>The general recipe for calling functions is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Use the Shell on the right to open up the docu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>Answer three</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>Two lists have been created for you on the rig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Use the index() method to get the index of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>Let's say the Moon's orbit around planet Earth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>Which import statement will you need in order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>For Numpy specifically, you can also use boole...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>The code that calculates the BMI of all baseba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>np_x = np.array(x) np_x[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>The script on the right already contains code ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>x = [[\"a\", \"b\"], [\"c\", \"d\"]] [x[0][0], x[1][0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>import numpy as np np_x = np.array(x) np_x[:,0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>For regular Python lists, this is a real pain....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>np_baseball is coded for you; it's again a 2D ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>The baseball data is available as a 2D Numpy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>Alright, it's time to create your first engine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>SQLAlchemy can be used to automatically load t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>Great job reflecting the census table! Now you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>Using what we just learned about SQL and apply...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>Excellent work so far! It's now time to build ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>Recall the differences between a ResultProxy a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>In these exercises, you will be working with r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>Having connected to the database, it's now tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>In addition to standard Python comparators, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>You're really getting the hang of this! SQLAlc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>To sort the result output by a field, we use t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>You can also use .order_by() to sort from high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>We can pass multiple arguments to the .order_b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>As mentioned in the video, SQLAlchemy's func m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>If instead you want to count the number of val...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>Furthermore, if you only want to count the dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>In this exercise, you will practice using func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>Often, we want to get a count for each record ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>INSTRUCTIONS 100XP Import func from sqlalchemy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>To avoid confusion with query result column na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>We can feed a ResultProxy directly into a pand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>We can also take advantage of pandas and Matpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>Before you jump into the calculation exercises...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>Often, you'll need to perform math operations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>It's possible to combine functions and operato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Import case, cast, and Float from sqlalchemy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>If you have two tables that already have an es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>in order to join the census and state_fact tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>If you aren't selecting columns from both tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>You can use the same select statement you buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>Often, you'll have tables that contain hierarc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>###INSTRUCTIONS 100XP Save an alias of the emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>It's also common to want to roll up data which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>Fantastic work so far! As Jason discussed in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>Previously, you used the Table object to refle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>You're now going to practice creating a table ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>There are several ways to perform an insert wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>It's time to practice inserting multiple recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>You've done a great job so far at inserting da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>The update statement is very similar to an ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>For your convenience, the names of the tables ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>As Jason discussed in the video, by using a wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>You can also update records with data from a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>Often, you'll need to empty a table of all of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>Do be careful, though, as deleting cannot be u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>By using a where() clause, you can target the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>Here you'll delete ALL rows which have 'M' in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>You're now going to practice dropping individu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>In this exercise, your job is to create an eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Having setup the engine and initialized the me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Leverage the Python CSV module from the standa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>724</th>\n",
       "      <td>Using the multiple insert pattern, in this exe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>In this exercise, you will use the func.sum() ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>In this exercise, you will write a query to de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>In this final exercise, you will write a query...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>It is time now to put together some of what yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>Rather than overlaying line plots on common ax...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>The command plt.axes() requires a lot of effor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Now you have some familiarity with plt.subplot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>In this exercise, you will work with the matpl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Using plt.xlim() and plt.ylim() are useful for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Legends are useful for distinguishing between ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>It is often useful to annotate a simple plot t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>Matplotlib comes with a number of different st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>In order to visualize two-dimensional arrays o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>This will create two arrays with a shape of (2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>753</th>\n",
       "      <td>Although plt.imshow() or plt.pcolor() are ofte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>When displaying a 2-D array with plt.imshow() ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Given a set of ordered pairs describing data p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>The function plt.hist2d() uses rectangular bin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Color images such as photographs contain the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Image data comes in many forms and it is not a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>When using plt.imshow() to display an array, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>Sometimes, low contrast images can be improved...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>As you have seen, seaborn provides a convenien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>Often, you don't just want to see the regressi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>When there are more complex relationships betw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>Often it is useful to compare and contrast tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>Rather than overlaying linear regressions of g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>Regressions are useful to understand relations...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>As you have seen, a strip plot can be visually...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>Both strip and swarm plots visualize all the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>There are numerous strategies to visualize how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>The seaborn function sns.jointplot() has a par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>Data sets often contain more than two continuo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>In this exercise, you will generate pairwise j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>Plotting relationships between many variables ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>How do they calculate the avaerages over the i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>For this exercise, you will construct a plot s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>You can easily slice subsets corresponding to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>In this exercise, you will use the same time s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>Remember, rather than comparing plots with sub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>In this exercise, you will plot pre-computed m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>Having plotted pre-computed moving averages of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>For grayscale images, various image processing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>A histogram of a continuous random variable is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>Histogram equalization is an image processing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>This exercise resembles the last in that you w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>Rather than overlaying univariate histograms o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Get product updates, company news, and more.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>Before you jump into the calculation exercises...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>Often, you'll need to perform math operations ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>It's possible to combine functions and operato...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825</th>\n",
       "      <td>Import case, cast, and Float from sqlalchemy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>826</th>\n",
       "      <td>If you have two tables that already have an es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>in order to join the census and state_fact tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>If you aren't selecting columns from both tabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>You can use the same select statement you buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>Often, you'll have tables that contain hierarc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>###INSTRUCTIONS 100XP Save an alias of the emp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>It's also common to want to roll up data which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>Fantastic work so far! As Jason discussed in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>Previously, you used the Table object to refle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>You're now going to practice creating a table ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>There are several ways to perform an insert wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>It's time to practice inserting multiple recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>You've done a great job so far at inserting da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>The update statement is very similar to an ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>For your convenience, the names of the tables ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>As Jason discussed in the video, by using a wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>You can also update records with data from a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>Often, you'll need to empty a table of all of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>Do be careful, though, as deleting cannot be u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>By using a where() clause, you can target the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Here you'll delete ALL rows which have 'M' in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>You're now going to practice dropping individu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>In this exercise, your job is to create an eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>Having setup the engine and initialized the me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>Leverage the Python CSV module from the standa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>Using the multiple insert pattern, in this exe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>In this exercise, you will use the func.sum() ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>In this exercise, you will write a query to de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>In this final exercise, you will write a query...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>You're no novice to data science, but let's ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>Reinforcement Learning, because the model is l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>As you know from previous courses, there are d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>Classification, because predicted probabilitie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>Now it's time to check out the dataset! You'll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>1560 rows, 25 columns, 1131 non-null entries i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>You'll continue your EDA in this exercise by c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>It's always good to know what datatypes you're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>Remember, your ultimate goal is to predict the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>As Peter mentioned in the video, there are ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>As Peter explained in the video, log loss prov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>To see how the log loss metric handles the tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>Alright, you've been patient and awesome. It's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>With split data in hand, you're only a few lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>You're ready to make some predictions! Remembe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>At last, you're ready to submit some predictio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>In this exercise, you'll study the effects of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>In order to get a bag-of-words representation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>Now you will use combine_text_columns to conve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>In order to make your life easier as you start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>Here, you'll perform a similar preprocessing p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>The next two exercises will introduce new topi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Now that you can separate text and numeric dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>In this exercise you're going to use FunctionT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>You're about to take everything you've learned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>Now you're cruising. One of the great strength...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>You just saw a substantial improvement in accu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>Recall from previous chapters that how you tok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>If you want, we've loaded this string into the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>4, because , and &amp; are not tokens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>Before you build up to the winning pipeline, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>In this exercise you'll insert a CountVectoriz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>Recall from the video that interaction terms i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>The second expression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>It's time to add interaction features to your ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>In the video, Peter explained that a hash func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>Some problems are memory-bound and not easily ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>In this exercise you will check out the scikit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>You have arrived! This is where all of your ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>Create a list of file names called filenames w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>Construct a copy of the DataFrame gold called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>Read 'monthly_max_temp.csv' into a DataFrame c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>948</th>\n",
       "      <td>Reorder the rows of weather1 using the .reinde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>950</th>\n",
       "      <td>As you can see by looking at their shapes, whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>Create a new DataFrame common_names by reindex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>953</th>\n",
       "      <td>Create a new DataFrame temps_f by extracting t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>Read the file 'GDP.csv' into a DataFrame calle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>In this exercise, stock prices in US Dollars f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>Read the DataFrames sp500 &amp; exchange from the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>In this exercise, you'll load sales data from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Read the files 'sales-jan-2015.csv', 'sales-fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>Having learned how to append Series, you'll no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>In this exercise, you'll use the Baby Names Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>The function pd.concat() can concatenate DataF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>It is often convenient to build a large DataFr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>When stacking a sequence of DataFrames vertica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>This exercise picks up where the last ended (a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>It is also possible to construct a DataFrame w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>Construct a new DataFrame february with MultiI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>You're now going to revisit the sales data you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>Here, you'll continue working with DataFrames ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>In this exercise, you'll compare the historica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>This exercise follows on the last one with the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>You continue working with the revenue &amp; manage...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>pd.merge(revenue, managers, on='city') Traceba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>Given this, it will take a bit more work for y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Another strategy to disambiguate cities with i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>return 5 rows with index labels [10, 20, 30, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>revenue.join(managers, lsuffix='_rev', rsuffix...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Suppose you have two DataFrames: students (wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>You now have, in addition to the revenue and m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>This exercise picks up where the previous one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>This exercise uses pre-loaded DataFrames austi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Similar to pd.merge_ordered(), the pd.merge_as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>In this chapter, you'll be using The Guardian'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Your task here is to prepare a DataFrame ioc_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Here, you'll start with the DataFrame editions...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>Here, you'll start with the concatenated DataF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>In this exercise, you'll start with the DataFr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>Here, you'll start with the DataFrames edition...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>Your task here is to prepare a DataFrame hosts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>This exercise starts off with fractions_change...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>This exercise starts off with the DataFrames r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>This final exercise starts off with the DataFr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Import Counter from collections. Use word_toke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>Import the WordNetLemmatizer class from nltk.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>Import Dictionary from gensim.corpora.dictiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Print the top five words of bow_doc using each...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>Now it's your turn to determine new significan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>Import TfidfModel from gensim.models.tfidfmode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>Tokenize article into sentences. Tokenize each...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1041</th>\n",
       "      <td>Create a defaultdict called ner_categories, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1043</th>\n",
       "      <td>Import spacy. Load the 'en' model using spacy....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>Create a new Text object called txt. Iterate o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>Use a list comprehension to create a list of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>Iterate over all of the entities of txt, using...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>Use a set comprehension to create a set of spa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Import CountVectorizer from sklearn.feature_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>Import TfidfVectorizer from sklearn.feature_ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>Create the DataFrames count_df and tfidf_df by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>Text classification models 50xp Which of the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Naive Bayes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1060</th>\n",
       "      <td>Linear Regression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1061</th>\n",
       "      <td>Deep Learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1063</th>\n",
       "      <td>Import the metrics module from sklearn and Mul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>Instantiate a MultinomialNB classifier called ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>Create a list of alphas to try using np.arange...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1069</th>\n",
       "      <td>Save the class labels as class_labelsby access...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1070</th>\n",
       "      <td>To get you up and running with the NetworkX AP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1071</th>\n",
       "      <td>23369, list, dict.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>NetworkX provides some basic drawing functiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>Now that you know some basic properties of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>In the video, Eric described to you different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>Weights can be added to edges in a graph, typi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>As Eric discussed, NetworkX also allows edges ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>It is time to try your first \"fancy\" graph vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1083</th>\n",
       "      <td>Circos plots are a rational, non-cluttered way...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>Following on what you've learned about the nxv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>How do you evaluate whether a node is an impor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>The number of neighbors that a node has is cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1091</th>\n",
       "      <td>The degree of a node is the number of neighbor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1093</th>\n",
       "      <td>You can leverage what you know about finding n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>Now that you've got the code for checking whet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>This is the final exercise of this trio! You'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>Betweenness centrality is a node importance me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>You're going to now take a deep dive into a Tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>Next, you're going to do an analogous deep div...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>Now that you've learned about cliques, it's ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>NetworkX provides an API for counting the numb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>Let us now move on to finding open triangles! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>Now that you've explored triangles (and open t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>There may be times when you just want to analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1115</th>\n",
       "      <td>In the previous exercise, we gave you a list o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>Let's continue recalling what you've learned b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1119</th>\n",
       "      <td>The last exercise was on degree centrality; th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>Let's now practice making some visualizations....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Next up, let's use the ArcPlot to visualize th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>Finally, you're going to make a CircosPlot of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>You're now going to practice finding cliques i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129</th>\n",
       "      <td>Great work! Let's continue by finding a partic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131</th>\n",
       "      <td>Almost there! You'll now look at important nod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>You're now going to combine what you've learne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>Finally, you're going to leverage the concept ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>Import numpy using the standard alias np.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>-Plot a PDF for the values in fraction with 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>Print the minimum value of the 'Engineering' c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>df[df['origin'] == 'US'].count()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>Extract data from ts0 for a single hour - the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1162</th>\n",
       "      <td>Create a new time series ts3 by reindexing ts2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>Downsample the 'Temperature' column of df to 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1166</th>\n",
       "      <td>Use partial string indexing to extract tempera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>Use partial string indexing to extract tempera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>Use partial string indexing to extract August ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>Use .str.strip() to strip extra whitespace fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1174</th>\n",
       "      <td>Replace the index of ts2 with that of ts1, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Create a Boolean mask, mask, such that if the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>Use pd.to_datetime() to convert the 'Date' col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>Plot the summer temperatures using method chai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>Import pandas as pd. Read the file 'data.csv' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>Convert the comma separated string column_labe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>Convert the 'date' column to a string with .as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>Print the 'dry_bulb_faren' temperature between...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>Select the 'dry_bulb_faren' column and print t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Downsample df_clean with daily frequency and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>Use .loc[] to select sunny days and assign to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>Import matplotlib.pyplot as plt. Select the 'v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>Create a Boolean Series for sunny days. Assign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200</th>\n",
       "      <td>Select the 'dew_point_faren' and 'dry_bulb_far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>From df_climate, extract the maximum temperatu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>Complete the function header of the nested fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>Complete the function header of the inner func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>Assign to echo_word the string word, concatena...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Complete the function header with the function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>Complete the function header with the function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>Complete the function header with the function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>Complete the function header with the function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>Complete the function header by supplying the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>Complete the function header by supplying the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>The function echo_word takes 2 parameters: a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>result = map(lambda a: a ** 2, nums)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1226</th>\n",
       "      <td>You can see here that a lambda function, which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1229</th>\n",
       "      <td>def gibberish(*args): \"\"\"Concatenate strings i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>gibberish() simply takes a list of strings as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>Create a for loop to loop over flash and print...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>Recall that range() doesn't actually create th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>Create an iterator object small_value over ran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1242</th>\n",
       "      <td>Create a range object that would produce the v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>Create a list of tuples from mutants and assig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>Using zip() with list(), create a list of tupl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>Create a zip object by using zip() on mutants ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>Initialize an empty dictionary counts_dict for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>Define the function count_entries(), which has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Using the range of numbers from 0 to 9 as your...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>Your task is to recreate this matrix by using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>In the inner list comprehension - that is, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>Use member as the iterator variable in the lis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>In the output expression, keep the string as-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>Create a dict comprehension where the key is a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>Create a generator object that will produce va...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>Write a generator expression that will generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>Complete the function header for the function ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>Extract the column 'created_at' from df and as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Extract the column 'created_at' from df and as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>Create a zip object by calling zip() and passi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>Define the function lists2dict() with two para...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>Inspect the contents of row_lists by printing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>To use the DataFrame() function you need, firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>Use open() to bind the csv file 'world_dev_ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>In the function read_large_file(), read a line...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>Bind the file 'world_dev_ind.csv' to file in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>Use pd.read_csv() to read in 'ind_pop.csv' in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>Use pd.read_csv() to read in the file in 'ind_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1293</th>\n",
       "      <td>Use pd.read_csv() to read in the file 'ind_pop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>Initialize an empty DataFrame data using pd.Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>Define the function plot_pop() that has two ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>#Chapter 1 - Parameter estimation by optimization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>The number of games played between each no-hit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>You have modeled no-hitters using an Exponenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>Now sample out of an exponential distribution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>Take 10000 samples out of an Exponential distr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>In the next few exercises, we will look at the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1307</th>\n",
       "      <td>We will assume that fertility is a linear func...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>The function np.polyfit() that you used to get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1311</th>\n",
       "      <td>For practice, perform a linear regression on t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>Now, to verify that all four of the Anscombe d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>In this exercise, you will generate bootstrap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>The function bootstrap_replicate_1d() from the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1319</th>\n",
       "      <td>In this exercise, you will compute a bootstrap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1321</th>\n",
       "      <td>We saw in a previous exercise that the mean is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>Consider again the inter-no-hitter intervals f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1325</th>\n",
       "      <td>As discussed in the video, pairs bootstrap inv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>Using the function you just wrote, perform pai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>A nice way to visualize the variability we mig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>In the video, you learned that permutation sam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>To help see how permutation sampling works, in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>the probability of observing a test statistic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>As discussed in the video, a permutation repli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>Kleinteich and Gorb (Sci. Rep., 4, 5225, 2014)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>The average strike force of Frog A was 0.71 Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>Another juvenile frog was studied, Frog C, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>In the video, we looked at a one-sample test, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>You performed a one-sample bootstrap hypothesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>The Civil Rights Act of 1964 was one of the mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1350</th>\n",
       "      <td>It turns out that you already did a hypothesis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>The observed correlation between female illite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>Do a permutation test: Permute the illiteracy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>The observed correlation between female illite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>As a final exercise in hypothesis testing befo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>Now, you will test the following hypothesis: O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>In the last exercise, you made a nice histogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>The histogram you just made had ten bins. This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>You will now use your ecdf() function to compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>In this exercise, you will write a function th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>The function foo() above takes two arguments a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>ECDFs also allow you to compare two or more di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>The mean of all measurements gives an indicati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>To see how the percentiles relate to the ECDF,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>Making a box plot for the petal lengths is unn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>In this exercise, you will compute the percent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>It is important to have some understanding of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>As mentioned in the video, the standard deviat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1382</th>\n",
       "      <td>When you made bee swarm plots, box plots, and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>The covariance may be computed using the Numpy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>As mentioned in the video, the Pearson correla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1388</th>\n",
       "      <td>We will be hammering the np.random module for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>You can think of a Bernoulli trial as a flip o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1392</th>\n",
       "      <td>Let's say a bank made 100 mortgage loans. It i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>Plot the number of defaults you got from the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>Compute the probability mass function for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>As mentioned in the video, plotting a nice loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>You just heard that the Poisson distribution i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1402</th>\n",
       "      <td>1990 and 2015 featured the most no-hitters of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>In this exercise, you will explore the Normal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>Now that you have a feel for how the Normal PD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>Since 1926, the Belmont Stakes is a 1.5 mile-l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1409</th>\n",
       "      <td>Assume that the Belmont winners' times are Nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1411</th>\n",
       "      <td>Sometimes, the story describing our probabilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413</th>\n",
       "      <td>Now, you'll use your sampling function to comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1416</th>\n",
       "      <td>The DataFrame has a total of 435 rows and 17 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1417</th>\n",
       "      <td>Except for 'party', all of the columns are of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1418</th>\n",
       "      <td>The first two rows of the DataFrame consist of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1419</th>\n",
       "      <td>There are 17 predictor variables, or features,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>The target variable in this DataFrame is 'party'.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1422</th>\n",
       "      <td>In sns.countplot(), we specify the x-axis data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1424</th>\n",
       "      <td>Import KNeighborsClassifier from sklearn.neigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>Import datasets from sklearn and matplotlib.py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>Import KNeighborsClassifier from sklearn.neigh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>Inside the for loop: Setup a k-NN classifier w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>Import numpy and pandas as their standard alia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>Import LinearRegression from sklearn.linear_mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>Import LinearRegression from sklearn.linear_mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>Import LinearRegression from sklearn.linear_mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>pandas and numpy are available in the workspac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>Import LinearRegression from sklearn.linear_mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>Import Lasso from sklearn.linear_model. Instan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>Don't worry about the specifics of the above f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>Instantiate a Ridge regressor and specify norm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>Import classification_report and confusion_mat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>Import: LogisticRegression from sklearn.linear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>Import roc_curve from sklearn.metrics. Using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>Import roc_auc_score from sklearn.metrics and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>Import LogisticRegression from sklearn.linear_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>Import DecisionTreeClassifier from sklearn.tre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>Create the hyperparameter grid: Use the array ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>Import the following modules: ElasticNet from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>Import pandas as pd. Read the CSV file 'gapmin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>Use the pandas get_dummies() function to creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>Import Ridge from sklearn.linear_model and cro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471</th>\n",
       "      <td>Explore the DataFrame df in the IPython Shell....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1473</th>\n",
       "      <td>Import Imputer from sklearn.preprocessing and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>Import the following modules: Imputer from skl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Import scale from sklearn.preprocessing. Scale...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>Import the following modules: StandardScaler f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>Setup the pipeline with the following steps: S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>Set up a pipeline with the following steps: 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>Get product updates, company news, and more.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>You are given an array grains giving the width...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>You observed in the previous exercise that the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>On the right are three scatter plots of the sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1490</th>\n",
       "      <td>Both plot 1 and plot 3.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>The first principal component of the data is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>The fish dataset is 6-dimensional. But what is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>In the previous exercise, you plotted the vari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>In a previous exercise, you saw that 2 was a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>In this exercise, you'll create a tf-idf word ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>You saw in the video that TruncatedSVD is able...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>It is now time to put your pipeline from the p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>Which of the following 2-dimensional arrays ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1506</th>\n",
       "      <td>In the video, you saw NMF applied to transform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>Now you will explore the NMF features you crea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>In this exercise, you'll check your understand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>In the video, you learned when NMF is applied ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>In the following exercises, you'll use NMF to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>Now use what you've learned about NMF to decom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>After you are done, take a moment to look thro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>Unlike NMF, PCA doesn't learn the parts of thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>In the video, you learned how to use NMF featu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>In this exercise and the next, you'll use what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>Suppose you were a big fan of Bruce Springstee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "1     Import pandas as pd. Read 'dob_job_application...\n",
       "3     Print the info of df. Print the info of the su...\n",
       "5     Print the value counts for: The 'Borough' colu...\n",
       "7     Import matplotlib.pyplot as plt. Create a hist...\n",
       "9     Using the .boxplot() method of df, create a bo...\n",
       "11    Using df, create a scatter plot (kind='scatter...\n",
       "13    Print the head of airquality. Use pd.melt() to...\n",
       "15    Print the head of airquality. Melt the Ozone, ...\n",
       "17    Print the head of airquality_melt. Pivot airqu...\n",
       "19    Print the index of airquality_pivot by accessi...\n",
       "20    Pivoting duplicate values 0xp So far, you've u...\n",
       "22    Melt tb keeping 'country' and 'year' fixed. Cr...\n",
       "24    Melt ebola using 'Date' and 'Day' as the id_va...\n",
       "26    Concatenate uber1, uber2, and uber3 together u...\n",
       "28    Concatenate ebola_melt and status_country colu...\n",
       "30    Import the glob module along with pandas (as i...\n",
       "32    Write a for loop to iterate though csv_files: ...\n",
       "34    Merge the site and visited DataFrames on the '...\n",
       "36    Merge the site and visited DataFrames on the '...\n",
       "38    Merge the site and visited DataFrames on the '...\n",
       "40    Convert the sex column of the tips DataFrame t...\n",
       "42    Use pd.to_numeric() to convert the 'total_bill...\n",
       "44    Import re. Compile a pattern that matches a ph...\n",
       "46    Import re. Write a pattern that will find all ...\n",
       "48    Write patterns to match: A telephone number of...\n",
       "50    Define a function named recode_sex() that has ...\n",
       "52                                  df.apply(my_square)\n",
       "53    The equivalent code using a lambda function is...\n",
       "54    The lambda function takes one parameter - the ...\n",
       "55    Use the .replace() method inside a lambda func...\n",
       "57    Create a new DataFrame called tracks that cont...\n",
       "59    Calculate the mean of the Ozone column of airq...\n",
       "61    Write an assert statement to confirm that ther...\n",
       "63    Each data point is a customer. The first input...\n",
       "64    Calculate the value in node 0 by multiplying i...\n",
       "66    Fill in the definition of the relu() function:...\n",
       "68    Define a function called predict_with_network(...\n",
       "70    Calculate node_0_0_input using its weights wei...\n",
       "72    Create a dictionary of weights called weights_...\n",
       "74    Import mean_squared_error from sklearn.metrics...\n",
       "76    Calculate the predictions, preds, by multiplyi...\n",
       "78    Set the learning rate to be 0.01 and calculate...\n",
       "80    Using a for loop to iteratively update weights...\n",
       "82    Store the number of columns in the predictors ...\n",
       "84    Compile the model using model.compile(). Your ...\n",
       "86    Fit the model. Remember that the first argumen...\n",
       "88    Convert df.survived to a categorical variable ...\n",
       "90    Create your predictions using the model's .pre...\n",
       "92    Import SGD from keras.optimizers. Create a lis...\n",
       "94    Compile your model using 'adam' as the optimiz...\n",
       "96    Import EarlyStopping from keras.callbacks. Com...\n",
       "98    Create model_2 to replicate model_1, but use 1...\n",
       "100   Specify a model called model_2 that is like mo...\n",
       "102   Create a Sequential object to start your model...\n",
       "104   Open the file moby_dick.txt as read-only and s...\n",
       "106   While still within this construct, the variabl...\n",
       "107   You'll now use these tools to print the first ...\n",
       "108   Open moby_dick.txt using the with context mana...\n",
       "110   Fill in the arguments of np.loadtxt() by passi...\n",
       "112   Complete the arguments of np.loadtxt(): the fi...\n",
       "114   Complete the first call to np.loadtxt() by pas...\n",
       "115   ## Working with mixed datatypes (1) 50xp Much ...\n",
       "116   Here, the first argument is the filename, the ...\n",
       "118   Import titanic.csv using the function np.recfr...\n",
       "120   Import the pandas package using the alias pd. ...\n",
       "121   ##Using pandas to import flat files as DataFra...\n",
       "122   Import the first 5 rows of the file into a Dat...\n",
       "124   Complete the sep (the pandas version of delim)...\n",
       "126   Import the pickle package. Complete the second...\n",
       "128   Assign the filename to the variable file. Pass...\n",
       "130   Load the sheet '2004' into the DataFrame df1 u...\n",
       "132   Parse the first sheet by index. In doing so, s...\n",
       "134   The data are adapted from the website of the u...\n",
       "135   Import the module SAS7BDAT from the library sa...\n",
       "137   Use pd.read_stata() to load the file 'disarea....\n",
       "139   Import the package h5py. Assign the name of th...\n",
       "141   Assign the HDF5 group data['strain'] to group....\n",
       "143   Import the package scipy.io. Load the file 'al...\n",
       "145   Once again, this file contains gene expression...\n",
       "146   Use the method .keys() on the dictionary mat t...\n",
       "148   Here, 'sqlite:///Northwind.sqlite' is called t...\n",
       "149   Import the function create_engine from the mod...\n",
       "151   Import the function create_engine from the mod...\n",
       "153   Open the engine connection as con using the me...\n",
       "155   with engine.connect() as con: rs = con.execute...\n",
       "156   Packages have already been imported as follows...\n",
       "157   The engine has also already been created: engi...\n",
       "158   The engine connection is already open with the...\n",
       "159   All the code you need to complete is within th...\n",
       "160   Execute the SQL query that selects the columns...\n",
       "162   In fact, you can filter any SELECT statement b...\n",
       "163                                         Query away!\n",
       "164   Complete the argument of create_engine() so th...\n",
       "166   In fact, you can order any SELECT statement by...\n",
       "167                                       Get querying!\n",
       "168   Using the function create_engine(), create an ...\n",
       "170   Using the function create_engine(), create an ...\n",
       "172   The following code has already been executed t...\n",
       "173   Assign to rs the results from the following qu...\n",
       "175   The following code has already been executed t...\n",
       "176   Use the pandas function read_sql_query() to as...\n",
       "178   Open the file moby_dick.txt as read-only and s...\n",
       "180   While still within this construct, the variabl...\n",
       "181   You'll now use these tools to print the first ...\n",
       "182   Open moby_dick.txt using the with context mana...\n",
       "184   Fill in the arguments of np.loadtxt() by passi...\n",
       "186   Complete the arguments of np.loadtxt(): the fi...\n",
       "188   Complete the first call to np.loadtxt() by pas...\n",
       "189   ## Working with mixed datatypes (1) 50xp Much ...\n",
       "190   Here, the first argument is the filename, the ...\n",
       "192   Import titanic.csv using the function np.recfr...\n",
       "194   Import the pandas package using the alias pd. ...\n",
       "195   ##Using pandas to import flat files as DataFra...\n",
       "196   Import the first 5 rows of the file into a Dat...\n",
       "198   Complete the sep (the pandas version of delim)...\n",
       "200   Import the pickle package. Complete the second...\n",
       "202   Assign the filename to the variable file. Pass...\n",
       "204   Load the sheet '2004' into the DataFrame df1 u...\n",
       "206   Parse the first sheet by index. In doing so, s...\n",
       "208   The data are adapted from the website of the u...\n",
       "209   Import the module SAS7BDAT from the library sa...\n",
       "211   Use pd.read_stata() to load the file 'disarea....\n",
       "213   Import the package h5py. Assign the name of th...\n",
       "215   Assign the HDF5 group data['strain'] to group....\n",
       "217   Import the package scipy.io. Load the file 'al...\n",
       "219   Once again, this file contains gene expression...\n",
       "220   Use the method .keys() on the dictionary mat t...\n",
       "222   Here, 'sqlite:///Northwind.sqlite' is called t...\n",
       "223   Import the function create_engine from the mod...\n",
       "225   Import the function create_engine from the mod...\n",
       "227   Open the engine connection as con using the me...\n",
       "229   with engine.connect() as con: rs = con.execute...\n",
       "230   Packages have already been imported as follows...\n",
       "231   The engine has also already been created: engi...\n",
       "232   The engine connection is already open with the...\n",
       "233   All the code you need to complete is within th...\n",
       "234   Execute the SQL query that selects the columns...\n",
       "236   In fact, you can filter any SELECT statement b...\n",
       "237                                         Query away!\n",
       "238   Complete the argument of create_engine() so th...\n",
       "240   In fact, you can order any SELECT statement by...\n",
       "241                                       Get querying!\n",
       "242   Using the function create_engine(), create an ...\n",
       "244   Using the function create_engine(), create an ...\n",
       "246   The following code has already been executed t...\n",
       "247   Assign to rs the results from the following qu...\n",
       "249   The following code has already been executed t...\n",
       "250   Use the pandas function read_sql_query() to as...\n",
       "252   After you import it, you'll check your working...\n",
       "253   Import the function urlretrieve from the subpa...\n",
       "255   Assign the URL of the file to the variable url...\n",
       "257   Your job is to use pd.read_excel() to read in ...\n",
       "258   Assign the URL of the file to the variable url...\n",
       "260   Import the functions urlopen and Request from ...\n",
       "262   Send the request and catch the response in the...\n",
       "264   Import the package requests. Assign the URL of...\n",
       "266   Import the function BeautifulSoupfrom the pack...\n",
       "268   In the sample code, the HTML response object h...\n",
       "270   Use the method find_all() to find all hyperlin...\n",
       "272   Load the JSON 'a_movie.json' into the variable...\n",
       "274   Import the requests package. Assign to the var...\n",
       "276   Pass the variable url to the requests.get() fu...\n",
       "278   Assign the relevant URL to the variable url. A...\n",
       "280   Import the package tweepy. Pass the parameters...\n",
       "282   Create your Stream object with authentication ...\n",
       "284   Assign the filename 'tweets.txt' to the variab...\n",
       "286   Use pd.DataFrame() to construct a DataFrame of...\n",
       "288   def word_in_text(word, tweet): word = word.low...\n",
       "289   You're going to iterate over the rows of the D...\n",
       "290   Within the for loop for index, row in df.iterr...\n",
       "292   Import both matplotlib.pyplot and seaborn usin...\n",
       "293   In this example, you're going to make a scatte...\n",
       "295   By calling multiple glyph functions on the sam...\n",
       "297   The three most important arguments to customiz...\n",
       "299   We can draw lines on Bokeh plots with the line...\n",
       "301   Lines and markers can be combined by plotting ...\n",
       "303   In Bokeh, extended geometrical shapes can be p...\n",
       "305   In the previous exercises, you made plots usin...\n",
       "307   You can create Bokeh plots from Pandas DataFra...\n",
       "309   You can create a ColumnDataSource object direc...\n",
       "311   In this exercise, you're going to add the box_...\n",
       "313   Now let's practice using and customizing the h...\n",
       "315   The final glyph customization we'll practice i...\n",
       "317   Layouts are collections of Bokeh figure object...\n",
       "319   In this exercise, you're going to use the colu...\n",
       "321   You can create nested layouts of plots by comb...\n",
       "323   Regular grids of Bokeh plots can be generated ...\n",
       "325   Tabbed layouts can be created in Pandas by pla...\n",
       "327   Tabbed layouts are collections of Panel object...\n",
       "329   Linking axes between plots is achieved by shar...\n",
       "331   By sharing the same ColumnDataSource object be...\n",
       "333   Legends can be added to any glyph by using the...\n",
       "335   Properties of the legend can be changed by usi...\n",
       "337   Working with the HoverTool is easy for data st...\n",
       "339   Let's get started with building an interactive...\n",
       "341   In the previous exercise, you added a single p...\n",
       "343   Having added a single slider in a widgetbox la...\n",
       "345   Let's begin making a Bokeh application that ha...\n",
       "347   You'll now learn how to use widget callbacks t...\n",
       "349   You'll now learn to update the plot's data usi...\n",
       "351   Here, you'll practice using a dropdown callbac...\n",
       "353   It's time to practice adding buttons to your i...\n",
       "355   You can also get really creative with your But...\n",
       "357   Here, you'll continue your Exploratory Data An...\n",
       "359   Let's get started on the Gapminder app. Your j...\n",
       "361   Now that you have the base plot ready, you can...\n",
       "363   Until now, we've been plotting data only for 1...\n",
       "365   Remember how in the plot from the previous exe...\n",
       "367   #Adding a hover tool In this exercise, you'll ...\n",
       "369   As a final step in enhancing your application,...\n",
       "372   In the video, you already saw how much the wor...\n",
       "373   print() the last item from both the year and t...\n",
       "375   Print the last item from both the list gdp_cap...\n",
       "377   Let's continue with the gdp_cap versus life_ex...\n",
       "378   Change the line plot that's coded in the scrip...\n",
       "380   Start from scratch: import matplotlib.pyplot a...\n",
       "382   Use plt.hist() to create a histogram of the va...\n",
       "384   Build a histogram of life_exp, with 5 bins. Ca...\n",
       "385   Build a histogram of life_exp with 15 bins. Bu...\n",
       "387   The strings xlab and ylab are already set for ...\n",
       "389   In this example, the ticks corresponding to th...\n",
       "390   Use tick_val and tick_lab as inputs to the xti...\n",
       "392   Run the script to see how the plot changes. Lo...\n",
       "394                          Nothing to worry about now\n",
       "395   Add c = col to the arguments of the plt.scatte...\n",
       "397   Add plt.grid(True) after the plt.text() calls ...\n",
       "399   Use the index() method on countries to find th...\n",
       "401   In this recipe, both the keys and the values a...\n",
       "403   Here, 'france' is the key and 'paris' the valu...\n",
       "404   Check out which keys are in europe by calling ...\n",
       "406   Add the key 'italy' with the value 'rome' to e...\n",
       "408   The capital of Germany is not 'bonn'; it's 'be...\n",
       "410   Use chained square brackets to select and prin...\n",
       "412   Import pandas as pd. Use the pre-defined lists...\n",
       "414   Hit Submit Answer to see that, indeed, the row...\n",
       "417   Run the code with Submit Answer and assert tha...\n",
       "419   The single bracket version gives a Pandas Seri...\n",
       "420   Use single square brackets to print out the co...\n",
       "422   The result is another DataFrame containing onl...\n",
       "423   Select the first 3 observations from cars and ...\n",
       "425                     cars.loc[['RU']] cars.iloc[[4]]\n",
       "426           cars.loc[['RU', 'AUS']] cars.iloc[[4, 1]]\n",
       "427   As before, code is included that imports the c...\n",
       "428   Use loc or iloc to select the observation corr...\n",
       "430   cars.loc[['IN', 'RU'], 'cars_per_cap'] cars.il...\n",
       "431   cars.loc[['IN', 'RU'], ['cars_per_cap', 'count...\n",
       "432   Print out the drives_right value of the row co...\n",
       "434   cars.loc[:, ['country','drives_right']] cars.i...\n",
       "435   Print out the drives_right column as a Series ...\n",
       "437   When you write these comparisons in a script, ...\n",
       "438   In the editor on the right, write code to see ...\n",
       "440   Remember that for string comparison, Python de...\n",
       "441   Write Python expressions, wrapped in a print()...\n",
       "443   Using comparison operators, generate boolean a...\n",
       "445   Write Python expressions, wrapped in a print()...\n",
       "446   Before, the operational operators like < and >...\n",
       "447   Generate boolean arrays that answer the follow...\n",
       "449   Examine the if statement that prints out \"Look...\n",
       "451   Add an else statement to the second control st...\n",
       "453   Add an elif to the second control structure su...\n",
       "455   Extract the drives_right column as a Pandas Se...\n",
       "457   Convert the code on the right to a one-liner t...\n",
       "459   Select the cars_per_cap column from cars as a ...\n",
       "461   Use the code sample above to create a DataFram...\n",
       "463   This example will come in handy, because it's ...\n",
       "466   As usual, you simply have to indent the code w...\n",
       "467   Write a for loop that iterates over all elemen...\n",
       "469   Adapt the for loop in the sample code to use e...\n",
       "471   Adapt the print() function in the for loop on ...\n",
       "473   Write a for loop that goes through each sublis...\n",
       "475   for key, value in world.items() : print(key + ...\n",
       "476   Remember the europe dictionary that contained ...\n",
       "477   Write a for loop that goes through each key:va...\n",
       "479   If you're dealing with a 2D Numpy array, it's ...\n",
       "480   Two Numpy arrays that you might recognize from...\n",
       "481   Import the numpy package under the local alias...\n",
       "483   In this and the following exercises you will b...\n",
       "484   Write a for loop that iterates over the rows o...\n",
       "486   Adapt the code in the for loop such that the f...\n",
       "488    You can do similar things on the cars DataFrame.\n",
       "489   Use a for loop to add a new column, named COUN...\n",
       "491   brics[\"name_length\"] = brics[\"country\"].apply(...\n",
       "492   We can do a similar thing to call the upper() ...\n",
       "493   Replace the for loop with a one-liner that use...\n",
       "495   This example will come in handy, because it's ...\n",
       "496   Create the variable offset with an initial val...\n",
       "498   Inside the while loop, replace offset = offset...\n",
       "500   As usual, you simply have to indent the code w...\n",
       "501   Write a for loop that iterates over all elemen...\n",
       "503   Adapt the for loop in the sample code to use e...\n",
       "505   Adapt the print() function in the for loop on ...\n",
       "507   Write a for loop that goes through each sublis...\n",
       "509   for key, value in world.items() : print(key + ...\n",
       "510   Remember the europe dictionary that contained ...\n",
       "511   Write a for loop that goes through each key:va...\n",
       "513   If you're dealing with a 2D Numpy array, it's ...\n",
       "514   Two Numpy arrays that you might recognize from...\n",
       "515   Import the numpy package under the local alias...\n",
       "517   In this and the following exercises you will b...\n",
       "518   Write a for loop that iterates over the rows o...\n",
       "520   Adapt the code in the for loop such that the f...\n",
       "522    You can do similar things on the cars DataFrame.\n",
       "523   Use a for loop to add a new column, named COUN...\n",
       "525   brics[\"name_length\"] = brics[\"country\"].apply(...\n",
       "526   We can do a similar thing to call the upper() ...\n",
       "527   Replace the for loop with a one-liner that use...\n",
       "529   Import numpy as np. Use seed() to set the seed...\n",
       "531   Numpy has already been imported as np and a se...\n",
       "532   Use randint() with the appropriate arguments t...\n",
       "534   Roll the dice. Use randint() to create the var...\n",
       "536   Make a list random_walk that contains the firs...\n",
       "538   Use max() in a similar way to make sure that s...\n",
       "540   The first list you pass is mapped onto the x a...\n",
       "541   Add some lines of code after the for loop: Imp...\n",
       "543   Initialize all_walks to an empty list. Fill in...\n",
       "545   Use np.array() to convert all_walks to a Numpy...\n",
       "546   Things are shaping up nicely! You already have...\n",
       "547   Use max() in a similar way to make sure that s...\n",
       "549   Change the range() function so that the simula...\n",
       "551   To make sure we've got enough simulations, go ...\n",
       "552   Remember how you calculated the money you ende...\n",
       "553   Instead of calculating with the actual values,...\n",
       "554   In the previous exercise, you worked with two ...\n",
       "555   int, or integer: a number without a fractional...\n",
       "556   Next to numerical data types, there are two ot...\n",
       "557   Create a new string, desc, with the value \"com...\n",
       "558   To find out the type of a value or a variable ...\n",
       "559   We already went ahead and created three variab...\n",
       "560   Filip mentioned that different types behave di...\n",
       "561   When you sum two strings, for example, you'll ...\n",
       "562   Using the + operator to paste together two str...\n",
       "563   This will not work, though, as you cannot simp...\n",
       "564   To fix the error, you'll need to explicitly co...\n",
       "565   Now that you know something more about combini...\n",
       "566   As opposed to int, bool etc, a list is a compo...\n",
       "567   After measuring the height of your family, you...\n",
       "568   -Create a list, areas, that contains the area ...\n",
       "569   A list can contain any Python type. Although i...\n",
       "570   A list can contain any Python type. But a list...\n",
       "571   Can you tell which ones of the following lines...\n",
       "572   As a data scientist, you'll often be dealing w...\n",
       "573   Finish the list of lists so that it also conta...\n",
       "575   Remember the areas list from before, containin...\n",
       "576   After you've extracted values from a list, you...\n",
       "577   Selecting single values from a list is just on...\n",
       "578   The start index will be included, while the en...\n",
       "579   The elements with index 1 and 2 are included, ...\n",
       "580   In the video, Filip only discussed the syntax ...\n",
       "581   However, it's also possible not to specify the...\n",
       "582   Use slicing to create the lists downstairs and...\n",
       "584   x[2] results in a list, that you can subset ag...\n",
       "585                                       aSNWE THERRRE\n",
       "587   For this and the following exercises, you'll c...\n",
       "588                                              #NAME?\n",
       "590   You just won the lottery, awesome! You decide ...\n",
       "591   Finally, you can also remove elements from you...\n",
       "592   Pay attention here: as soon as you remove an e...\n",
       "593   There was a mistake! The amount you won with t...\n",
       "594                    Separate lines command1 command2\n",
       "595   Which of the code chunks will do the job for u...\n",
       "596   At the end of the video, Filip explained how P...\n",
       "598   The general recipe for calling functions is th...\n",
       "600   Use the Shell on the right to open up the docu...\n",
       "601                                        Answer three\n",
       "603   Two lists have been created for you on the rig...\n",
       "606   Use the index() method to get the index of the...\n",
       "610   Let's say the Moon's orbit around planet Earth...\n",
       "612   Which import statement will you need in order ...\n",
       "617   For Numpy specifically, you can also use boole...\n",
       "618   The code that calculates the BMI of all baseba...\n",
       "620                          np_x = np.array(x) np_x[1]\n",
       "621   The script on the right already contains code ...\n",
       "625     x = [[\"a\", \"b\"], [\"c\", \"d\"]] [x[0][0], x[1][0]]\n",
       "626     import numpy as np np_x = np.array(x) np_x[:,0]\n",
       "627   For regular Python lists, this is a real pain....\n",
       "629   np_baseball is coded for you; it's again a 2D ...\n",
       "631   The baseball data is available as a 2D Numpy a...\n",
       "634   Alright, it's time to create your first engine...\n",
       "636   SQLAlchemy can be used to automatically load t...\n",
       "638   Great job reflecting the census table! Now you...\n",
       "640   Using what we just learned about SQL and apply...\n",
       "642   Excellent work so far! It's now time to build ...\n",
       "644   Recall the differences between a ResultProxy a...\n",
       "646   In these exercises, you will be working with r...\n",
       "648   Having connected to the database, it's now tim...\n",
       "650   In addition to standard Python comparators, we...\n",
       "652   You're really getting the hang of this! SQLAlc...\n",
       "654   To sort the result output by a field, we use t...\n",
       "656   You can also use .order_by() to sort from high...\n",
       "658   We can pass multiple arguments to the .order_b...\n",
       "660   As mentioned in the video, SQLAlchemy's func m...\n",
       "661   If instead you want to count the number of val...\n",
       "662   Furthermore, if you only want to count the dis...\n",
       "663   In this exercise, you will practice using func...\n",
       "665   Often, we want to get a count for each record ...\n",
       "666   INSTRUCTIONS 100XP Import func from sqlalchemy...\n",
       "667   To avoid confusion with query result column na...\n",
       "669   We can feed a ResultProxy directly into a pand...\n",
       "671   We can also take advantage of pandas and Matpl...\n",
       "673   Before you jump into the calculation exercises...\n",
       "675   Often, you'll need to perform math operations ...\n",
       "677   It's possible to combine functions and operato...\n",
       "679   Import case, cast, and Float from sqlalchemy. ...\n",
       "680   If you have two tables that already have an es...\n",
       "681   in order to join the census and state_fact tab...\n",
       "683   If you aren't selecting columns from both tabl...\n",
       "685   You can use the same select statement you buil...\n",
       "687   Often, you'll have tables that contain hierarc...\n",
       "688   ###INSTRUCTIONS 100XP Save an alias of the emp...\n",
       "689   It's also common to want to roll up data which...\n",
       "691   Fantastic work so far! As Jason discussed in t...\n",
       "693   Previously, you used the Table object to refle...\n",
       "695   You're now going to practice creating a table ...\n",
       "697   There are several ways to perform an insert wi...\n",
       "699   It's time to practice inserting multiple recor...\n",
       "701   You've done a great job so far at inserting da...\n",
       "703   The update statement is very similar to an ins...\n",
       "704   For your convenience, the names of the tables ...\n",
       "706   As Jason discussed in the video, by using a wh...\n",
       "708   You can also update records with data from a s...\n",
       "710   Often, you'll need to empty a table of all of ...\n",
       "711   Do be careful, though, as deleting cannot be u...\n",
       "713   By using a where() clause, you can target the ...\n",
       "714   Here you'll delete ALL rows which have 'M' in ...\n",
       "716   You're now going to practice dropping individu...\n",
       "718   In this exercise, your job is to create an eng...\n",
       "720   Having setup the engine and initialized the me...\n",
       "722   Leverage the Python CSV module from the standa...\n",
       "724   Using the multiple insert pattern, in this exe...\n",
       "726   In this exercise, you will use the func.sum() ...\n",
       "728   In this exercise, you will write a query to de...\n",
       "730   In this final exercise, you will write a query...\n",
       "732   It is time now to put together some of what yo...\n",
       "734   Rather than overlaying line plots on common ax...\n",
       "736   The command plt.axes() requires a lot of effor...\n",
       "738   Now you have some familiarity with plt.subplot...\n",
       "740   In this exercise, you will work with the matpl...\n",
       "742   Using plt.xlim() and plt.ylim() are useful for...\n",
       "744   Legends are useful for distinguishing between ...\n",
       "746   It is often useful to annotate a simple plot t...\n",
       "748   Matplotlib comes with a number of different st...\n",
       "750   In order to visualize two-dimensional arrays o...\n",
       "751   This will create two arrays with a shape of (2...\n",
       "753   Although plt.imshow() or plt.pcolor() are ofte...\n",
       "755   When displaying a 2-D array with plt.imshow() ...\n",
       "757   Given a set of ordered pairs describing data p...\n",
       "759   The function plt.hist2d() uses rectangular bin...\n",
       "761   Color images such as photographs contain the i...\n",
       "763   Image data comes in many forms and it is not a...\n",
       "765   When using plt.imshow() to display an array, t...\n",
       "767   Sometimes, low contrast images can be improved...\n",
       "769   As you have seen, seaborn provides a convenien...\n",
       "771   Often, you don't just want to see the regressi...\n",
       "773   When there are more complex relationships betw...\n",
       "775   Often it is useful to compare and contrast tre...\n",
       "777   Rather than overlaying linear regressions of g...\n",
       "779   Regressions are useful to understand relations...\n",
       "781   As you have seen, a strip plot can be visually...\n",
       "783   Both strip and swarm plots visualize all the d...\n",
       "785   There are numerous strategies to visualize how...\n",
       "787   The seaborn function sns.jointplot() has a par...\n",
       "789   Data sets often contain more than two continuo...\n",
       "791   In this exercise, you will generate pairwise j...\n",
       "793   Plotting relationships between many variables ...\n",
       "795   How do they calculate the avaerages over the i...\n",
       "796   For this exercise, you will construct a plot s...\n",
       "798   You can easily slice subsets corresponding to ...\n",
       "800   In this exercise, you will use the same time s...\n",
       "802   Remember, rather than comparing plots with sub...\n",
       "804   In this exercise, you will plot pre-computed m...\n",
       "806   Having plotted pre-computed moving averages of...\n",
       "808   For grayscale images, various image processing...\n",
       "810   A histogram of a continuous random variable is...\n",
       "812   Histogram equalization is an image processing ...\n",
       "814   This exercise resembles the last in that you w...\n",
       "816   Rather than overlaying univariate histograms o...\n",
       "818        Get product updates, company news, and more.\n",
       "819   Before you jump into the calculation exercises...\n",
       "821   Often, you'll need to perform math operations ...\n",
       "823   It's possible to combine functions and operato...\n",
       "825   Import case, cast, and Float from sqlalchemy. ...\n",
       "826   If you have two tables that already have an es...\n",
       "827   in order to join the census and state_fact tab...\n",
       "829   If you aren't selecting columns from both tabl...\n",
       "831   You can use the same select statement you buil...\n",
       "833   Often, you'll have tables that contain hierarc...\n",
       "834   ###INSTRUCTIONS 100XP Save an alias of the emp...\n",
       "835   It's also common to want to roll up data which...\n",
       "837   Fantastic work so far! As Jason discussed in t...\n",
       "839   Previously, you used the Table object to refle...\n",
       "841   You're now going to practice creating a table ...\n",
       "843   There are several ways to perform an insert wi...\n",
       "845   It's time to practice inserting multiple recor...\n",
       "847   You've done a great job so far at inserting da...\n",
       "849   The update statement is very similar to an ins...\n",
       "850   For your convenience, the names of the tables ...\n",
       "852   As Jason discussed in the video, by using a wh...\n",
       "854   You can also update records with data from a s...\n",
       "856   Often, you'll need to empty a table of all of ...\n",
       "857   Do be careful, though, as deleting cannot be u...\n",
       "859   By using a where() clause, you can target the ...\n",
       "860   Here you'll delete ALL rows which have 'M' in ...\n",
       "862   You're now going to practice dropping individu...\n",
       "864   In this exercise, your job is to create an eng...\n",
       "866   Having setup the engine and initialized the me...\n",
       "868   Leverage the Python CSV module from the standa...\n",
       "870   Using the multiple insert pattern, in this exe...\n",
       "872   In this exercise, you will use the func.sum() ...\n",
       "874   In this exercise, you will write a query to de...\n",
       "876   In this final exercise, you will write a query...\n",
       "878   You're no novice to data science, but let's ma...\n",
       "879   Reinforcement Learning, because the model is l...\n",
       "880   As you know from previous courses, there are d...\n",
       "881   Classification, because predicted probabilitie...\n",
       "882   Now it's time to check out the dataset! You'll...\n",
       "883   1560 rows, 25 columns, 1131 non-null entries i...\n",
       "884   You'll continue your EDA in this exercise by c...\n",
       "886   It's always good to know what datatypes you're...\n",
       "887   Remember, your ultimate goal is to predict the...\n",
       "889   As Peter mentioned in the video, there are ove...\n",
       "891   As Peter explained in the video, log loss prov...\n",
       "892   To see how the log loss metric handles the tra...\n",
       "894   Alright, you've been patient and awesome. It's...\n",
       "896   With split data in hand, you're only a few lin...\n",
       "898   You're ready to make some predictions! Remembe...\n",
       "900   At last, you're ready to submit some predictio...\n",
       "902   In this exercise, you'll study the effects of ...\n",
       "904   In order to get a bag-of-words representation ...\n",
       "906   Now you will use combine_text_columns to conve...\n",
       "908   In order to make your life easier as you start...\n",
       "910   Here, you'll perform a similar preprocessing p...\n",
       "912   The next two exercises will introduce new topi...\n",
       "914   Now that you can separate text and numeric dat...\n",
       "916   In this exercise you're going to use FunctionT...\n",
       "918   You're about to take everything you've learned...\n",
       "920   Now you're cruising. One of the great strength...\n",
       "922   You just saw a substantial improvement in accu...\n",
       "924   Recall from previous chapters that how you tok...\n",
       "925   If you want, we've loaded this string into the...\n",
       "926                   4, because , and & are not tokens\n",
       "927   Before you build up to the winning pipeline, i...\n",
       "929   In this exercise you'll insert a CountVectoriz...\n",
       "931   Recall from the video that interaction terms i...\n",
       "932                               The second expression\n",
       "933   It's time to add interaction features to your ...\n",
       "935   In the video, Peter explained that a hash func...\n",
       "936   Some problems are memory-bound and not easily ...\n",
       "937   In this exercise you will check out the scikit...\n",
       "939   You have arrived! This is where all of your ha...\n",
       "942   Create a list of file names called filenames w...\n",
       "944   Construct a copy of the DataFrame gold called ...\n",
       "946   Read 'monthly_max_temp.csv' into a DataFrame c...\n",
       "948   Reorder the rows of weather1 using the .reinde...\n",
       "950   As you can see by looking at their shapes, whi...\n",
       "951   Create a new DataFrame common_names by reindex...\n",
       "953   Create a new DataFrame temps_f by extracting t...\n",
       "955   Read the file 'GDP.csv' into a DataFrame calle...\n",
       "956   In this exercise, stock prices in US Dollars f...\n",
       "957   Read the DataFrames sp500 & exchange from the ...\n",
       "958   In this exercise, you'll load sales data from ...\n",
       "959   Read the files 'sales-jan-2015.csv', 'sales-fe...\n",
       "960   Having learned how to append Series, you'll no...\n",
       "962   In this exercise, you'll use the Baby Names Da...\n",
       "964   The function pd.concat() can concatenate DataF...\n",
       "966   It is often convenient to build a large DataFr...\n",
       "968   When stacking a sequence of DataFrames vertica...\n",
       "970   This exercise picks up where the last ended (a...\n",
       "972   It is also possible to construct a DataFrame w...\n",
       "974   Construct a new DataFrame february with MultiI...\n",
       "975   You're now going to revisit the sales data you...\n",
       "977   Here, you'll continue working with DataFrames ...\n",
       "979   In this exercise, you'll compare the historica...\n",
       "981   This exercise follows on the last one with the...\n",
       "983   You continue working with the revenue & manage...\n",
       "984   pd.merge(revenue, managers, on='city') Traceba...\n",
       "985   Given this, it will take a bit more work for y...\n",
       "987   Another strategy to disambiguate cities with i...\n",
       "989   return 5 rows with index labels [10, 20, 30, 3...\n",
       "990   revenue.join(managers, lsuffix='_rev', rsuffix...\n",
       "991   Suppose you have two DataFrames: students (wit...\n",
       "992   You now have, in addition to the revenue and m...\n",
       "994   This exercise picks up where the previous one ...\n",
       "996   This exercise uses pre-loaded DataFrames austi...\n",
       "998   Similar to pd.merge_ordered(), the pd.merge_as...\n",
       "1000  In this chapter, you'll be using The Guardian'...\n",
       "1002  Your task here is to prepare a DataFrame ioc_c...\n",
       "1004  Here, you'll start with the DataFrame editions...\n",
       "1006  Here, you'll start with the concatenated DataF...\n",
       "1008  In this exercise, you'll start with the DataFr...\n",
       "1010  Here, you'll start with the DataFrames edition...\n",
       "1012  Your task here is to prepare a DataFrame hosts...\n",
       "1014  This exercise starts off with fractions_change...\n",
       "1016  This exercise starts off with the DataFrames r...\n",
       "1018  This final exercise starts off with the DataFr...\n",
       "1029  Import Counter from collections. Use word_toke...\n",
       "1031  Import the WordNetLemmatizer class from nltk.s...\n",
       "1033  Import Dictionary from gensim.corpora.dictiona...\n",
       "1035  Print the top five words of bow_doc using each...\n",
       "1036  Now it's your turn to determine new significan...\n",
       "1037  Import TfidfModel from gensim.models.tfidfmode...\n",
       "1039  Tokenize article into sentences. Tokenize each...\n",
       "1041  Create a defaultdict called ner_categories, wi...\n",
       "1043  Import spacy. Load the 'en' model using spacy....\n",
       "1045  Create a new Text object called txt. Iterate o...\n",
       "1047  Use a list comprehension to create a list of t...\n",
       "1049  Iterate over all of the entities of txt, using...\n",
       "1051  Use a set comprehension to create a set of spa...\n",
       "1053  Import CountVectorizer from sklearn.feature_ex...\n",
       "1055  Import TfidfVectorizer from sklearn.feature_ex...\n",
       "1057  Create the DataFrames count_df and tfidf_df by...\n",
       "1058  Text classification models 50xp Which of the b...\n",
       "1059                                        Naive Bayes\n",
       "1060                                  Linear Regression\n",
       "1061                                      Deep Learning\n",
       "1063  Import the metrics module from sklearn and Mul...\n",
       "1065  Instantiate a MultinomialNB classifier called ...\n",
       "1067  Create a list of alphas to try using np.arange...\n",
       "1069  Save the class labels as class_labelsby access...\n",
       "1070  To get you up and running with the NetworkX AP...\n",
       "1071                                 23369, list, dict.\n",
       "1072  NetworkX provides some basic drawing functiona...\n",
       "1074  Now that you know some basic properties of the...\n",
       "1076  In the video, Eric described to you different ...\n",
       "1077  Weights can be added to edges in a graph, typi...\n",
       "1079  As Eric discussed, NetworkX also allows edges ...\n",
       "1081  It is time to try your first \"fancy\" graph vis...\n",
       "1083  Circos plots are a rational, non-cluttered way...\n",
       "1085  Following on what you've learned about the nxv...\n",
       "1087  How do you evaluate whether a node is an impor...\n",
       "1089  The number of neighbors that a node has is cal...\n",
       "1091  The degree of a node is the number of neighbor...\n",
       "1093  You can leverage what you know about finding n...\n",
       "1095  Now that you've got the code for checking whet...\n",
       "1097  This is the final exercise of this trio! You'r...\n",
       "1099  Betweenness centrality is a node importance me...\n",
       "1101  You're going to now take a deep dive into a Tw...\n",
       "1103  Next, you're going to do an analogous deep div...\n",
       "1105  Now that you've learned about cliques, it's ti...\n",
       "1107  NetworkX provides an API for counting the numb...\n",
       "1109  Let us now move on to finding open triangles! ...\n",
       "1111  Now that you've explored triangles (and open t...\n",
       "1113  There may be times when you just want to analy...\n",
       "1115  In the previous exercise, we gave you a list o...\n",
       "1117  Let's continue recalling what you've learned b...\n",
       "1119  The last exercise was on degree centrality; th...\n",
       "1121  Let's now practice making some visualizations....\n",
       "1123  Next up, let's use the ArcPlot to visualize th...\n",
       "1125  Finally, you're going to make a CircosPlot of ...\n",
       "1127  You're now going to practice finding cliques i...\n",
       "1129  Great work! Let's continue by finding a partic...\n",
       "1131  Almost there! You'll now look at important nod...\n",
       "1132  You're now going to combine what you've learne...\n",
       "1134  Finally, you're going to leverage the concept ...\n",
       "1137          Import numpy using the standard alias np.\n",
       "1149  -Plot a PDF for the values in fraction with 30...\n",
       "1151  Print the minimum value of the 'Engineering' c...\n",
       "1156                   df[df['origin'] == 'US'].count()\n",
       "1160  Extract data from ts0 for a single hour - the ...\n",
       "1162  Create a new time series ts3 by reindexing ts2...\n",
       "1164  Downsample the 'Temperature' column of df to 6...\n",
       "1166  Use partial string indexing to extract tempera...\n",
       "1168  Use partial string indexing to extract tempera...\n",
       "1170  Use partial string indexing to extract August ...\n",
       "1172  Use .str.strip() to strip extra whitespace fro...\n",
       "1174  Replace the index of ts2 with that of ts1, and...\n",
       "1176  Create a Boolean mask, mask, such that if the ...\n",
       "1178  Use pd.to_datetime() to convert the 'Date' col...\n",
       "1180  Plot the summer temperatures using method chai...\n",
       "1182  Import pandas as pd. Read the file 'data.csv' ...\n",
       "1184  Convert the comma separated string column_labe...\n",
       "1186  Convert the 'date' column to a string with .as...\n",
       "1188  Print the 'dry_bulb_faren' temperature between...\n",
       "1190  Select the 'dry_bulb_faren' column and print t...\n",
       "1192  Downsample df_clean with daily frequency and a...\n",
       "1194  Use .loc[] to select sunny days and assign to ...\n",
       "1196  Import matplotlib.pyplot as plt. Select the 'v...\n",
       "1198  Create a Boolean Series for sunny days. Assign...\n",
       "1200  Select the 'dew_point_faren' and 'dry_bulb_far...\n",
       "1202  From df_climate, extract the maximum temperatu...\n",
       "1205  Complete the function header of the nested fun...\n",
       "1207  Complete the function header of the inner func...\n",
       "1209  Assign to echo_word the string word, concatena...\n",
       "1211  Complete the function header with the function...\n",
       "1213  Complete the function header with the function...\n",
       "1215  Complete the function header with the function...\n",
       "1217  Complete the function header with the function...\n",
       "1219  Complete the function header by supplying the ...\n",
       "1221  Complete the function header by supplying the ...\n",
       "1223  The function echo_word takes 2 parameters: a s...\n",
       "1225               result = map(lambda a: a ** 2, nums)\n",
       "1226  You can see here that a lambda function, which...\n",
       "1229  def gibberish(*args): \"\"\"Concatenate strings i...\n",
       "1230  gibberish() simply takes a list of strings as ...\n",
       "1237  Create a for loop to loop over flash and print...\n",
       "1239  Recall that range() doesn't actually create th...\n",
       "1240  Create an iterator object small_value over ran...\n",
       "1242  Create a range object that would produce the v...\n",
       "1244  Create a list of tuples from mutants and assig...\n",
       "1246  Using zip() with list(), create a list of tupl...\n",
       "1248  Create a zip object by using zip() on mutants ...\n",
       "1250  Initialize an empty dictionary counts_dict for...\n",
       "1252  Define the function count_entries(), which has...\n",
       "1254  Using the range of numbers from 0 to 9 as your...\n",
       "1256  Your task is to recreate this matrix by using ...\n",
       "1257  In the inner list comprehension - that is, the...\n",
       "1259  Use member as the iterator variable in the lis...\n",
       "1261  In the output expression, keep the string as-i...\n",
       "1263  Create a dict comprehension where the key is a...\n",
       "1265  Create a generator object that will produce va...\n",
       "1267  Write a generator expression that will generat...\n",
       "1269  Complete the function header for the function ...\n",
       "1271  Extract the column 'created_at' from df and as...\n",
       "1273  Extract the column 'created_at' from df and as...\n",
       "1275  Create a zip object by calling zip() and passi...\n",
       "1277  Define the function lists2dict() with two para...\n",
       "1279  Inspect the contents of row_lists by printing ...\n",
       "1281  To use the DataFrame() function you need, firs...\n",
       "1283  Use open() to bind the csv file 'world_dev_ind...\n",
       "1285  In the function read_large_file(), read a line...\n",
       "1287  Bind the file 'world_dev_ind.csv' to file in t...\n",
       "1289  Use pd.read_csv() to read in 'ind_pop.csv' in ...\n",
       "1291  Use pd.read_csv() to read in the file in 'ind_...\n",
       "1293  Use pd.read_csv() to read in the file 'ind_pop...\n",
       "1295  Initialize an empty DataFrame data using pd.Da...\n",
       "1297  Define the function plot_pop() that has two ar...\n",
       "1298  #Chapter 1 - Parameter estimation by optimization\n",
       "1299  The number of games played between each no-hit...\n",
       "1301  You have modeled no-hitters using an Exponenti...\n",
       "1303  Now sample out of an exponential distribution ...\n",
       "1304  Take 10000 samples out of an Exponential distr...\n",
       "1305  In the next few exercises, we will look at the...\n",
       "1307  We will assume that fertility is a linear func...\n",
       "1309  The function np.polyfit() that you used to get...\n",
       "1311  For practice, perform a linear regression on t...\n",
       "1313  Now, to verify that all four of the Anscombe d...\n",
       "1315  In this exercise, you will generate bootstrap ...\n",
       "1317  The function bootstrap_replicate_1d() from the...\n",
       "1319  In this exercise, you will compute a bootstrap...\n",
       "1321  We saw in a previous exercise that the mean is...\n",
       "1323  Consider again the inter-no-hitter intervals f...\n",
       "1325  As discussed in the video, pairs bootstrap inv...\n",
       "1327  Using the function you just wrote, perform pai...\n",
       "1329  A nice way to visualize the variability we mig...\n",
       "1331  In the video, you learned that permutation sam...\n",
       "1333  To help see how permutation sampling works, in...\n",
       "1335  the probability of observing a test statistic ...\n",
       "1336  As discussed in the video, a permutation repli...\n",
       "1338  Kleinteich and Gorb (Sci. Rep., 4, 5225, 2014)...\n",
       "1340  The average strike force of Frog A was 0.71 Ne...\n",
       "1342  Another juvenile frog was studied, Frog C, and...\n",
       "1344  In the video, we looked at a one-sample test, ...\n",
       "1346  You performed a one-sample bootstrap hypothesi...\n",
       "1348  The Civil Rights Act of 1964 was one of the mo...\n",
       "1350  It turns out that you already did a hypothesis...\n",
       "1352  The observed correlation between female illite...\n",
       "1353  Do a permutation test: Permute the illiteracy ...\n",
       "1354  The observed correlation between female illite...\n",
       "1356  As a final exercise in hypothesis testing befo...\n",
       "1358  Now, you will test the following hypothesis: O...\n",
       "1360  In the last exercise, you made a nice histogra...\n",
       "1362  The histogram you just made had ten bins. This...\n",
       "1364  You will now use your ecdf() function to compu...\n",
       "1366  In this exercise, you will write a function th...\n",
       "1367  The function foo() above takes two arguments a...\n",
       "1369  ECDFs also allow you to compare two or more di...\n",
       "1371  The mean of all measurements gives an indicati...\n",
       "1373  To see how the percentiles relate to the ECDF,...\n",
       "1375  Making a box plot for the petal lengths is unn...\n",
       "1377  In this exercise, you will compute the percent...\n",
       "1378  It is important to have some understanding of ...\n",
       "1380  As mentioned in the video, the standard deviat...\n",
       "1382  When you made bee swarm plots, box plots, and ...\n",
       "1384  The covariance may be computed using the Numpy...\n",
       "1386  As mentioned in the video, the Pearson correla...\n",
       "1388  We will be hammering the np.random module for ...\n",
       "1390  You can think of a Bernoulli trial as a flip o...\n",
       "1392  Let's say a bank made 100 mortgage loans. It i...\n",
       "1394  Plot the number of defaults you got from the p...\n",
       "1396  Compute the probability mass function for the ...\n",
       "1398  As mentioned in the video, plotting a nice loo...\n",
       "1400  You just heard that the Poisson distribution i...\n",
       "1402  1990 and 2015 featured the most no-hitters of ...\n",
       "1404  In this exercise, you will explore the Normal ...\n",
       "1405  Now that you have a feel for how the Normal PD...\n",
       "1407  Since 1926, the Belmont Stakes is a 1.5 mile-l...\n",
       "1409  Assume that the Belmont winners' times are Nor...\n",
       "1411  Sometimes, the story describing our probabilit...\n",
       "1413  Now, you'll use your sampling function to comp...\n",
       "1416  The DataFrame has a total of 435 rows and 17 c...\n",
       "1417  Except for 'party', all of the columns are of ...\n",
       "1418  The first two rows of the DataFrame consist of...\n",
       "1419  There are 17 predictor variables, or features,...\n",
       "1420  The target variable in this DataFrame is 'party'.\n",
       "1422  In sns.countplot(), we specify the x-axis data...\n",
       "1424  Import KNeighborsClassifier from sklearn.neigh...\n",
       "1427  Import datasets from sklearn and matplotlib.py...\n",
       "1429  Import KNeighborsClassifier from sklearn.neigh...\n",
       "1431  Inside the for loop: Setup a k-NN classifier w...\n",
       "1433  Import numpy and pandas as their standard alia...\n",
       "1435  Import LinearRegression from sklearn.linear_mo...\n",
       "1437  Import LinearRegression from sklearn.linear_mo...\n",
       "1439  Import LinearRegression from sklearn.linear_mo...\n",
       "1441  pandas and numpy are available in the workspac...\n",
       "1442  Import LinearRegression from sklearn.linear_mo...\n",
       "1444  Import Lasso from sklearn.linear_model. Instan...\n",
       "1446  Don't worry about the specifics of the above f...\n",
       "1447  Instantiate a Ridge regressor and specify norm...\n",
       "1449  Import classification_report and confusion_mat...\n",
       "1451  Import: LogisticRegression from sklearn.linear...\n",
       "1453  Import roc_curve from sklearn.metrics. Using t...\n",
       "1455  Import roc_auc_score from sklearn.metrics and ...\n",
       "1457  Import LogisticRegression from sklearn.linear_...\n",
       "1459  Import DecisionTreeClassifier from sklearn.tre...\n",
       "1461  Create the hyperparameter grid: Use the array ...\n",
       "1463  Import the following modules: ElasticNet from ...\n",
       "1465  Import pandas as pd. Read the CSV file 'gapmin...\n",
       "1467  Use the pandas get_dummies() function to creat...\n",
       "1469  Import Ridge from sklearn.linear_model and cro...\n",
       "1471  Explore the DataFrame df in the IPython Shell....\n",
       "1473  Import Imputer from sklearn.preprocessing and ...\n",
       "1475  Import the following modules: Imputer from skl...\n",
       "1477  Import scale from sklearn.preprocessing. Scale...\n",
       "1479  Import the following modules: StandardScaler f...\n",
       "1481  Setup the pipeline with the following steps: S...\n",
       "1483  Set up a pipeline with the following steps: 'i...\n",
       "1484       Get product updates, company news, and more.\n",
       "1485  You are given an array grains giving the width...\n",
       "1487  You observed in the previous exercise that the...\n",
       "1489  On the right are three scatter plots of the sa...\n",
       "1490                            Both plot 1 and plot 3.\n",
       "1491  The first principal component of the data is t...\n",
       "1493  The fish dataset is 6-dimensional. But what is...\n",
       "1495  In the previous exercise, you plotted the vari...\n",
       "1496                                                  2\n",
       "1497  In a previous exercise, you saw that 2 was a r...\n",
       "1499  In this exercise, you'll create a tf-idf word ...\n",
       "1501  You saw in the video that TruncatedSVD is able...\n",
       "1503  It is now time to put your pipeline from the p...\n",
       "1505  Which of the following 2-dimensional arrays ar...\n",
       "1506  In the video, you saw NMF applied to transform...\n",
       "1508  Now you will explore the NMF features you crea...\n",
       "1510  In this exercise, you'll check your understand...\n",
       "1511  In the video, you learned when NMF is applied ...\n",
       "1513  In the following exercises, you'll use NMF to ...\n",
       "1515  Now use what you've learned about NMF to decom...\n",
       "1516  After you are done, take a moment to look thro...\n",
       "1518  Unlike NMF, PCA doesn't learn the parts of thi...\n",
       "1520  In the video, you learned how to use NMF featu...\n",
       "1521  In this exercise and the next, you'll use what...\n",
       "1523  Suppose you were a big fan of Bruce Springstee..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67385e9d-fb2e-4257-8d88-f4acb10c8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
